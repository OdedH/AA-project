An Asymptotic Analysis of Generative, Discriminative, and
Pseudolikelihood Estimators

Percy Liang
Computer Science Division, University of California, Berkeley, CA, USA

pliang@cs.berkeley.edu

Michael I. Jordan
jordan@cs.berkeley.edu
Computer Science Division and Department of Statistics, University of California, Berkeley, CA, USA

Abstract
Statistical and computational concerns have
motivated parameter estimators based on
various forms of likelihood, e.g., joint, conditional, and pseudolikelihood. In this paper,
we present a uniﬁed framework for studying
these estimators, which allows us to compare
their relative (statistical) eﬃciencies. Our
asymptotic analysis suggests that modeling
more of the data tends to reduce variance,
but at the cost of being more sensitive to
model misspeciﬁcation. We present experiments validating our analysis.

Note: this version (updated Oct. 16, 2010) ﬁxes some
errors in the original ICML paper, strengthens some
results, and provides more discussion.

1. Introduction
Probabilistic models play a prominent role in domains
such as natural language processing, bioinformatics,
and computer vision, where they provide methods
for jointly reasoning about many interdependent variables. For prediction tasks, one generally models a
conditional distribution over outputs given an input.
There can be reasons, however, for pursuing alternatives to conditional modeling. First, we might be able
to leverage additional statistical strength present in
the input by using generative methods rather than discriminative ones. Second, the exact inference required
for a full conditional likelihood could be intractable;
in this case, one might turn to computationally more
eﬃcient alternatives such as pseudolikelihood (Besag,
1975).
Appearing in Proceedings of the 25 th International Conference on Machine Learning, Helsinki, Finland, 2008. Copyright 2008 by the author(s)/owner(s).

The generative-discriminative distinction has received
much attention in machine learning. The standing intuition is that while discriminative methods achieve
lower asymptotic error, generative methods might be
better when training data are limited. This intuition
is supported by the theoretical comparison of Naive
Bayes and logistic regression (Ng & Jordan, 2002) and
the recent empirical success of hybrid methods (McCallum et al., 2006; Lasserre et al., 2006).
Computational concerns have also spurred the development of alternatives to the full likelihood; these
methods can be seen as optimizing an alternate
objective or performing approximate inference during optimization. Examples include pseudolikelihood
(Besag, 1975), composite likelihood (Lindsay, 1988),
tree-reweighted belief propagation (Wainwright et al.,
2003), piecewise training (Sutton & McCallum, 2005),
agreement-based learning (Liang et al., 2008), and
many others (Varin, 2008).
We can think of all these schemes as simply diﬀerent
estimators operating in a single model family. In this
work, we analyze the statistical properties of a class of
convex composite likelihood estimators for exponential
families, which contains the generative, discriminative,
and pseudolikelihood estimators as special cases.
The main focus of our analysis is on prediction error.
Standard tools from learning theory based on uniform
convergence typically only provide upper bounds on
this quantity. Moreover, they generally express estimation error in terms of the overall complexity of the
model family.1 In our case, since all estimators operate
in the same model family, these tools are inadequate
for comparing diﬀerent estimators.
Instead, we turn to asymptotic analysis, a mainstay
1
There are more advanced techniques such as local
Rademacher complexities, which focus on the relevant regions of the model family, but these typically only apply
to empirical risk minimization.

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

of theoretical statistics. There is much relevant statistical work on the estimators that we treat; note in
particular that Lindsay (1988) used asymptotic arguments to show that composite likelihoods are generally
less eﬃcient than the joint likelihood. The majority of
these results are, however, focused on parameter estimation. In the current paper, our focus is on prediction, and we also consider model misspeciﬁcation.
We draw two main conclusions from our analysis:
First, when the model is well-speciﬁed, conditioning
on fewer variables increases statistical eﬃciency; this
to some extent accounts for the better generalization
enjoyed by generative estimators and the worse performance of pseudolikelihood estimators. Second, model
misspeciﬁcation can severely increase both the approximation and estimation errors of generative estimators.
We conﬁrm our theoretical results by comparing our
three estimators on a toy example to verify the asymptotics and on a Markov model for part-of-speech tagging.

In structured prediction tasks, we are interested in
learning a mapping from an input space X to an output space Y. Probabilistic modeling is a common platform for solving such tasks, allowing for the natural
handling of missing data and the incorporation of latent variables.
In this paper, we focus on regular exponential families,
which deﬁne distributions over an outcome space Z as
follows:
def

(1)

d

where φ(z) ∈ R is a vector of suﬃcient statistics
(features), θ ∈ Rd is a vector of parameters, and
def

A(θ) = log eφ(z) θ ν(dz) is the log-partition function. In our case, the outcomes are input-output pairs:
z = (x, y) and Z = X × Y.
Exponential families include a wide range of popular
models used in machine learning. For example, for a
conditional random ﬁeld (CRF) (Laﬀerty et al., 2001)
deﬁned on a graph G = (V, E), we have an output variable for each node (y = {yi }i∈V ), and the features are
φ(x, y) = i∈V φnode (yi , x, i) + (i,j)∈E φedge (yi , yj ).
From the density pθ (z), we can compute event probabilities as follows:
pθ (z ∈ s) = exp{A(θ; s) − A(θ)},

In this paper, we consider a class of composite likelihood estimators (Lindsay, 1988), which is incidentally
equivalent to the multi-conditional learning framework
of McCallum et al. (2006). A composite likelihood consists of a weighted sum of component likelihoods, each
of which is the probability of one subset of variables
conditioned on another. In this work, we only consider
the case where the ﬁrst set is all the variables.
We adopt the following more fundamental way of specifying the components: Each component r is deﬁned by
a partitioning of the outcome space Z. We represent a
partitioning by an associated equivalence function that
maps each z ∈ Z to its partition:
Deﬁnition 1 (Equivalence function). An equivalence
function r is a measurable map from Z to measurable
subsets of Z such that for each z ∈ Z and z ∈ r(z),
r(z) = r(z ).
The component likelihood associated with r takes the
following form:

2. Exponential Family Estimators

pθ (z) = exp{φ(z) θ − A(θ)} for z ∈ Z,

2.1. Composite Likelihood Estimators

(2)

where A(θ; s) = log eφ(z) θ I[z ∈ s]ν(dz) is a conditional log-partition function.

pθ (z | z ∈ r(z)) = exp{φ(z) θ − A(θ; r(z))}.

(3)

By maximizing this quantity, we are intuitively taking
probability mass away from some neighborhood r(z)
of z and putting it on z.
Without loss of generality, assume the component
weights sum to 1, so we can think of taking an expectation over a random component R drawn from some
ﬁxed distribution P r . We then deﬁne the criterion
function:
def

mθ (z) = ER∼P r log pθ (z | z ∈ R(z)).

(4)

Given data points Z (1) , . . . , Z (n) drawn i.i.d. from
some true distribution p∗ (not necessarily in the exponential family), the maximum composite likelihood
estimator is deﬁned by averaging the criterion function
over these data points:
ˆ
ˆ
θ = argmax Emθ (Z),

(5)

θ

ˆ
where Emθ (Z) =

1
n

n
i=1

mθ (Z (i) ).

We can now place the three estimators of interest in
our framework:
Generative: We have one component rg (x, y) = X ×
Y, which has one partition—the whole outcome space.
Fully discriminative: We have one component
rd (x, y) = x × Y. The outcomes in each partition have
the same value of x, but diﬀerent y.

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators
v ⊗ = vv
Parameter estimates
Z = (X, Y ) data point
p∗ true distribution of the data
mθ criterion function (deﬁnes the estimator)
R risk (expected log-loss)
ˆ
ˆ
θ = argmaxθ Emθ (Z) [empirical parameter estimate]
θ◦ = argmaxθ Emθ (Z) [limiting parameter vector]
Random variables for asymptotic analysis
R ∼ P r [choose composite likelihood component]
S = R(Z) [neighborhood]
rd (x, y) = x × Y [fully discriminative component]
Sd = rd (Z) [discriminative neighborhood]
φ = φ(Z), Z ∼ p∗ [sample from true distribution]
φm = φ(Z m ), Z m ∼ pθ◦ (· | · ∈ R(Z)) [for estimation]
φe = φ(Z e ), Z e ∼ pθ◦ (· | · ∈ rd (Z)) [for prediction]

Table 1. Notation used in the paper. See Figure 1 for a
visualization of the random variables.

Pseudolikelihood discriminative: Assume y =
{yi }i∈V . For each i ∈ V , we have a component
ri (x, y) = {(x , y ) : x = x, y ∈ Y, yj = yj for j = i}.
P r is uniform over these components.
2.2. Prediction and Evaluation
ˆ
Given a parameter estimate θ, we make predictions
based on pθ (y | x). In this paper, we evaluate our
ˆ
model according to log-loss; the risk is the expected
log-loss:
R(θ) = E(X,Y )∼p∗ [− log pθ (Y | X)].

(6)

The quality of an estimator is determined by the gap
ˆ
between the risk of the estimate R(θ) and the Bayes
risk R∗ = H(Y | X). It will be useful to relate these
two via the risk of θ◦ = argmaxθ EZ∼p∗ mθ (Z), which
leads to the following standard decomposition:
ˆ
ˆ
R(θ) − R∗ = (R(θ) − R(θ◦ )) + (R(θ◦ ) − R∗ ) .
total error

estimation error

(7)

R
Zm

S

φm

Sd

Z

φe

φ

Figure 1. Graphical model showing the dependencies between the random variables in our analysis (these variables
are deﬁned formally in Table 1). Thick edges entering a
node denote that the node is a deterministic function of its
parents. Note the independence assumptions: conditioned
on the neighborhood S = R(Z) (Sd = rd (Z)), φ is independent of φm (φe ). This independence will be useful for
decomposing variances in our analysis.

In this paper, we assume that our exponential family
is identiﬁable.3 Also assume that our estimators conˆ P
verge (θ − θ◦ ) and are consistent when the model is
→
well-speciﬁed (if p∗ = pθ∗ , then θ◦ = θ∗ ). Note, however, that in general we do not assume that our model
is well-speciﬁed.
Our asymptotic analysis is driven by Taylor expansions, so we need to compute a few derivatives. The
derivatives of the log-partition function are moments
of the suﬃcient statistics (a standard result, see Wainwright and Jordan (2003), for example):
˙
A(θ; s) = EZ∼pθ (·|·∈s) (φ(Z))
¨
A(θ; s) = varZ∼pθ (·|·∈s) (φ(Z)).

mθ ◦
˙

= φ − E(φm | Z)
m

mθ◦ = −E[var(φ | S) | Z]
¨
˙ ◦ ) = E(φe − φ)
R(θ
¨
R(θ◦ ) = E var(φe | S).

The estimation error is due to having only ﬁnite data;
the approximation error is due to the intrinsic suboptimality of the estimator.2

We ﬁrst compute the asymptotic estimation errors
of composite likelihood estimators in general (Sections 3.1 and 3.2). Then we use these results to compare the estimators of interest (Sections 3.3 and 3.4).
2
Note that θ◦ is not necessarily the minimum risk parameter vector in the model family.

(8)
(9)

From these moments, we can obtain the derivatives
of mθ◦ and R (to simplify notation, we express these
in terms of random variables whose distributions are
deﬁned in Table 1):

approx. error

3. Asymptotic Analysis

Ze

(10)
(11)
(12)
(13)

3.1. Asymptotics of the Parameters
ˆ
We ﬁrst analyze how fast θ converges to θ◦ by computˆ
ing the asymptotic distribution of θ−θ◦ . In Section 3.2
3

In the non-identiﬁable case, the analysis becomes more
cluttered, but the results are essentially the same, since
predictions depend on only the distributions induced by
the parameters. See the longer version of this paper for an
in-depth discussion.

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

we use this result to get the asymptotic distribution of
ˆ
the estimation error R(θ) − R(θ◦ ).
The following standard lemma will prove to be very
useful in our analysis:
Lemma 1. For random vectors X, Y , we have
var(X) = E[var(X | Y )] + var[E(X | Y )].
The important implication of this lemma is that conditioning on another variable Y reduces the variance
of X. This lemma already hints at how conditioning
on more variables can lead to poorer estimators: conditioning reduces the variance of the data, which can
make it harder to learn about the parameters.
Another standard result we will use is the multivariate
Cauchy-Schwarz inequality:
Lemma 2. For random vectors X, Y with E(Y ⊗ )
we have E(X ⊗ ) E[XY ]E(Y ⊗ )−1 E[Y X ].

0,

The following theorem gives us the asymptotic variance of a general composite likelihood estimator:
Theorem 1 (Asymptotic distribution of the parameˆ P
ters). Assume θ − θ◦ . Then
→
√
ˆ
n(θ − θ◦ ) → N (0, Σ) .
(14)
The asymptotic variance is
Σ = Γ−1 + Γ−1 (Cm − Cc )Γ−1 ,

(15)

across diﬀerent components R. Cc is zero for the generative and fully discriminative estimators, which have
one component, but positive for the pseudolikelihood
discriminative estimator, which has more than one
component. The negative contribution of Cc to the
asymptotic variance suggests that having many diverse
components could in general be helpful. However, this
diversity is somewhat at odds with having larger neighborhoods, which tends to increase the sensitivity Γ but
reduce the component correction Cc .
The misspeciﬁcation correction Cm is zero when the
d
model is well-speciﬁed (in this case, φm | S = φ | S),
but is in general nonzero under model misspeciﬁcation.
In this latter case, one incurs a nonzero approximation
error (deﬁned in (7)) as expected, but the more subtle
point is that there is also a nonzero eﬀect on estimation
error.
Proof. The standard asymptotic normality result for
M-estimators (Theorem 5.21 of van der Vaart (1998)),
which includes composite likelihood estimators, gives
us the asymptotic variance:
Σ = (Emθ◦ )−1 (Em⊗ )(Emθ◦ )−1 .
¨
˙ θ◦
¨

(20)

The remainder of the proof simply re-expresses Σ in
terms of the quantities in our theorem. Subtracting
and adding an intermediate φm to (10) and taking the
outer product yields:
Em⊗ = E[(φ − φm ) + (φm − E(φm | Z))]⊗ .
˙ θ◦

where
Γ = E var(φm | S)

(16)

Cc = E var[E(φm | S) | Z]

(17)

is the sensitivity,

is the component correction, and
Cm = E[var(φ | S) − var(φm | S)]
m

⊗

+ E[E(φ | S) − E(φ | S)]

(18)
(19)

is the misspeciﬁcation correction.
Before we prove the theorem, let us use the decomposition in (15) to make several qualitative judgments.
First, the sensitivity Γ = E var(φm | S) is the expected amount of variation in the features given the
(random) neighborhood S = R(Z) of our data point
Z. The larger the sensitivity, the more the data can
tell us about the parameters, and thus the lower the
asymptotic variance will be.
The component correction Cc intuitively measures the
amount of variation in feature expectations E(φm | S)

We distribute this outer product over the sum of the
two terms, yielding (i) E[(φ − φm )⊗ ], (ii) E[var(φm |
Z)], and (iii) the pair of cross terms, which is exactly
−2E[var(φm | Z)] (since conditioned on Z, φ is a constant).
To handle (i), we condition on S, rendering φ and
φm conditionally independent (see Figure 1). Then
we subtract and add various expectations and observe
that all the cross terms are zero due to (conditional)
independence:
E[(φ − φm )⊗ ]

(21)
m

m

=EE (φ − E(φ | S)) − (φ − E(φ | S))+
m

(E(φ | S) − E(φ | S))

⊗

(22)

|S

(23)

=Evar(φ | S) + Evar(φ | S)+

(24)

m

m

⊗

E(E(φ | S) − E(φ | S))
m

=Cm + 2Evar(φ | S).
Summarizing our progress so far, we have
Em⊗ = Cm + 2Evar(φm | S) − Evar(φm | Z).
˙ θ◦

(25)
(26)

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

We now apply Lemma 1 (with X = φm and Y = R
conditioned on Z) to decompose the last term:
E var(φm | Z) = E var(φm | S) + E var[E(φm | S) | Z].
Note that we write S in place of R, Z because φm only
depends on R and Z through S = R(Z). Putting these
results together, and substituting the deﬁnitions of Cc
and Γ, we get
Em⊗ = Cm + Γ − Cc .
˙ θ◦
From (11), we have Emθ◦ = −Γ. Some simple algebra
¨
yields the formula of the asymptotic variance (15).
3.2. Asymptotics of the Risk
The following theorem turns Theorem 1 from a statement about the asymptotic distribution of the parameters into one about the risk:
Theorem 2 (Asymptotic distribution of the risk). Let
Σ be the asymptotic variance as deﬁned in (15). De˙ def ˙
¨ def ¨
note R = R(θ◦ ) and R = R(θ◦ ). Then
√

d

ˆ
˙
˙
n(R(θ) − R(θ◦ )) − N 0, R ΣR .
→

(27)

˙
Furthermore, if R = 0, then
d 1
ˆ
¨1 ¨1
n(R(θ) − R(θ◦ )) − tr W R 2 ΣR 2 , 1 ,
→
2

(28)

where W(V, n) is the Wishart distribution with n degrees of freedom.
Proof. Perform a Taylor expansion of the risk function
around θ◦ :
ˆ
˙ ˆ
R(θ) = R(θ◦ ) + R (θ − θ◦ ) +
(29)
1 ˆ
ˆ
¨ ˆ
(θ − θ◦ ) R(θ − θ◦ ) + o(||θ − θ◦ ||2 ).
2
We use a standard argument known as the delta
method (van der Vaart, 1998). Multiplying (29) on
√
both sides by n, rearranging terms, and applying
˙
Slutsky’s theorem, we get (27). However, when R = 0,
the ﬁrst-order term of the expansion (29) is zero,
so we must consider the second-order term to get a
¨
non-degenerate distribution. Note that R is positive
semideﬁnite. Multiplying (29) by n and rearranging
yields the following:
ˆ
n(R(θ) − R(θ◦ )) =

√
1
ˆ
¨1
tr [R 2 n(θ − θ◦ )]⊗ + · · ·
2

d
¨1√ ˆ
¨1 ¨1
Since R 2 n(θ − θ◦ ) − N (0, R 2 ΣR 2 ), applying the
→
continuous mapping theorem with the outer product

function yields a Wishart as the limiting distribution.
ˆ
Thus, n(R(θ) − R(θ◦ )) is asymptotically equal in dis1
tribution to 2 times the trace of a sample from that
Wishart distribution.
We can also understand (28) in the following way.
d
¨1 ¨1
Let V = R 2 ΣR 2 .
Note that 1 tr W(V, 1) =
2
1
2 tr (V W(I, 1)), which is the distribution of a weighted
sum of independent χ2 variables, where the weights
1
are determined by the diagonal elements of V . The
mean of this distribution is 1 tr(V ) and the variance is
2
tr(V • V ), where • denotes elementwise product.
An important question is when we obtain the ordi1
nary O(n− 2 ) convergence (27) versus the much better
O(n−1 ) convergence (28). A suﬃcient condition for
˙
O(n−1 ) convergence is R(θ◦ ) = 0. When the model is
well-speciﬁed, this is true for any consistent estimator.
Even if the model is misspeciﬁed, the fully discriminative estimator still achieves the O(n−1 ) rate. The
reason is that whenever a training criterion mθ is the
˙
same (up to constants) as the test criterion R(·), R
−1
vanishes and we obtain the O(n ) rate. This is in
concordance with a related observation made by Wainwright (2006) that it is better to use the same inference
procedure at both training and test time.
When the model is well-speciﬁed, there is another appealing property that holds if the training and test
criterion are the same up to constants: the asymptotic distribution of the risk depends on only the dimensionality of the exponential family, not the actual
structure of the model. In particular, for composite
likelihood estimators with one component, Σ = Γ−1 =
¨
¨1 ¨1
(−Emθ◦ )−1 = R−1 . Therefore, R 2 ΣR 2 = Id and so
¨
d
d 1
ˆ
n(R(θ) − R(θ◦ )) − 1 trW(Id , 1) = 2 χ2 , where d is
→ 2
d
the number of parameters. This result is essentially
another way of looking at the fact that the likelihood
ratio test statistic is asymptotically distributed as χ2 .
3.3. Comparing Estimation Errors
In the previous section, we analyzed the asymptotics
of a single estimator. Now, given two estimators, we
would like to be able to tell which one is better. In order to compare two estimators, it would be convenient
if they converged to the same limit. In this section,
we ensure this by assuming that the model is wellspeciﬁed and that our estimators are consistent.
Since all parameter estimates are used in the same
way for prediction, it suﬃces to analyze the relative
eﬃciencies of the parameter estimates. The following
theorem says that coarser partitionings of Z generally
lead to more eﬃcient estimators:

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

ˆ
Theorem 3 (Asymptotic relative eﬃciency). Let θ1
ˆ2 be two consistent estimators with asymptotic
and θ
variances Σ1 and Σ2 as deﬁned in (15). Assume that
ˆ
ˆ
either R1 or R2 is constant (that is, either θ1 or θ2
has exactly one component) and R1 (z) ⊃ R2 (z) for all
ˆ
z ∈ Z. If the model is well-speciﬁed, then Σ1 Σ2 (θ1
ˆ2 ).
is no worse than θ

R1

R2

S1

S2

are both zero. Putting these results together, we get
that Σ1 Σ2 .
Now, for the second part of the proof, let us assume
that R1 is constant. The goal is to rewrite Σ−1 and
1
Σ−1 and apply Lemma 2 to conclude that Σ−1 Σ−1 .
2
1
2
Let U1 and U2 be mθ◦ corresponding to the two esti˙
ˆ
ˆ
mators, θ1 and θ2 , respectively. Since R1 is a constant
and the model is well-speciﬁed, for the ﬁrst estimator,
we have:
⊗
Σ−1 = Γ1 Γ−1 Γ1 = Γ1 = E(U1 ).
1
1

For the second estimator, we have

Z

φ
Figure 2. Graphical model showing the dependencies between the random variables in the proof of Theorem 3. We
deﬁne S1 = ∪z∈S2 R1 (z).

Proof. In order to compare the two estimators, it will
be useful to deﬁne the random variables associated
with each on the same probability space. We do this
in Figure 2. The idea is that since S1 ⊃ S2 and R1 , R2
are equivalence relations, S1 = ∪z∈S2 R1 (z) = R1 (Z).
In other words, from the point of view of the ﬁrst estimator, R2 , S2 might as well not have been there. Intuitively, S2 preserves strictly more information about
Z than S1 , so applying S2 ﬁrst is harmless. Furthermore, since the model is well-speciﬁed, Z and Z m have
the same distribution conditioned on either S1 or S2
d
(φm = φ | Sk , k = 1, 2). Operationally, this allows us
to replace φm with φ whenever we condition on S1 or
S2 .
The proof is carried out in two parts. In the ﬁrst
part, we prove the theorem for the case where R2 is
constant. We will show that Γ−1
Γ−1 , where Γ1
1
2
and Γ2 are the sensitivities of the two estimators. Note
Γk = E var(φ | Sk ). We use Lemma 1 (with X = φ and
Y = S2 conditioned on S1 ) to decompose the variance:
Γ1 = E var(φ | S2 , S1 ) + E var[E(φ | S2 , S1 ) | S1 ].
Since φ is conditionally independent of S1 given S2 ,
var(φ | S2 , S1 ) = var(φ | S2 ), which is exactly Γ2 . The
second term is positive semideﬁnite, so Γ1 Γ2 , which
implies Γ−1 Γ−1 .
1
2
Let Cc1 and Cc2 be the component corrections of the
two estimators. Note that Cc2 = 0 because R2 is constant, so Cc1 Cc2 . The misspeciﬁcation corrections

⊗
Σ−1 = Evar(φ | S2 )E(U2 )−1 Evar(φ | S2 ).
2

Our next step is to show Evar(φ | S2 ) = E(U1 U2 ). We
can rewrite the deﬁnition of Uk (10) for k = 1, 2:
Uk = φ − E(φm | Z) = φ −

r
Pk (r)E(φ | r(Z)),
r

where we used the fact that E(φ | r(Z)) = E(φm |
r(Z)) for any r (since the model is well-speciﬁed).
Plugging in deﬁnitions for U1 and U2 and simplifying:
E(U1 U2 )

(30)
r
P2 (r)E(φ

=E[(φ − E(φ | S1 ))(φ −

| r(Z))) ]

r
r
P2 (r)E[(φ − E(φ | S1 ))(φ − E(φ | r(Z))) ]

=
r

r
P2 (r)Evar(φ | r(Z))

=
r

=Evar(φ | S2 ),
where in the second equality, we used the key fact that
conditioned on r(Z), E(φ | S1 ) is constant because R1
is constant and S1 ⊃ r(Z). This allows us to write
⊗
Σ−1 = E(U1 )
2

⊗
E(U1 U2 )E(U2 )E(U2 U1 ) = Σ−1 .
2

Applying Lemma 2 yields Σ−1
1

Σ−1 .
2

One might wonder if we really need one of R1 or R2
to be constant. Is it not enough to just assume that
R1 (z) ⊃ R2 (z) (for some coupling of the random variables R1 and R2 )? The answer is in general no, as the
following counterexample shows:
Counterexample Let Z = {1, 2, 3}. The general
shape of the distribution is given by the single feature
φ(1) = 1, φ(2) = 3, φ(3) = 2 and a scalar parameter θ controls the peakiness of the distribution. Let
the true parameter be θ∗ = 1. Consider two estiˆ
mators: θ1 has two components, r1a = {{1, 2}, {3}}

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

ˆ
and r1b = {{1}, {2, 3}}; θ2 also has two components,
r2a = {{1, 2}, {3}} and r2b = {{1}, {2}, {3}}. Both
estimators place 1 probability on each component.
2

In the following toy example where the model is wellspeciﬁed, we see concretely that the generative estimator has smaller asymptotic estimation error:

Coupling r1a with r2a and r1b with r2b , we have
R1 (z) ⊃ R2 (z). However, we computed and found
ˆ
that Σ1
2.36 and Σ2
3.15, so θ2 actually has
higher asymptotic variance although it has ﬁner partitionings.

Example Consider a model where x and y are binary variables: φ(x, y) θ = θ0 I[x = 0, y = 1] + θ1 I[x =
1, y = 1], where the true parameters are θ∗ = (0, 0).
3
1
We can compute Γg = var(φ) = 16 −1 −1 and
3

To explain this, note that the contribution of r2b to
the criterion function is zero, so the second estimator
is equivalent to just using the single component r2a
(= r1a ), so the ﬁrst estimator actually suﬀers by using the additional component r1b . In general, while
we would still expect coarser partitionings to be better even for estimators with many components, this
counterexample shows that we must exercise caution.
3.4. Comparing Estimators
Finally, we use Theorem 3 to compare the estimation
ˆ
and approximation errors of the generative (θg ), fully
ˆd ), and pseudolikelihood discriminadiscriminative (θ
ˆ
tive (θp ) estimators. The subscripts g, d, p will be attached to other variables to refer to the quantities associated with the corresponding estimators. In the following corollaries, we use the word “lower” loosely to
mean “no more than,” although in general we expect
the inequality to be strict.
Corollary 1 (Generative versus fully discriminative).
ˆ
(1) If the model is well-speciﬁed, θg has lower asympˆd ; both have zero approxtotic estimation error than θ
ˆ
imation error. (2) If the model is misspeciﬁed, θd has
lower approximation and asymptotic estimation errors
ˆ
than θg .
Proof. For (1), since Rd (z) ⊂ Rg (z), we have Σg Σd
by Theorem 3. Zero approximation error follows from
consistency. For (2), since the discriminative estimator
achieves the minimum risk in the model family, it has
the lowest approximation error. Also, by Theorem 2
and the ensuing discussion, it always converges at a
O(n−1 ) rate, whereas the generative estimator will in
1
general converge at a O(n− 2 ) rate.
Note that there is a qualitative change of asymptotics
in going from the well-speciﬁed to the misspeciﬁed scenario. This discontinuity demonstrates one weakness
of asymptotic analyses: we would expect that for a
very minor model misspeciﬁcation, the generative estimator would still dominate the discriminative estimator for moderate sample sizes, but even a small
misspeciﬁcation is magniﬁed in the asymptotic limit.

¨
R(θ∗ ) = Γd = E var(φ | X) =

1
16

2
0

0
2

. The mean

asymptotic estimation error (scaled by n) of the generative estimator is 1 tr(Γd Γ−1 ) = 3 while that of the
g
2
4
discriminative estimator is 1 tr(Γd Γ−1 ) = 1.
d
2
We now show that fully discriminative estimators are
statistically superior to pseudolikelihood discriminative estimators in all regimes, but of course pseudolikelihood is computationally more eﬃcient.
Corollary 2 (Fully discriminative versus pseudolikelihood discriminative). (1) If the model is well-speciﬁed,
ˆ
ˆ
θd has lower asymptotic estimation error than θp ; both
have zero approximation error. (2) If the model is misˆ
speciﬁed, θd has lower approximation and asymptotic
ˆ
estimation errors than θp .
Proof. For (1), since Rp (z) ⊂ Rd (z) and Rd is constant, Σd
Σp by Theorem 3. Zero approximation
error follows from consistency. For (2), the same arguments as the corresponding part of the proof of Corollary 1 apply.

4. Experiments
In this section, we validate our theoretical analysis empirically. First, we evaluate the three estimators on a
simple graphical model which allows us to plot the
real asymptotics of the estimation error (Section 4.1).
Then we show that in the non-asymptotic regime, the
qualitative predictions of the asymptotic analyses are
also valid (Section 4.2).
4.1. A Simple Graphical Model
Consider a four-node binary-valued graphical model
where z = (x1 , x2 , y1 , y2 ). The true model family
p∗ is an Markov random ﬁeld parametrized by θ∗ =
(α∗ , β ∗ , γ ∗ ) as follows:
φ(z) θ

=

αI[y1 = y2 ] + β(I[x1 = y1 ] + I[x2 = y2 ]) +
γ(I[x1 = y2 ] + I[x2 = y1 ]).

To emulate misspeciﬁcation, we set γ ∗ to be nonzero
and force γ = 0 during parameter estimation.

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

In the ﬁrst experiment, we estimated the variance (by
running 10K trials) of the estimation error as we increased the number of data points. We set α∗ = β ∗ =
1 for the true model. When γ ∗ = 0 (the model is
well-speciﬁed), Figures 3(a)–(c) show that scaling the
variance by n yields a constant; this implies that all
three estimators achieve O(n−1 ) convergence.
When the model is misspeciﬁed with γ ∗ = 0.5 (Figures 3(d)–(f)), there is a sharp diﬀerence between
the rates of the generative and discriminative estimators. The fully discriminative estimator still enjoys
the O(n−1 ) convergence; scaling by n reveals that the
generative and pseudolikelihood discriminative estima1
tors are only attaining a O(n− 2 ) rate as predicted by
Theorem 2 (Figure 3(f)). Note that the generative
estimator is aﬀected most severely.
Figures 3(g)–(h) demonstrate the non-asymptotic impact of varying the parameters of the graphical model
in terms of the total error. In (g), as we increase the
amount of misspeciﬁcation γ, the error increases for
all estimators, but most sharply for the generative estimator. In (h), as we increase the strength of the
edge potential α, the pseudolikelihood discriminative
estimator suﬀers, the fully discriminative estimator is
unaﬀected, and the generative estimator actually improves.
4.2. Part-of-speech Tagging
In this section, we present experiments on part-ofspeech (POS) tagging. In POS tagging, the input is a
sequence of words x = (x1 , . . . , x ) and the output is a
sequence of POS tags y = (y1 , . . . , y ), e.g., noun, verb,
etc. (There are 45 tags total.) We consider the following model, speciﬁed by the following features (roughly
2 million total):
−1

φ(x, y) =

φnode (yi , xi ) +
i=1

φedge (yi , yi+1 ), (31)
i=1

where the node features φnode (yi , xi ) are a vector of
indicator functions of the form I[yi = a, xi = b], and
the edge features φedge (yi , yi+1 ) are a vector of indicator functions of the form I[yi = a, yi+1 = b]. Trained
generatively, this model is essentially an HMM, but
slightly more expressive. Trained (fully) discriminatively, this model is a CRF.
We used the Wall Street Journal (WSJ) portion of the
Penn Treebank, with sections 0–21 for training (38K
sentences) and 22–24 for testing (5.5K sentences). Table 2(a) shows that the discriminative estimators perform better than the generative one. This is not surprising given that the model is misspeciﬁed (language

Accuracy
Log-loss
Train
Test
Train
Test
Gen.
0.940 0.935
4.628 4.945
0.977 0.956 1.480 3.120
Fully dis.
Pseudo dis. 0.975 0.955
1.562 3.170
(a) Real data (misspeciﬁed)
Accuracy
Log-loss
Train
Test
Train
Test
Gen.
0.989 0.898 0.570 7.297
0.992 0.879 0.407 12.431
Full dis.
Pseudo dis. 0.990 0.891
0.469 10.840
(b) Synthetic data (well-speciﬁed)
Table 2. Part-of-speech tagging results. Discriminative estimators outperform the generative estimator (on both test
accuracy and log-loss) when the model is misspeciﬁed, but
the reverse is true when the model is well-speciﬁed.

does not come from an HMM).
To verify that the generative estimator is superior
when the model is well-speciﬁed, we used the learned
generative model in the previous experiment to sample
1000 synthetic training and 1000 synthetic test examples. We then applied the estimators as before on this
artiﬁcial data. Table 2(b) shows that the generative estimator has an advantage over the fully discriminative
estimator, and both are better than the pseudolikelihood estimator.

5. Discussion and Extensions
We believe our analysis captures the essence of the
generative-discriminative distinction: by modeling the
input, we reduce the variance of the parameter estimates. In related work, Ng and Jordan (2002) showed
that Naive Bayes requires exponentially fewer examples than logistic regression to obtain the same estimation error. The key property needed in their proof
was that the Naive Bayes estimator decouples into d
independent closed form optimization problems, which
does not seem to be the deﬁning property of generative estimation. In particular, this property does not
apply to general globally-normalized generative models, but one would still expect those models to have
the advantages of being generative.
Given that the generative and discriminative estimators are complementary, one natural question is how
to interpolate between the two to get the beneﬁts of
both. Our framework naturally suggests two ways to
go about this. First, we could vary the coarseness of
the partitioning. Generative and discriminative estimators diﬀer only in this coarseness and there is a

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

1.7e-6
1.3e-6
8.4e-7
4.3e-7

2.7e-3

n · var(EstErr)

n · var(EstErr)

7.2e-5
5.9e-5
4.5e-5
3.2e-5
1.9e-5

√

var(EstErr)

2.1e-6

20K

40K

60K

80K

100K

20K

40K

n

80K

20K

40K

7.5e-6
5.0e-6

60K

80K

100K

80K

100K

6.1e-2

3.5e-4
2.6e-4
1.8e-4
9.2e-5

100K

20K

40K

n

60K

80K

4.9e-2
3.7e-2
2.5e-2
1.4e-2

100K

20K

n

(d) α∗ = β ∗ = 1

80K

(c) α∗ = β ∗ = 1

√

2.5e-6

60K

n

n · var(EstErr)

n · var(EstErr)

1.0e-5

60K

(f) α∗ = β ∗ = 1

7.1e-9

TotalErr

8.3e-9

3.9e-2

40K

n

(e) α∗ = β ∗ = 1

4.8e-2

TotalErr

1.8e-3

100K

4.3e-4

40K

2.0e-3

(b) α∗ = β ∗ = 1

1.2e-5

20K

2.2e-3

n

(a) α∗ = β ∗ = 1

var(EstErr)

60K

2.5e-3

2.9e-2
1.9e-2
9.7e-3
0.2

0.4

0.6

0.8

1.0

5.9e-9

◦
Generative θg

4.8e-9

◦
Fully discrim. θd

3.6e-9

◦
Pseudo. discrim. θp
0.6

γ

(g) Vary misspeciﬁcation

1.2

1.8

2.4

3.0

α

(h) Vary edge potentials

Figure 3. Asymptotics of the simple four-node graphical model. In (a)–(c), α∗ = β ∗ = 1 and γ ∗ = 0; we plot the
√
asymptotic variance of the estimation error, scaled by 1, n, and n. In (d)–(f), we repeat with γ ∗ = 0.5. In (g), we take
∗
∗
n = 20000 examples, α = β = 1 and vary γ. In (h), we take n = 20000, β ∗ = 1, γ ∗ = 0 and vary α.

range of intermediate choices corresponding to conditioning on more or fewer of the input variables. Second, we could take a weighted combination of estimators (e.g., Bouchard and Triggs (2004); McCallum
et al. (2006)). For one-parameter models, Lindsay
(1988) derived the optimal weighting of the component
likelihoods, but unfortunately these results cannot be
applied directly in practice.
It would also be interesting to perform a similar
asymptotic analysis on other estimators used in practice, for example marginal likelihoods with latent variables, tree-reweighted belief propagation (Wainwright
et al., 2003; Wainwright, 2006), piecewise training
(Sutton & McCallum, 2005), etc. Another important
extension is to curved exponential families, which account for many of the popular generative models based
on directed graphical models.

6. Conclusion
We have analyzed the asymptotic distributions of composite likelihood estimators in the exponential family.
The idea of considering diﬀerent partitionings of the
outcome space allows a clean and intuitive characterization of the asymptotic variances, which enables us
to compare the commonly used generative, discriminative, and pseudolikelihood estimators as special cases.
Our work provides new theoretical support for existing intuitions and a basis for developing new estimators which balance the tradeoﬀ between computational
and statistical eﬃciency.

Acknowledgments We thank Peter Bartlett for
useful discussions and Simon Lacoste-Julien for comments. We also wish to acknowledge NSF grant
0509559 and a grant from Microsoft Research.

An Asymptotic Analysis of Generative, Discriminative, and Pseudolikelihood Estimators

References
Besag, J. (1975). The analysis of non-lattice data. The
Statistician, 24, 179–195.
Bouchard, G., & Triggs, B. (2004). The trade-oﬀ between
generative and discriminative classiﬁers. International
Conference on Computational Statistics (pp. 721–728).
Laﬀerty, J., McCallum, A., & Pereira, F. (2001). Conditional random ﬁelds: Probabilistic models for segmenting and labeling data. International Conference on Machine Learning (ICML).
Lasserre, J. A., Bishop, C. M., & Minka, T. P. (2006). Principled hybrids of generative and discriminative models.
Computer Vision and Pattern Recognition (CVPR) (pp.
87–94).
Liang, P., Klein, D., & Jordan, M. I. (2008). Agreementbased learning. Advances in Neural Information Processing Systems (NIPS).
Lindsay, B. (1988). Composite likelihood methods. Contemporary Mathematics, 80, 221–239.
McCallum, A., Pal, C., Druck, G., & Wang, X. (2006).
Multi-conditional learning: Generative/discriminative
training for clustering and classiﬁcation. Association for
the Advancement of Artiﬁcial Intelligence (AAAI).
Ng, A. Y., & Jordan, M. I. (2002). On discriminative vs.
generative classiﬁers: A comparison of logistic regression and naive Bayes. Advances in Neural Information
Processing Systems (NIPS).
Sutton, C., & McCallum, A. (2005). Piecewise training of
undirected models. Uncertainty in Artiﬁcial Intelligence
(UAI).
van der Vaart, A. W. (1998). Asymptotic Statistics. Cambridge University Press.
Varin, C. (2008). On composite marginal likelihoods. Advances in Statistical Analysis, 92, 1–28.
Wainwright, M. (2006). Estimating the “wrong” graphical model: Beneﬁts in the computation-limited setting.
Journal of Machine Learning Research, 7, 1829–1859.
Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Treereweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching. Artiﬁcial Intelligence and Statistics (AISTATS).
Wainwright, M., & Jordan, M. I. (2003). Graphical models,
exponential families, and variational inference (Technical Report). Department of Statistics, University of California at Berkeley.

