Learning Dependency-Based Compositional
Semantics
Percy Liang∗

Michael I. Jordan∗∗

UC Berkeley

UC Berkeley

Dan Klein†
UC Berkeley

Suppose we want to build a system that answers a natural language question by representing its
semantics as a logical form and computing the answer given a structured database of facts. The
core part of such a system is the semantic parser that maps questions to logical forms. Semantic
parsers are typically trained from examples of questions annotated with their target logical forms,
but this type of annotation is expensive.
Our goal is to instead learn a semantic parser from question-answer pairs, where the logical
form is modeled as a latent variable. We develop a new semantic formalism, dependency-based
compositional semantics (DCS) and deﬁne a log-linear distribution over DCS logical forms. The
model parameters are estimated using a simple procedure that alternates between beam search
and numerical optimization. On two standard semantic parsing benchmarks, we show that our
system obtains comparable accuracies to even state-of-the-art systems that do require annotated
logical forms.
1. Introduction
One of the major challenges in NLP is building systems that both handle complex linguistic phenomena and require minimal human effort. The difﬁculty of achieving both
criteria is particularly evident in training semantic parsers, where annotating linguistic
expressions with their associated logical forms is expensive but until recently, seemingly
unavoidable. However, advances in learning latent-variable models have made it possible to progressively reduce the amount of supervision required for various semanticsrelated tasks (e.g., Zettlemoyer and Collins (2005); Liang et al. (2009); Branavan et al.
(2009); Clarke et al. (2010); Goldwasser et al. (2011); Artzi and Zettlemoyer (2011)). In
this article, we develop new techniques to learn accurate semantic parsers from even
weaker supervision.
We demonstrate our techniques on the concrete task of building a system to answer questions given a structured database of facts–see Figure 1 for an example in
the domain of US geography. This problem of building natural language interfaces to
databases (NLIDBs) has a long history in NLP, starting from the early days of AI with
systems such as L UNAR (Woods et al., 1972), C HAT-80 (Warren and Pereira, 1982), and

∗ Computer Science Division, University of California, Berkeley, CA 94720, USA.
∗∗ Computer Science Division and Department of Statistics, University of California, Berkeley, CA 94720,
USA.
† Computer Science Division, University of California, Berkeley, CA 94720, USA.

© 2012 Association for Computational Linguistics

Computational Linguistics

Volume ?, Number ?

What is the total population of the
ten largest cities in California?
city
San Francisco
Chicago
Boston
···

loc
Mount Shasta California
San Francisco California
Boston
Massachusetts
···
···

state
Alabama
Alaska
Arizona
···

population
Los Angeles 3.8 million
San Francisco 805,000
Boston
617,000
···
···

7
5
18
···

>
3
0
2
···

count
0
{}
{1,4} 2
{2,5,6} 3
···
···

System

?
Figure 1
The concrete objective: a system that answers natural language questions given a structured
database of facts. An example is shown in the domain of US geography.

many others (see Androutsopoulos et al. (1995) for an overview). We believe NLIDBs
provide an appropriate starting point for semantic parsing because they lead directly to
practical systems, and they allow us to temporarily sidestep intractable philosophical
questions on how to represent meaning in general. Early NLIDBs were quite successful
in their respective limited domains, but because these systems were constructed from
manually-built rules, they became difﬁcult to scale up, both to other domains and to
more complex utterances. In response, against the backdrop of a statistical revolution
in NLP during the 1990s, researchers began to build systems that could learn from
examples, with the hope of overcoming the limitations of rule-based methods. One of
the earliest statistical efforts was the C HILL system (Zelle and Mooney, 1996), which
learned a shift-reduce semantic parser. Since then, there has been a healthy line of
work yielding increasingly more accurate semantic parsers by using new semantic
representations and machine learning techniques (Zelle and Mooney, 1996; Miller et al.,
1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Kate et al., 2005; Zettlemoyer and
Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2006; Kate and Mooney, 2007;
Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010, 2011).
However, while statistical methods provided advantages such as robustness and
portability, their application in semantic parsing achieved only limited success. One
of the main obstacles was that these methods depended crucially on having examples
of utterances paired with logical forms, and this requires substantial human effort to
obtain. Furthermore, the annotators must be proﬁcient in some formal language, which
drastically reduces the size of the annotator pool, dampening any hope of acquiring
enough data to fulﬁll the vision of learning highly accurate systems.
In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al.,
2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011). It is in
this vein that we develop our present work. Speciﬁcally, given a set of (x, y) example
pairs, where x is an utterance (e.g., a question) and y is the corresponding answer, we
wish to learn a mapping from x to y. What makes this mapping particularly interesting
is it passes through a latent logical form z, which is necessary to capture the semantic
complexities of natural language. Also note that while the logical form z was the end
goal in much of earlier work on semantic parsing, for us, it is just an intermediate
variable—a means towards an end. Figure 2 shows the graphical model which captures

2

Liang et al.

Learning Dependency-Based Compositional Semantics

city
San Francisco
Chicago
Boston
···

[0.3, −0.7, 4.5, 1.2, . . . ]

loc
Mount Shasta California
San Francisco California
Boston
Massachusetts
···
···

state
Alabama
Alaska
Arizona
···

population
Los Angeles 3.8 million
San Francisco 805,000
Boston
617,000
···
···

(parameters)

>
3
0
2
···

count
0
{}
{1,4} 2
{2,5,6} 3
···
···

(world)

θ

7
5
18
···

w

Semantic Parsing
z ∼ p(z | x; θ)

Semantic Evaluation
y= z w

y

x

z

(utterance)

(logical form)

(answer)

state with the
largest area

∗∗

Alaska

x1
state
1
1
area
c
argmax

Figure 2
Our statistical methodology consists of two steps: (i) semantic parsing (p(z | x; θ)): an utterance
x is mapped to a logical form z by drawing from a log-linear distribution parametrized by a
vector θ; and (ii) evaluation ( z w ): the logical form z is evaluated with respect to the world w
(database of facts) to deterministically produce an answer y. The ﬁgure also shows an example
conﬁguration of the variables around the graphical model. Logical forms z are represented as
labeled trees. During learning, we are given w and (x, y) pairs (shaded nodes) and try to infer
the latent logical forms z and parameters θ.

the learning setting we just described: The question x, answer y, and world/database
w are all observed. We want to infer the logical forms z and the parameters θ of the
semantic parser, which are unknown quantities.
While liberating ourselves from annotated logical forms reduces cost, it does increase the difﬁculty of the learning problem. The core challenge here is program induction: on each example (x, y), we need to efﬁciently search over the exponential space
of possible logical forms (programs) z and ﬁnd ones that produces the target answer
y, a computationally daunting task. There is also a statistical challenge: how do we
parametrize the mapping from utterance x to logical form z so that it can be learned
from only the indirect signal y? To address these two challenges, we must ﬁrst discuss
the issue of semantic representation. There are two basic questions here: (i) what should
the formal language for the logical forms z be, and (ii) what are the compositional
mechanisms for constructing those logical forms?
The semantic parsing literature has considered many different formal languages
for represent logical forms, including SQL (Giordani and Moschitti, 2009), Prolog (Zelle
and Mooney, 1996; Tang and Mooney, 2001), a simple functional query language called
FunQL (Kate et al., 2005), and lambda calculus (Zettlemoyer and Collins, 2005), just to
name a few. The construction mechanisms are equally diverse, including synchronous

3

Computational Linguistics

Volume ?, Number ?

grammars (Wong and Mooney, 2007), hybrid trees (Lu et al., 2008), Combinatory Categorial Grammars (CCG) (Zettlemoyer and Collins, 2005), and shift-reduce derivations
(Zelle and Mooney, 1996). It is worth pointing out that the choice of formal language
and the construction mechanism are decisions which are really more orthogonal than is
often assumed—the former is concerned with what the logical forms look like; the latter,
with how to generate a set of possible logical forms compositionally given an utterance.
(How to score these logical forms is yet another dimension.)
Existing systems are rarely based on the joint design of the formal language and
the construction mechanism; one or the other is often chosen for convenience from
existing implementations. For example, Prolog and SQL have often been chosen as
formal languages for convenience in end applications, but they were not designed
for representing the semantics of natural language, and, as a result, the construction
mechanism that bridges the gap between natural language and formal language is
generally complex and difﬁcult to learn. CCG (Steedman, 2000) is quite popular in
computational linguistics (for example, see Bos et al. (2004); Zettlemoyer and Collins
(2005)). In CCG, logical forms are constructed compositionally using a small handful
of combinators (function application, function composition, and type raising). For a
wide range of canonical examples, CCG produces elegant, streamlined analyses, but
its success really depends on having a good, clean lexicon. During learning, there is
often large amounts of uncertainty over the lexical entries, which makes CCG more
cumbersome. Furthermore, in real-world applications, we would like to handle disﬂuent utterances, and this further strains CCG by demanding either extra type-raising
rules and disharmonic combinators (Zettlemoyer and Collins, 2007) or a proliferation of
redundant lexical entries for each word (Kwiatkowski et al., 2010).
To cope with the challenging demands of program induction, we break away from
tradition in favor of a new formal language and construction mechanism, which we
call dependency-based compositional semantics (DCS). The guiding principle behind DCS is
to provide a simple and intuitive framework for constructing and representing logical
forms. Logical forms in DCS are tree structures called DCS trees. The motivation is twofold: (i) DCS trees are meant to parallel syntactic dependency trees, which facilitates
parsing; and (ii) a DCS tree essentially encodes a constraint satisfaction problem, which
can be solved efﬁciently using dynamic programming to obtain the denotation of a DCS
tree. In addition, DCS provides a mark-execute construct, which provides a uniform way
of dealing with scope variation, a major source of trouble in any semantic formalism.
The construction mechanism in DCS is a generalization of labeled dependency parsing,
which leads to simple and natural algorithms. To a linguist, DCS might appear unorthodox, but it is important to keep in mind that our primary goal is effective program
induction, not necessarily to model new linguistic phenomena in the tradition of formal
semantics.
Armed with our new semantic formalism, DCS, we then deﬁne a discriminative
probabilistic model, which is depicted in Figure 2. The semantic parser is a loglinear distribution over DCS trees z given an utterance x. Notably, z is unobserved,
and we instead observe only the answer y, which is obtained by evaluating z on a
world/database w. There are an exponential number of possible trees z, and usually
dynamic programming can be used to efﬁciently search over trees. However, in our
learning setting (independent of the semantic formalism), we must enforce the global
constraint that z produces y. This makes dynamic programming infeasible, so we use
beam search (though dynamic programming is still used to compute the denotation
of a ﬁxed DCS tree). We estimate the model parameters with a simple procedure which
alternates between beam search and optimizing a likelihood objective restricted to those

4

Liang et al.

Learning Dependency-Based Compositional Semantics

beams. This yields a natural bootstrapping procedure in which learning and search are
integrated.
We evaluated our DCS-based approach on two standard benchmarks, G EO, a US
geography domain (Zelle and Mooney, 1996) and J OBS, a job queries domain (Tang and
Mooney, 2001). On G EO, we found that our system signiﬁcantly outperforms previous
work that also learns from answers instead of logical forms (Clarke et al., 2010). What
is perhaps a more signiﬁcant result is that our system obtains comparable accuracies to
state-of-the-art systems that do rely on annotated logical forms. This demonstrates that
the viability of training accurate systems with much less supervision than before.
The rest of this article is organized as follows: Section 2 introduces dependencybased compositional semantics (DCS), our new semantic formalism. Section 3 presents
our probabilistic model and learning algorithm. Section 4 provides an empirical evaluation of our methods. Finally, Section 5 situates this work in a broader context.
2. Representation
In this section, we present the main conceptual contribution of this work, dependencybased compositional semantics (DCS), using the US geography domain (Zelle and
Mooney, 1996) as a running example. To do this, we need to deﬁne the syntax and
semantics of the formal language. The syntax is deﬁned in Section 2.2 and is quite
straightforward: The logical forms in the formal language are simply trees, which we
call DCS trees. In Section 2.3, we give a type-theoretic deﬁnition of worlds (also known
as databases or models) with respect to which we can deﬁne the semantics of DCS trees.
The semantics, which is the heart of this article, contains two main ideas: (i) using
trees to represent logical forms as constraint satisfaction problems or extensions thereof,
and (ii) dealing with cases when syntactic and semantic scope diverge (e.g., for generalized quantiﬁcation and superlative constructions) using a new construct which we
call mark-execute. We start in Section 2.4 by introducing the semantics of a basic version
of DCS which focuses only on (i) and then extend it to the full version (Section 2.5) to
account for (ii).
Finally, having fully speciﬁed the formal language, we describe a construction
mechanism for mapping a natural language utterance to a set of candidate DCS trees
(Section 2.6).
2.1 Notation
Operations on tuples will play a prominent role in this article. For a sequence1 v =
(v1 , . . . , vk ), we use |v| = k to denote the length of the sequence. For two sequences
u and v, we use u + v = (u1 , . . . , u|u| , v1 , . . . , v|v| ) to denote their concatenation.
For a sequence of positive indices i = (i1 , . . . , im ), let vi = (vi1 , . . . , vim ) consist of
the components of v speciﬁed by i; we call vi the projection of v onto i. We use negative
indices to exclude components: v−i = (v(1,...,|v|)\i ). We can also combine sequences of
indices by concatenation: vi,j = vi + vj . Some examples: if v = (a, b, c, d), then v2 = b,
v3,1 = (c, a), v−3 = (a, b, d), v3,−3 = (c, a, b, d).

1 We use the sequence to include both tuples (v1 , . . . , vk ) and arrays [v1 , . . . , vk ]. For our purposes, there is
no functional difference between tuples and arrays; the distinction is convenient when we start to talk
about arrays of tuples.

5

Computational Linguistics

Volume ?, Number ?

Relations R
Name
join
aggregate
extract
quantify
compare
execute

Relation
j
j for j, j ∈ {1, 2, . . . }
Σ
E
Q
C
Xi

for i ∈ {1, 2 . . . }∗

Description of semantic function
j-th component of parent = j -th component of child
parent = set of feasible values of child
mark node for extraction
mark node for quantiﬁcation, negation
mark node for superlatives, comparatives
process marked nodes speciﬁed by i

Table 1
Possible relations that appear on edges of DCS trees. Basic DCS uses only the join and aggregate
relations; the full version of DCS uses all of them.

2.2 Syntax of DCS Trees
The syntax of the DCS formal language is built from two ingredients, predicates and
relations:

r

r

Let P be a set of predicates. We assume that P contains a special null
predicate ø, domain-independent predicates (e.g., count, <, >, and =), and
domain-speciﬁc predicates (for the US geography domain, state, river,
border, etc.). Right now, think of predicates as just labels, which have yet
to receive formal semantics.
Let R be the set of relations. note that unlike the predicates P, which can
very across domains, the relations R are ﬁxed. The full set of relations are
shown in Table 1. For now, just think of relations as labels—their semantics
will be deﬁned in Section 2.4.

The logical forms in DCS are called DCS trees. A DCS tree is a directed rooted tree
in which nodes are labeled with predicates and edges are labeled with relations; each
node also maintains an ordering over its children. Formally:
Deﬁnition 1 (DCS trees)
Let Z be the set of DCS trees, where each z ∈ Z consists of (i) a predicate z.p ∈ P and
(ii) a sequence of edges z.e = (z.e1 , . . . , z.em ). Each edge e consists of a relation e.r ∈ R
(see Table 1) and a child tree e.c ∈ Z.
We will either draw a DCS tree graphically or write it compactly as p; r1 : c1 ; . . . ; rm : cm
where p is the predicate at the root node and c1 , . . . , cm are its m children connected via
edges labeled with relations r1 , . . . , rm , respectively. Figure 3(a) shows an example of a
DCS tree expressed using both graphical and compact formats.
A DCS tree is a logical form, but it is designed to look like a syntactic dependency
tree, only with predicates in place of words. As we’ll see over the course of this section,
it is this transparency between syntax and semantics provided by DCS which leads to a
simple and streamlined compositional semantics suitable for program induction.

6

Liang et al.

Learning Dependency-Based Compositional Semantics

Example: major city in California
z = city; 1 : major ; 1 : loc; 2 : CA
1
1
1
city
1 1
1
major

1
loc
2
1
CA

λc ∃m ∃ ∃s .
city(c) ∧ major(m) ∧ loc( ) ∧ CA(s)∧
c1 = m1 ∧ c1 = 1 ∧ 2 = s1

(a) DCS tree

(b) Lambda calculus formula

(c) Denotation: z

w

= {SF, LA, . . . }

Figure 3
(a) An example of a DCS tree (written in both the mathematical and graphical notation). Each
node is labeled with a predicate, and each edge is labeled with a relation. (b) A DCS tree z with
only join relations encodes a constraint satisfaction problem, represented here as a lambda
calculus formula. For example, the root node label city corresponds to a unary predicate
city(c), the right child node label loc corresponds to a binary predicate loc( ) (where is a
pair), and the edge between them denotes the constraint c1 = 1 , where the indices corresponds
to the two labels on the edge. (c) The denotation of z is the set of feasible values for the root
node.
w:

city
San Francisco
Chicago
Boston
···

loc
Mount Shasta California
San Francisco California
Boston
Massachusetts
···
···

>
7 3
5 0
18 2
··· ···

state
Alabama
Alaska
Arizona
···

population
Los Angeles 3.8 million
San Francisco 805,000
Boston
617,000
···
···

count
0
{}
{1,4} 2
{2,5,6} 3
···
···

Figure 4
We use the domain of US geography as a running example. The ﬁgure presents an example of a
world w (database) in this domain. A world maps each predicate to a set of tuples. For example,
the depicted world w maps the predicate loc to the set of pairs of places and their containers.
Note that functions (e.g., population) are also represented as predicates for uniformity. Some
predicates (e.g., count) map to an inﬁnite number of tuples and would be represented
implicitly.

2.3 Worlds
In the context of question answering, the DCS tree is a formal speciﬁcation of the
question. To obtain an answer, we still need to evaluate the DCS tree with respect to
a database of facts (see Figure 4 for an example). We will use the term world to refer

7

Computational Linguistics

Volume ?, Number ?

to this database (it is sometimes also called model, but we avoid this term to avoid
confusion with the probabilistic model for learning that we will present in Section 3.1).
Throughout this work, we assume the world is fully-observed and ﬁxed, which is a
realistic assumption for building natural language interfaces to existing databases, but
questionable for modeling the semantics of language in general.
2.3.1 Types and Values. To deﬁne a world, we start by constructing a set of values V. The
exact set of values depend on the domain (we will continue to use US geography as a
running example). Brieﬂy, V contains numbers (e.g., 3 ∈ V), strings (e.g., Washington ∈
V), tuples (e.g., (3, Washington) ∈ V), sets (e.g., {3, Washington} ∈ V), and other higherorder entities.
To be more precise, we construct V recursively. First, deﬁne a set of primitive values
V , which includes the following:

r

r

Numeric values: each value has the form x : t ∈ V , where x ∈ R is a real
number and t ∈ {number, ordinal, percent, length, . . . } is a tag. The
tag allows us to differentiate 3, 3rd, 3%, and 3 miles—this will be
important in Section 2.6.3. We simply write x for the value x : number.
Symbolic values: each value has the form x : t ∈ V , where x is a string
(e.g., Washington) and t ∈ {string, city, state, river, . . . } is a tag.
Again, the tag allows us to differentiate, for example, the entities
Washington : city and Washington : state.

Now we build the full set of values V from the primitive values V . To deﬁne V, we
need a bit more machinery: To avoid logical paradoxes, we construct V in increasing
order of complexity using types (see Carpenter (1998) for a similar construction). The
casual reader can skip this construction without losing any intuition.
Deﬁne the set of types T to be the smallest set that satisﬁes the following properties:
∈T;

1.

The primitive type

2.

The tuple type (t1 , . . . , tk ) ∈ T for each k ≥ 0 and each non-tuple type
ti ∈ T for i = 1, . . . , k; and

3.

The set type {t} ∈ T for each tuple type t ∈ T .

Note that { }, {{ }}, and (( )) are not valid types.
For each type t ∈ T , we construct a corresponding set of values Vt :
1.

For the primitive type t = , the primitive values V have already been
speciﬁed. Note that these types are rather coarse: Primitive values with
different tags are considered to have the same type .

2.

For a tuple type t = (t1 , . . . , tk ), Vt is the cross product of the values of its
component types:
Vt = {(v1 , . . . , vk ) : ∀i, vi ∈ Vti }.

8

(1)

Liang et al.

3.

Learning Dependency-Based Compositional Semantics

For a set type t = {t }, Vt contains all subsets of its element type t :
Vt = {s : s ⊂ Vt }.

(2)

With this last condition, we ensure that all elements of a set must have the
same type. Note that a set is still allowed to have values with different tags
(e.g., {(Washington : city), (Washington : state)} is a valid set, which
might denote the semantics of the utterance things named Washington).
Another distinction is that types are domain-independent whereas tags
tend to be more domain-speciﬁc.
Let V = ∪t∈T Vt be the set of all possible values.
A world maps each predicate to its semantics, which is a set of tuples (see Figure 4
for an example). First, let TTUPLE ⊂ T be the tuple types, which are the ones of the form
(t1 , . . . , tk ) for some k. Let V{TUPLE} denote all the sets of tuples (with the same type):
def

V{TUPLE} =

V{t} .

(3)

t∈TTUPLE

Now we deﬁne a world formally:
Deﬁnition 2 (World)
A world w : P → V{TUPLE} ∪ {V} is a function that maps each non-null predicate p ∈
P\{ø} to a set of tuples w(p) ∈ V{TUPLE} and maps the null predicate ø to the set of all
values (w(ø) = V).
For a set of tuples A with the same arity, let A RITY(A) = |x|, where x ∈ A is arbitrary; if A is empty, then A RITY(A) is undeﬁned. Now for a predicate p ∈ P and world
w, deﬁne A RITYw (p), the arity of predicate p with respect to w, as follows:

A RITYw (p) =

1
if p = ø,
A RITY(w(p)) if p = ø.

(4)

The null predicate has arity 1 by ﬁat; the arity of a non-null predicate p is inherited from
the tuples in w(p).
Remarks. In higher-order logic and lambda calculus, we construct function types and
values, whereas in DCS, we construct tuple types and values. The two are equivalent in
representational power, but this discrepancy does point at the fact that lambda calculus
is based on function application, whereas DCS, as we will see, is based on declarative
constraints. The set type {( , )} in DCS corresponds to the function type → ( →
bool). In DCS, there is no explicit bool type—it is implicitly represented by using sets.
2.3.2 Examples. The world w maps each domain-speciﬁc predicate to a set of tuples
(usually a ﬁnite set backed by a database). For the US geography domain, w has a
predicate that maps to the set of US states (state), another predicate that maps to the

9

Computational Linguistics

Volume ?, Number ?

set of pairs of entities and where they are located (loc), and so on:
w(state) = {(California : state), (Oregon : state), . . . },

(5)

w(loc) = {(San Francisco : city, California : state), . . . }

(6)
(7)

...

To shorten notation, we use state abbreviations (e.g., CA = California : state).
The world w also speciﬁes the semantics of several domain-independent predicates
(think of these as helper functions), which usually correspond to an inﬁnite set of tuples.
Functions are represented in DCS by a set of input-output pairs. For example, the
semantics of the countt predicate (for each type t ∈ T ) contains pairs of sets S and
their cardinalities |S|:
w(countt ) = {(S, |S|) : S ∈ V{(t)} } ∈ V{({(t)},

(8)

)} .

As another example, consider the predicate averaget (for each t ∈ T ), which takes
a set of key-value pairs (with keys of type t) and returns the average value. For notational convenience, we treat an arbitrary set of pairs S as a set-valued function: We let
S1 = {x : (x, y) ∈ S} denote the domain of the function, and abusing notation slightly,
we deﬁne the function S(x) = {y : (x, y) ∈ S} to be the set of values y that co-occur with
the given x. The semantics of averaget contains pairs of sets and their averages:

w(averaget ) =





(S, z) : S ∈ V{(t,

)} , z

= |S1 |−1



|S(x)|−1
x∈S1

y∈S(x)



y  ∈ V{({(t,


)}, )} .

(9)
Similarly, we can deﬁne the semantics of argmint and argmaxt , which each takes a set
of key-value pairs and returns the keys that attain the smallest (largest) value:
w(argmint ) =

(S, z) : S ∈ V{(t,

)} , z

∈ argmin min S(x)

∈ V{({(t,

)},t)} ,

(10)

x∈S1

w(argmaxt ) =

(S, z) : S ∈ V{(t,

)} , z

∈ argmax max S(x)

∈ V{({(t,

)},t)} .

(11)

x∈S1

The extra min and max is needed since S(x) could contain more than one value. We also
impose that w(argmint ) contains only (S, z) such that y is numeric for all (x, y) ∈ S;
thus, argmint denotes a partial function (same for argmaxt ).
These helper functions are monomorphic: For example, countt only computes
cardinalities of sets of type {(t)}. In practice, we mostly operate on sets of primitives (t = ). To reduce notation, we omit t to refer to this version: count = count ,
average = average , etc.
2.4 Semantics of DCS Trees without Mark-Execute (Basic Version)
The semantics or denotation of a DCS tree z with respect to a world w is denoted z w .
First, we deﬁne the semantics of DCS trees with only join relations (Section 2.4.1). In

10

Liang et al.

Learning Dependency-Based Compositional Semantics

this case, a DCS tree encodes a constraint satisfaction problem (CSP); this is important
because it highlights the constraint-based nature of DCS and also naturally leads to a
computationally efﬁcient way of computing denotations (Section 2.4.2). We then allow
DCS trees to have aggregate relations (Section 2.4.3). The fragment of DCS which has
only join and aggregate relations is called basic DCS.
2.4.1 Basic DCS Trees as Constraint Satisfaction Problems. Let z be a DCS tree with
only join relations on its edges. In this case, z encodes a constraint satisfaction problem
(CSP) as follows: For each node x in z, the CSP has a variable with value a(x); the
collection of these values is referred to as an assignment a. The predicates and relations
of z introduce constraints:
1.

a(x) ∈ w(p) for each node x labeled with predicate p ∈ P; and

2.

j
a(x)j = a(y)j for each edge (x, y) labeled with j ∈ R, which says that the
j-th component of a(x) must equal the j -th component of a(y).

We say that an assignment a is feasible if it satisﬁes all the above constraints. Next, for
a node x, deﬁne V (x) = {a(x) : assignment a is feasible} as the set of feasible values
for x—these are the ones which are consistent with at least one feasible assignment.
Finally, we deﬁne the denotation of the DCS tree z with respect to the world w to be
z w = V (x0 ), where x0 is the root node of z.
Figure 3(a) shows an example of a DCS tree. The corresponding CSP has four variables c, m, , s.2 In Figure 3(b), we have written the equivalent lambda calculus formula.
The non-root nodes are existentially quantiﬁed, the root node c is λ-abstracted, and
all constraints introduced by predicates and relations are conjoined. The λ-abstraction
of c represents the fact that the denotation is the set of feasible values for c (note the
equivalence between the boolean function λc.p(c) and the set {c : p(c)}).
Remarks. Note that CSPs only allow existential quantiﬁcation and conjunction. Why did
we choose this particular logical subset as a starting point, rather than allowing universal quantiﬁcation, negation, or disjunction? There seems to be something fundamental
about this subset, which also appears in Discourse Representation Theory (DRT) (Kamp
and Reyle, 1993; Kamp et al., 2005). Brieﬂy, logical forms in DRT are called Discourse
Representation Structures (DRSes), each of which contains (i) a set of existentiallyquantiﬁed discourse referents (variables), (ii) a set of conjoined discourse conditions
(constraints), and (iii) nested DRSes. If we exclude nested DRSes, a DRS is exactly a
CSP.3 The default existential quantiﬁcation and conjunction are quite natural for modeling cross-sentential anaphora: New variables can be added to a DRS and connected to
other variables. Indeed, DRT was originally motivated by these phenomena (see Kamp
and Reyle (1993) for more details).4
Tree-structured CSPs can capture unboundedly complex recursive structures—such
as cities in states that border states that have rivers that. . . . Trees are limited, however, in

2 Technically, the node is c and the variable is a(c), but we use c to denote the variable to simplify notation.
3 Unlike the CSPs corresponding to DCS trees, the CSPs corresponding DRSes need not be tree-structured,
though economical DRT (Bos, 2009) imposes a tree-like restriction on DRSes for computational reasons.
4 DRT started the dynamic semantics tradition where meanings are context-change potentials, a natural
way to capture anaphora. The DCS formalism presented here does not deal with anaphora, so we give it
a purely static semantics.

11

Computational Linguistics

Volume ?, Number ?

that they are unable to capture long-distance dependencies such as those arising from
anaphora. For example, in the phrase a state with a river that traverses its capital, its binds
to state, but this dependence cannot be captured in a tree structure. A solution is to
simply add an edge between the its node and the state node that forces the two nodes
to have the same value. The result still a well-deﬁned CSP, though not a tree-structured
one. The situation would become trickier if we were to integrate the other relations
(aggregate, mark, and execute). We might be able to incorporate some ideas from
Hybrid Logic Dependency Semantics (HLDS) (Baldridge and Kruijff, 2002; White, 2006),
given that hybrid logic extends the tree structures of modal logic with nominals, thereby
allowing a node to freely reference other nodes. In this article, however, we will stick to
trees and leave the full exploration of non-trees for future work.
2.4.2 Computation of Join Relations. So far, we have given a declarative deﬁnition of
the denotation z w of a DCS tree z with only join relations. Now we will show how to
compute z w efﬁciently. Recall that the denotation is the set of feasible values for the
root node. In general, ﬁnding the solution to a CSP is NP-hard, but for trees, we can
exploit dynamic programming (Dechter, 2003). The key is that the denotation of a tree
depends on its subtrees only through their denotations:
m
j

p; j1 : c1 ; · · · ; jm : cm
jm
1

{v : vji = tji , t ∈ ci

= w(p) ∩
w

w }.

(12)

i=1

On the right-hand side of (12), the ﬁrst term w(p) is the set of values that satisfy the
node constraint, and the second term consists of an intersection across all m edges of
{v : vji = tji , t ∈ ci w }, which is the set of values v which satisfy the edge constraint
with respect to some value t for the child ci .
To further ﬂesh out this computation, we express (12) in terms of two operations:
join and project. Join takes a cross product of two sets of tuples and retains the resulting
tuples that match the join constraint:
A

j,j

B = {u + v : u ∈ A, v ∈ B, uj = vj }.

(13)

Project takes a set of tuples and retains a ﬁxed subset of the components:
A[i] = {vi : v ∈ A}.

(14)

The denotation in (12) can now be expressed in terms of these join and project operations:
j

p; j1 : c1 ; · · · ; jm : cm
jm
1

= ((w(p)
w

j1 ,j1

c1

w )[i] · · ·

jm ,jm

cm

w )[i],

(15)

where i = (1, . . . , A RITYw (p)). Projecting onto i retains only components corresponding
to p.
The time complexity for computing the denotation of a DCS tree z w scales linearly
with the number of nodes, but there is also a dependence on the cost of performing the
join and project operations. For details on how we optimize these operations and handle
inﬁnite sets of tuples (for predicates such as count), see Liang (2011).
The denotation of DCS trees is deﬁned in terms of the feasible values of a CSP, and
the recurrence in (15) is only one way of computing this denotation. However, in light

12

Liang et al.

Learning Dependency-Based Compositional Semantics

number of
major cities

average population of
major cities

city in
Oregon or a state bordering Oregon

∗∗
1

∗∗
1

city
1

2
count
1

2
average
1

1
loc
2

1
∗∗

1
∗∗

Σ

Σ

2
contains
1

city
1

population
1

1
major

1
city
1

3
union
1 2
1
∗∗
Σ

Σ

OR

1
major

1
∗∗

state
1
1
border
2
1
OR

(a) Counting

(b) Averaging

(c) Disjunction

Figure 5
Examples of DCS trees that use the aggregate relation (Σ) to (a) compute the cardinality of a set,
(b) take the average over a set, (c) represent a disjunction over two conditions. The aggregate
relation sets the parent node deterministically to the denotation of the child node. Nodes with
the special null predicate ø are represented as empty nodes.

of the extensions to come, we now consider (15) as the actual deﬁnition rather than just
a computational mechanism. It will still be useful to refer to the CSP in order to access
the intuition of using declarative constraints.
2.4.3 Aggregate Relation. Thus far, we have focused on DCS trees that only use join
relations, which are insufﬁcient for capturing higher-order phenomena in language. For
example, consider the phrase number of major cities. Suppose that number corresponds
to the count predicate, and that major cities maps to the DCS tree city; 1 : major .
1
We cannot simply join count with the root of this DCS tree because count needs to be
joined with the set of major cities (the denotation of city; 1 : major ), not just a single
1
city.
We therefore introduce the aggregate relation (Σ) that takes a DCS subtree and reiﬁes
its denotation so that it can be accessed by other nodes in its entirety. Consider a tree
ø; Σ : c , where the root is connected to a child c via Σ. The denotation of the root is
simply the singleton set containing the denotation of c:
ø; Σ : c

w

= {( c

w )}.

(16)

13

Computational Linguistics

Volume ?, Number ?

Figure 5(a) shows the DCS tree for our running example. The denotation of the
middle node is {(s)}, where s is all major cities. Everything above this node is an
ordinary CSP: s constrains the count node, which in turns constrains the root node to
|s|. Figure 5(b) shows another example of using the aggregate relation Σ. Here, the node
right above Σ is constrained to be a set of pairs of major cities and their populations.
The average predicate then computes the desired answer.
To represent logical disjunction in natural language, we use the aggregate relation
and two predicates, union and contains, which are deﬁned in the expected way:
w(union) = {(A, B, C) : C = A ∪ B, A ∈ V{ } , B ∈ V{ } },
w(contains) = {(A, x) : x ∈ A, A ∈ V{ } },

(17)
(18)

where A, B, C ∈ V{ } are sets of primitive values (see Section 2.3.1). Figure 5(c) shows an
example of a disjunctive construction: We use the aggregate relations to construct two
sets, one containing Oregon, and the other containing states bordering Oregon. We take
the union of these two sets; contains takes the set and reads out an element, which
then constrains the city node.
Remarks. A DCS tree that contains only join and aggregate relations can be viewed as a
collection of tree-structured CSPs connected via aggregate relations. The tree structure
still enables us to compute denotations efﬁciently based on the recurrences in (15) and
(16).
Recall that a DCS tree with only join relations is a DRS without nested DRSes. The
aggregate relation corresponds to the abstraction operator in DRT and is one way of
making nested DRSes. It turns out that the abstraction operator is sufﬁcient to obtain
the full representational power of DRT, and subsumes generalized quantiﬁcation and
disjunction constructs in DRT. By analogy, we use the aggregate relation to handle
disjunction (Figure 5(c)) and generalized quantiﬁcation (Section 2.5.6).
DCS restricted to join relations is less expressive than ﬁrst-order logic because it
does not have universal quantiﬁcation, negation, and disjunction. The aggregate relation is analogous to lambda abstraction, and in basic DCS we use the aggregate relation
to implement those basic constructs using higher-order predicates such as not,every,
and union. We can also express logical statements such as generalized quantiﬁcation,
which go beyond ﬁrst-order logic.
2.5 Semantics of DCS Trees with Mark-Execute (Full Version)
Basic DCS includes two types of relations, join and aggregate, but it is already quite
expressive. However, in general, it is not enough just to be able to express the meaning
of a sentence using some logical form; we must be able to derive the logical form
compositionally and simply from the sentence. Consider the superlative construction
most populous city, which has a basic syntactic dependency structure shown in Figure 6(a). Figure 6(b) shows that we can in principle already use a DCS tree with only join
and aggregate relations to express the correct semantics of the superlative construction.
However, note that the two structures are quite divergent—the syntactic head is city and
the semantic head is argmax. This divergence runs counter to a principal desideratum
of DCS, which is to create a transparent interface between coarse syntax and semantics.
In this section, we introduce mark and execute relations, which will allow us use
the DCS tree in Figure 6(c) to represent the semantics associated with Figure 6(a);

14

Liang et al.

Learning Dependency-Based Compositional Semantics

Example: most populous city
city

populous

most

∗∗
1

∗∗
x12

2
argmax
1
1
∗∗

city
1
e
∗∗

1
population

Σ

c

population
1

argmax

1
city
(a) Syntax

(b) Using only join and aggregate

(c) Using mark-execute

Figure 6
Two semantically-equivalent DCS trees are shown in (b) and (c). The DCS tree in (b), which uses
the join and aggregate relations in the basic DCS, does not align well with the syntactic structure
of most populous city (a), and thus is undesirable. The DCS tree in (c), by using the mark-execute
construct, aligns much better, with city rightfully dominating its modiﬁers. The full version of
DCS allows us to construct (c), which is preferable to (b).

these two are more similar than (a) and (b). The focus of this section is on this markexecute construct—using mark and execute relations to give proper semantically-scoped
denotations to syntactically-scoped tree structures.
The basic intuition of the mark-execute construct is as follows: We mark a node
low in the tree with a mark relation; then, higher up in the tree, we invoke it with
a corresponding execute relation (Figure 7). For our example in Figure 6(c), we mark
the population node, which puts the child argmax in a temporary store; when we
execute the city node, we fetch the superlative predicate argmax from the store and
invoke it.
This divergence between syntactic and semantic scope arises in other linguistic contexts besides superlatives such as quantiﬁcation and negation. In each of these cases, the
general template is the same: a syntactic modiﬁer low in the tree needs to have semantic
force higher in the tree. A particularly compelling case of this divergence happens
with quantiﬁer scope ambiguity (e.g., Some river traverses every city.5 ), where the quantiﬁers appear in ﬁxed syntactic positions, but the surface and inverse scope readings
correspond to different semantically-scoped denotations. Analogously, a single syntactic structure involving superlatives can also yield two different semantically-scoped

5 The two meanings are: (i) there is a river x such that x traverses every city; and (ii) for every city x, some
river traverses x.

15

Computational Linguistics

Volume ?, Number ?

∗∗
xi
···

···

···

e|q|c
···
Figure 7
The template for the mark-execute construct. A mark relation (one of E, Q, C) “stores” the
modiﬁer. Then an execute relation (of the form Xi for indices i) higher up “recalls” the modiﬁer
and applies it at the desired semantic point.

denotations—the absolute and relative readings (e.g., state bordering the largest state6 ).
The mark-execute construct provides a uniﬁed framework for dealing all these forms
of divergence between syntactic and semantic scope. See Figures 8 and 9 for concrete
examples of this construct.
2.5.1 Denotations. We now formalize the mark-execute construct. We saw that the markexecute construct appears to act non-locally, putting things in a store and retrieving
them later. This means that if we want the denotation of a DCS tree to only depend
on the denotations of its subtrees, the denotations need to contain more than the set of
feasible values for the root node, as was the case for basic DCS. We need to augment
denotations to include information about all marked nodes, since these can be accessed
by an execute relation higher up in the tree.
More speciﬁcally, let z be a DCS tree and d = z w be its denotation. The denotation
d consists of n columns. The ﬁrst column always corresponds to the root node of z, and
the rest of the columns correspond to non-root marked nodes in z. In the example in
Figure 10, there are two columns, one for the root state node and the other for size
node, which is marked by C. The columns are ordered according to a pre-order traversal
of z, so column 1 always corresponds to the root node. The denotation d contains a set of
arrays d.A, where each array represents a feasible assignment of values to the columns
of d; note that we quantify over non-marked nodes, so they do not correspond to any
column in the denotation. For example, in Figure 10, the ﬁrst array in d.A corresponds to
assigning (OK) to the state node (column 1) and (TX, 2.7e5) to the size node (column
2). If there are no marked nodes, d.A is basically a set of tuples, which corresponds to
a denotation in basic DCS. For each marked node, the denotation d also maintains a
store with information to be retrieved when that marked node is executed. A store σ
for a marked node contains the following: (i) the mark relation σ.r (C in the example),
(ii) the base denotation σ.b which essentially corresponds to denotation of the subtree

6 The two meanings are: (i) a state that borders Alaska (which is the largest state); and (ii) a state with the
highest score, where the score of a state x is the maximum size of any state that x borders (Alaska is
irrelevant here because no states border it).

16

Liang et al.

Learning Dependency-Based Compositional Semantics

California borders which states?

Alaska borders no states.

∗∗

∗∗

x1

x1

border
12

border
12

1
CA

1
state

1
AK

1
state

e

q

∗∗
(a) Extraction (e)

no
(b) Quantiﬁcation (q)

Some river traverses every city.

city traversed by no rivers

∗∗

∗∗

∗∗

x12

x21

x12

traverse
1 2

traverse
1 2

city
1
e

1
river

1
city

1
river

1
city

q

q

q

q

some
every
(surface)

some
every
(inverse)

∗∗

2
traverse
1
1
river
q

(c) Quantiﬁer scope ambiguity (q, q)

no
(d) Quantiﬁcation (q, e)

Figure 8
Examples of DCS trees that use the mark-execute construct with the E and Q mark relations. (a)
The head verb borders, which needs to be returned, has a direct object states modiﬁed by which.
(b) The quantiﬁer no is syntactically dominated by state but needs to take wider scope. (c) Two
quantiﬁers yield two possible readings; we build the same basic structure, marking both
quantiﬁers; the choice of execute relation (X12 versus X21 ) determines the reading. (d) We employ
two mark relations, Q on river for the negation, and E on city to force the quantiﬁer to be
computed for each value of city.

rooted at the marked node excluding the mark relation and its subtree ( size
the example), and (iii) the denotation of the child of the mark relation ( argmax
the example). The store of any unmarked nodes is always empty (σ = ø).

w
w

in
in

Deﬁnition 3 (Denotations)
Let D be the set of denotations, where each denotation d ∈ D consists of

r

a set of arrays d.A, where each array a = [a1 , . . . , an ] ∈ d.A is a sequence of
n tuples for some n ≥ 0; and

17

Computational Linguistics

state bordering
the most states

Volume ?, Number ?

most populous city
∗∗

∗∗

state bordering
more states than Texas
∗∗

x12

x12

x12

city
1
e

state
1
e
1
∗∗
border
2

∗∗

state
1
e
1
∗∗
border
2

1
population
c

1
state

1
state

argmax

c

c

argmax

more
3

(a) Superlative (c)

1
TX
(c) Comparative (c)

(b) Superlative (c)

state bordering
the largest state

Most states’
largest city is major.

∗∗

1
border
2

∗∗

x12

state
1

x1

state
1
e
1
∗∗
border
2

1
∗∗
x12
state
1
e
1
∗∗
size
c

major
x2
city
1 1

1
state
1

1
loc
2

1
size

1
state

c

q

argmax
argmax
(absolute)
(relative)
(d) Superlative scope ambiguity (c)

1
size
c
argmax

most
(e) Quantiﬁcation+Superlative (q, c)

Figure 9
Examples of DCS trees that use the mark-execute construct with the E and C relation. (a,b,c)
Comparatives and superlatives are handled as follows: For each value of the node marked by E,
we compute a number based on the node marked by C; based on this information, a subset of the
values is selected as the possible values of the root node. (d) Analog of quantiﬁer scope
ambiguity for superlatives: The placement of the execute relation determines an absolute versus
relative reading. (e) Interaction between a quantiﬁer and a superlative: The lower execute
relation computes the largest city for each state; the second execute relation invokes most and
enforces that the major constraint holds for the majority of states.

18

Liang et al.

Learning Dependency-Based Compositional Semantics

state
1
1
border
2
1
state
1
1
size
c
argmax

DCS tree

·

w

column 1 column 2
[(OK)
(TX,2.7e5)]
[(NM)
(TX,2.7e5)]
A:
(CA,1.6e5)]
[(NV)
···
···
r:
ø
c
size w
b:
ø
argmax w
c:
ø
Denotation

Figure 10
Example of the denotation for a DCS tree (with the compare relation C). This denotation has two
columns, one for each active node—the root node state and the marked node size.

r

a sequence of n stores d.σ = (d.σ1 , . . . , d.σn ), where each store σ contains a
mark relation σ.r ∈ {E, Q, C, ø}, a base denotation σ.b ∈ D ∪ {ø}, and a
child denotation σ.c ∈ D ∪ {ø}.

Note that denotations are formally deﬁned without reference to DCS trees (just as sets
of tuples were in basic DCS), but it is sometimes useful to refer to the DCS tree that
generates that denotation.
For notational convenience, we write d as A; (r1 , b1 , c1 ); . . . ; (rn , bn , cn ) . Also let
d.ri = d.σi .r, d.bi = d.σi .b, and d.ci = d.σi .c. Let d{σi = x} be the denotation which is
identical to d, except with d.σi = x; d{ri = x}, d{bi = x}, and d{ci = x} are deﬁned
def

analogously. We also deﬁne a project operation for denotations: A; σ [i] = {ai : a ∈
A}; σi . Extending this notation further, we use ø to denote the indices of the non-initial
columns with empty stores (i > 1 such that d.σi = ø). We can then use d[−ø] to represent
projecting away the non-initial columns with empty stores. For the denotation d in
Figure 10, d[1] keeps column 1, d[−ø] keeps both columns, and d[2, −2] swaps the two
columns.
In basic DCS, denotations are sets of tuples, which works quite well for representing the semantics of wh-questions such as What states border Texas? But what about
polar questions such as Does Louisiana border Texas? The denotation should be a simple
boolean value, which basic DCS does not represent explicitly. Using our new denotations, we can represent boolean values explicitly using zero-column structures: true
corresponds to a singleton set containing just the empty array (dT = {[ ]} ) and false is
the empty set (dF = ∅ ).
Having described denotations as n-column structures, we now give the formal
mapping from DCS trees to these structures. As in basic DCS, this mapping is deﬁned
recursively over the structure of the tree. We have a recurrence for each case (the ﬁrst

19

Computational Linguistics

Volume ?, Number ?

line is the base case, and each of the others handles a different edge relation):
p
j
p; e; j : c

w

= {[v] : v ∈ w(p)}; ø ,
=

p; e

w

−ø
j,j

w

c

(19)

[join]

w,

[base case]

(20)

p; e; Σ : c

w

=

p; e

w

−ø
∗,∗

Σ( c

w) ,

[aggregate]

(21)

p; e; Xi : c

w

=

p; e

w

−ø
∗,∗

Xi ( c

w ),

[execute]

(22)

p; e; E : c

w

= M( p; e

w , E,

c

w ),

[extract]

(23)

p; e; C : c

w

= M( p; e

w , C,

c

w ),

[compare]

(24)

p; Q : c; e

w

= M( p; e

w , Q,

c

w ).

[quantify]

(25)

We deﬁne the operations

−ø
j,j , Σ, Xi , M

in the remainder of this section.

2.5.2 Base Case. (19) deﬁnes the denotation for a DCS tree z with a single node with
predicate p. The denotation of z has one column whose arrays correspond to the tuples
w(p); the store for that column is empty.
2.5.3 Join Relations. (20) deﬁnes the recurrence for join relations. On the left-hand side,
j
p; e; j : c is a DCS tree with p at the root, a sequence of edges e followed by a ﬁnal
j
edge with relation j connected to a child DCS tree c. On the right-hand side, we take
the recursively computed denotation of p; e , the DCS tree without the ﬁnal edge, and
perform a join-project-inactive operation (notated −ø ) with the denotation of the child
j,j
DCS tree c.
The join-project-inactive operation joins the arrays of the two denotations (this is the
core of the join operation in basic DCS—see (13)), and then projects away the non-initial
empty columns:7

A; σ

−ø
j,j

A ;σ

= A ; σ + σ [−ø], where

(26)

A = {a + a : a ∈ A, a ∈ A , a1j = a1j }.
We concatenate all arrays a ∈ A with all arrays a ∈ A that satisfy the join condition
a1j = a1j . The sequences of stores are simply concatenated: (σ + σ ). Finally, any noninitial columns with empty stores are projected away by applying ·[−ø].
Note that the join works on column 1; the other columns are carried along for the
ride. As another piece of convenient notation, we use ∗ to represent all components, so
−ø
∗,∗ imposes the join condition that the entire tuple has to agree (a1 = a1 ).
2.5.4 Aggregate Relations. (21) deﬁnes the recurrence for aggregate relations. Recall
that in basic DCS, aggregate (16) simply takes the denotation (a set of tuples) and puts it
into a set. Now, the denotation is not just a set, so we need to generalize this operation.
Speciﬁcally, the aggregate operation applied to a denotation forms a set out of the tuples

7 The join and project operations are taken from relational algebra.

20

Liang et al.

Learning Dependency-Based Compositional Semantics

column 1
column 2
[(FL)
(AL)]
A: [(GA)
(AL)]
···
···
r:
ø
e
b:
ø
{[(AL)], [(AK)], . . . }; ø
c:
ø
ø

state
1
1
border
2
1
state

·

w

e
∗∗

Σ (·)
∗∗
Σ
state
1
1
border
2
1
state
e

·

w

column 1
column 2
[({(FL), (GA), (MS), (TN)})
(AL)]
A:
[({})
(AK)]
···
···
r:
ø
e
b:
ø
{[(AL)], [(AK)], . . . }; ø
c:
ø
ø

∗∗

DCS tree

Denotation

Figure 11
An example of applying the aggregate operation, which takes a denotation and aggregates the
values in column 1 for every setting of the other columns. The base denotations (b) are used to
put in {} for values that do not appear in A. (in this example, AK, corresponding to the fact that
Alaska does not border any states).

in the ﬁrst column for each setting of the rest of the columns:
Σ ( A; σ ) = A ∪ A ; σ ,

(27)

A = {[S(a), a2 , . . . , an ] : a ∈ A},
S(a) = {a1 : [a1 , a2 , . . . , an ] ∈ A},
A = {[∅, a2 , . . . , an ] : ∀i ∈ {2, . . . , n}, [ai ] ∈ σi .b.A[1], ¬∃a1 , a ∈ A}.
The aggregate operation takes the set of arrays A and produces two sets of arrays, A
and A , which are unioned (note that the stores do not change). The set A is the one that
ﬁrst comes to mind: For every setting of a2 , . . . , an , we construct S(a), the set of tuples
a1 in the ﬁrst column which co-occur with a2 , . . . , an in A.
However, there is another case: what happens to settings of a2 , . . . , an that do not
co-occur with any value of a1 in A? Then, S(a) = ∅, but note that A by construction will
not have the desired array [∅, a2 , . . . , an ]. As a concrete example, suppose A = ∅ and we
have one column (n = 1). Then A = ∅, rather than the desired {[∅]}.
Fixing this problem is slightly tricky. There are an inﬁnite number of a2 , . . . , an
which do not co-occur with any a1 in A, so for which ones do we actually include
[∅, a2 , . . . , an ]? Certainly, the answer to this question cannot come from A, so it must
come from the stores. In particular, for each column i ∈ {2, . . . , n}, we have conveniently
stored a base denotation σi .b. We consider any ai that occurs in column 1 of the arrays

21

Computational Linguistics

Volume ?, Number ?

state

·

column 1
[(AL)]
A: [(AK)]
···
r:
ø
b:
ø
c:
ø

w

M(·, q, every

A:

state
q
every

DCS tree

·

w

r:
b:
c:

w)

column 1
[(AL)]
[(AK)]
···
q
{[(AL)], [(AK)], . . . }; ø
every w
Denotation

Figure 12
An example of applying the mark operation, which takes a denotation and modiﬁes the store of
the column 1. This information is used by other operations such as aggregate and execute.

of this base denotation ([ai ] ∈ σi .b.A[1]). For this a2 , . . . , an , we include [∅, a2 , . . . , an ] in
A as long as a2 , . . . , an does not co-occur with any a1 . An example is given in Figure 11.
The reason for storing base denotations is thus partially revealed: The arrays represent feasible values of a CSP and can only contain positive information. When we
aggregate, we need to access possibly empty sets of feasible values—a kind of negative
information, which can only be recovered from the base denotations.
2.5.5 Mark Relations. (23), (24), and (25) each processes a different mark relation. We
deﬁne a general mark operation, M(d, r, c) which takes a denotation d, a mark relation
r ∈ {E, Q, C} and a child denotation c, and sets the store of d in column 1 to be (r, d, c):
M(d, r, c) = d{r1 = r, b1 = d, c1 = c}.

(28)

The base denotation of the ﬁrst column b1 is set to the current denotation d. This, in
some sense, creates a snapshot of the current denotation. Figure 12 shows an example
of the mark operation.
2.5.6 Execute Relations. (22) deﬁnes the denotation of a DCS tree where the last edge of
the root is an execute relation. Similar to the aggregate case (21), we recurse on the DCS
tree without the last edge ( p; e ) and then join it to the result of applying the execute
operation Xi to the denotation of the child ( c w ).
The execute operation Xi is the most intricate part of DCS and is what does the
heavy lifting. The operation is parametrized by a sequence of distinct indices i which
speciﬁes the order in which the columns should be processed. Speciﬁcally, i indexes into
the subsequence of columns with non-empty stores. We then process this subsequence

22

Liang et al.

Learning Dependency-Based Compositional Semantics

border
12
1
CA

1
state

·

w

e
∗∗

column 1 column 2
[(CA,AZ)
(AZ)]
(NV)]
A: [(CA,NV)
[(CA,OR)
(OR)]
r:
ø
e
state w
b:
ø
c:
ø
ø

X1 (·)
∗∗
x1
border
12
1
CA

1
state
e
∗∗

DCS tree

·

w

column 1
(AZ)
A: (NV)
(OR)
r:
ø
b:
ø
c:
ø
Denotation

Figure 13
An example of applying the execute operation on column 1 with the extract relation E. The
denotation prior to execution consists of two columns: column 1 corresponds to the border
node; column 2 to the state node. The join relations and predicates CA and state constrain the
arrays A in the denotation to include only the states that border California. After execution, the
non-marked column 1 is projected away, leaving only the state column with its store emptied.

of columns in reverse order, where processing a column means performing some operations depending on the stored relation in that column. For example, suppose that
columns 2 and 3 are the only non-empty columns. Then X12 processes column 3 before
column 2. On the other hand, X21 processes column 2 before column 3. We ﬁrst deﬁne
the execute operation Xi for a single column i. There are three distinct cases, depending
on the relation stored in column i:
Extraction. For a denotation d with the extract relation E in column i, executing Xi (d)
involves three steps: (i) moving column i to before column 1 (·[i, −i]), (ii) projecting
away non-initial empty columns (·[−ø]), and (iii) removing the store (·{σ1 = ø}):
Xi (d) = d[i, −i][−ø]{σ1 = ø}

if d.ri = E.

(29)

An example is given in Figure 13. There are two main uses of extraction:
1.

By default, the denotation of a DCS tree is the set of feasible values of the
root node (which occupies column 1). To return the set of feasible values of
another node, we mark that node with E. Upon execution, the feasible
values of that node move into column 1. Extraction can be used to handle
in situ questions (see Figure 8(a)).

2.

Unmarked nodes (those that do not have an edge with a mark relation) are
existentially quantiﬁed and have narrower scope than all marked nodes.

23

Computational Linguistics

column 1 column 2

border
12
1
AK

Volume ?, Number ?

1
state

·

w

q
no

A:
r:
b:
c:

ø
ø
ø

∗∗

q
state w
no w

[−1]
no
1 2

∗∗

1
∗∗

x1

X1 (·)

border
12
1
AK

∗∗

1
state

border
12
1
AK

Σ

“

q

x1

·

1
state

w

A: [ ]
r:
b:
c:

1
∗∗

no

”

Σ

state

∗∗
x1
border
12
1
AK

1
state
e
∗∗

q
no

DCS tree

Denotation

(a) Execute a quantify relation q

(b) Execute “expands the DCS tree”

Figure 14
(a) An example of applying the execute operation on column i with the quantify relation Q.
Before executing, note that A = {} (because Alaska does not border any states). The restrictor (A)
is the set of all states, and the nuclear scope (B) is empty. Since the pair (A, B) does exists in
w(no), the ﬁnal denotation, is {[ ]} (which represents true). (b) Although the execute operation
actually works on the denotation, think of it in terms of expanding the DCS tree. We introduce
an extra projection relation [−1], which projects away the ﬁrst column of the child subtree’s
denotation.

Therefore, we can make a node x have wider scope than another node y by
marking x (with E) and executing y before x (see Figure 8(d,e) for
examples). The extract relation E (in fact, any mark relation) signiﬁes that
we want to control the scope of a node, and the execute relation allows us
to set that scope.
Generalized Quantiﬁcation. Generalized quantiﬁers are predicates on two sets, a restrictor
A and a nuclear scope B. For example,
w(some) = {(A, B) : A ∩ B > 0},
w(every) = {(A, B) : A ⊂ B},

(31)

w(no) = {(A, B) : A ∩ B = ∅},
w(most) = {(A, B) : |A ∩ B| >

(30)

1
|A|}.
2

(32)
(33)

We think of the quantiﬁer as a modiﬁer which always appears as the child of a Q relation;
the restrictor is the parent. For example, in Figure 8(b), no corresponds to the quantiﬁer
and state corresponds to the restrictor. The nuclear scope should be the set of all states

24

Liang et al.

Learning Dependency-Based Compositional Semantics

that Alaska borders. More generally, the nuclear scope is the set of feasible values of the
restrictor node with respect to the CSP that includes all nodes between the mark and
execute relations. The restrictor is also the set of feasible values of the restrictor node,
but with respect to the CSP corresponding to the subtree rooted at that node.8
We implement generalized quantiﬁers as follows: Let d be a denotation and suppose
we are executing column i. We ﬁrst construct a denotation for the restrictor dA and a
denotation for the nuclear scope dB . For the restrictor, we take the base denotation in
column i (d.bi )—remember that the base denotation represents a snapshot of the restrictor node before the nuclear scope constraints are added. For the nuclear scope, we take
the complete denotation d (which includes the nuclear scope constraints) and extract
column i (d[i, −i][−ø]{σ1 = ø}—see (29)). We then construct dA and dB by applying the
aggregate operation to each. Finally, we join these sets with the quantiﬁer denotation,
stored in d.ci :
Xi (d) =

d.ci

−ø
1,1

dA

−ø
2,1

dB [−1]

if d.ri = Q, where

(34)

dA = Σ (d.bi ) ,

(35)

dB = Σ (d[i, −i][−ø]{σ1 = ø}) .

(36)

When there is one quantiﬁer, think of the execute relation as performing a syntactic
rewriting operation, as shown in Figure 14(b). For more complex cases, we must defer
to (34).
Figure 8(c) shows an example with two interacting quantiﬁers. The denotation of
the DCS tree before execution is the same in both readings, as shown in Figure 15. The
quantiﬁer scope ambiguity is resolved by the choice of execute relation: X12 gives the
surface scope reading, X21 gives the inverse scope reading.

traverse
1 2
1
river

1
city

q

q

some

every

DCS tree

·

w

column 1
column 2 column 3
[(Hudson,NYC)
(Hudson)
(NYC)]
A: [(Columbia,Portland) (Columbia) (Portland)]
···
···
···
r:
ø
q
q
river w
city w
b:
ø
some w
every w
c:
ø
Denotation

Figure 15
Denotation of Figure 8(c) before the execute relation is applied.

Figure 8(d) shows how extraction and quantiﬁcation work together. First, the no
quantiﬁer is processed for each city, which is an unprocessed marked node. Here, the
extract relation is a technical trick to give city wider scope.

8 Deﬁned this way, we can only handle conservative quantiﬁers, since the nuclear scope will always be a
subset of the restrictor. This design decision is inspired by DRT, where it provides a way of modeling
donkey anaphora. We are not treating anaphora in this work, but we can handle it by allowing pronouns
in the nuclear scope to create anaphoric edges into nodes in the restrictor. These constraints naturally
propagate through the nuclear scope’s CSP without affecting the restrictor.

25

Computational Linguistics

state
1
e
1
∗∗
border
2
1
state
1

·

w

1
size
c
argmax

Volume ?, Number ?

column 1 column 2
(TX,267K)]
[(AR)
(TX,267K)]
[(LA)
(TX,267K)]
[(NM)
A:
[(OK)
(TX,267K)]
[(NV)
(CA,158K)]
···
···
r:
ø
c
size w
b:
ø
argmax w
c:
ø

X12 (·)

∗∗
1
2
argmax
1
1
∗∗
∗∗

Σ

x12

∗∗

state
1
e
1
∗∗
border
2
1
state
1

∗∗
x12
state
1
e
1
∗∗
border
2

·

1
state
1
1
size

w

column 1
[(AR)]
[(LA)]
A:
[(NM)]
[(OK)]
r:
ø
b:
ø
c:
ø

1
size
c
argmax

+2,1
∗∗
2

“

”

1
∗∗
x2
state
1
e
1
∗∗
border
2
1
state
1
1
size
e
∗∗

c
argmax

DCS tree

Denotation

(a) Execute a compare relation c

(b) Execute “expands the DCS tree”

Figure 16
(a) Executing the compare relation C for an example superlative construction (relative reading of
state bordering the largest state from Figure 9(d)). Before executing, column 1 contains the entity to
compare, and column 2 contains the degree information, of which only the second component is
relevant. After executing, the resulting denotation contains a single column with only the entities
that obtain the highest degree (in this case, the states that border Texas) (b) For this example,
think of the execute operation as expanding the original DCS tree, although the execute
operation actually works on the denotation, not the DCS tree. The expanded DCS tree has the
same denotation as the original DCS tree, and syntactically captures the essence of the
execute-compare operation. Going through the relations of the expanded DCS tree from bottom
to top: The X2 relation swaps columns 1 and 2; the join relation keeps only the second
component ((TX, 267K) becomes (267K)); +2,1 concatenates columns 2 and 1 ([(267K), (AR)]
becomes [(AR, 267K)]); Σ aggregates these tuples into a set; argmax operates on this set and
returns the elements.

Comparatives and Superlatives. Comparative and superlative constructions involve comparing entities, and for this, we rely on a set S of entity-degree pairs (x, y), where x is an
entity and y is a numeric degree. Recall that we can treat S as a function, which maps
an entity x to the set of degrees S(x) associated with x. Note that this set can contain

26

Liang et al.

Learning Dependency-Based Compositional Semantics

multiple degrees. For example, in the relative reading of state bordering the largest state,
we would have a degree for the size of each neighboring state.
Superlatives use the argmax and argmin predicates, which are deﬁned in Section 2.3. Comparatives use the more and less predicates: w(more) contains triples
(S, x, y), where x is “more than” y as measured by S; w(less) is deﬁned analogously:
w(more) = {(S, x, y) : max S(x) > max S(y)},

(37)

w(less) = {(S, x, y) : min S(x) < min S(y)}.

(38)

We use the same mark relation C for both comparative and superlative constructions. In terms of the DCS tree, there are three key parts: (i) the root x, which corresponds
to the entity to be compared, (ii) the child c of a C relation, which corresponds to the
comparative or superlative predicate, and (iii) c’s parent p, which contains the “degree
information” (which will be described later) used for comparison. We assume that the
root is marked (usually with a relation E). This forces us to compute a comparison
degree for each value of the root node. In terms of the denotation d corresponding to the
DCS tree prior to execution, the entity to be compared occurs in column 1 of the arrays
d.A, the degree information occurs in column i of the arrays d.A, and the denotation of
the comparative or superlative predicate itself is the child denotation at column i (d.ci ).
First, we deﬁne a concatenating function +i (d), which combines the columns i of d
by concatenating the corresponding tuples of each array in d.A:
+i ( A; σ ) = A ; σ , where

(39)

A = {a(1...i1 )\i + [ai1 + · · · + ai|i| ] + a(i1 ...n)\i : a ∈ A}
σ = σ(1...i1 )\i + [σi1 ] + σ(i1 ...n)\i .
Note that the store of column i1 is kept and the others are discarded. As an example:
+2,1 ( {[(1), (2), (3)], [(4), (5), (6)]}; σ1 , σ2 , σ3 ) = {[(2, 1), (3)], [(5, 4), (6)]}; σ2 , σ3 .
(40)
We ﬁrst create a denotation d where column i, which contains the degree information, is extracted to column 1 (and thus column 2 corresponds to the entity to be
compared). Next, we create a denotation dS whose column 1 contains a set of entitydegree pairs. There are two types of degree information:
1.

Suppose the degree information has arity 2 (A RITY(d.A[i]) = 2). This
occurs, for example, in most populous city (see Figure 9(b)), where column i
is the population node. In this case, we simply set the degree to the
second component of population by projection ( ø w −ø d ). Now
1,2
columns 1 and 2 contain the degrees and entities, respectively. We
concatenate columns 2 and 1 (+2,1 (·)) and aggregate to produce a
denotation dS which contains the set of entity-degree pairs in column 1.

2.

Suppose the degree information has arity 1 (A RITY(d.A[i]) = 1). This
occurs, for example, in state bordering the most states (see Figure 9(a)), where
column i is the lower marked state node. In this case, the degree of an
entity from column 2 is the number of different values that column 1 can

27

Computational Linguistics

Volume ?, Number ?

take. To compute this, aggregate the set of values (Σ (d )) and apply the
count predicate. Now with the degrees and entities in columns 1 and 2,
respectively, we concatenate the columns and aggregate again to obtain dS .
Having constructed dS , we simply apply the comparative/superlative predicate which
has been patiently waiting in d.ci . Finally, the store of d’s column 1 was destroyed by the
concatenation operation +2,1 (() ·), so we must restore it with ·{σ1 = d.σ1 }. The complete
operation is as follows:
Xi (d) =
dS =

ø

w

Σ +2,1
Σ +2,1

−ø
1,2

d.ci
ø
ø

w
w

−ø
1,1
−ø
1,2
−ø
1,2

d = d[i, −i][−ø]{σ1 = ø}.

dS

{σ1 = d.σ1 } if d.σi = C, d.σ1 = ø, where

d
count

w

−ø
1,1

Σ (d )

(41)

if A RITY(d.A[i]) = 2
if A RITY(d.A[i]) = 1,
(42)
(43)

An example of executing the C relation is shown in Figure 16(a). As with executing a
Q relation, for simple cases, we can think of executing a C relation as expanding a DCS
tree, as shown in Figure 16(b).
Figure 9(a) and Figure 9(b) show examples of superlative constructions with the arity 1 and arity 2 types of degree information, respectively. Figure 9(c) shows an example
of an comparative construction. Comparatives and superlatives use the same machinery, differing only in the predicate: argmax versus more; 3 : TX (more than Texas). But
1
both predicates have the same template behavior: Each takes a set of entity-degree pairs
and returns any entity satisfying some property. For argmax, the property is obtaining
the highest degree; for more, it is having a degree higher than a threshold. We can
handle generalized superlatives (the ﬁve largest or the ﬁfth largest or the 5% largest) as well
by swapping in a different predicate; the execution mechanisms deﬁned in (41) remain
the same.
We saw that the mark-execute machinery allows decisions regarding quantiﬁer
scope to made in a clean and modular fashion. Superlatives also have scope ambiguities
in the form of absolute versus relative readings. Consider the example in Figure 9(d). In
the absolute reading, we ﬁrst compute the superlative in a narrow scope (the largest state
is Alaska), and then connect it with the rest of the phrase, resulting in the empty set
(since no states border Alaska). In the relative reading, we consider the ﬁrst state as the
entity we want to compare, and its degree is the size of a neighboring state. In this case,
the lower state node cannot be set to Alaska because there are no states bordering
it. The result is therefore any state that borders Texas (the largest state that does have
neighbors). The two DCS trees in Figure 9(d) show that we can naturally account for this
form of superlative ambiguity based on where the scope-determining execute relation
is placed without drastically changing the underlying tree structure.
Remarks. These scope divergence issues are not speciﬁc to DCS—every serious semantic
formalism must address them. Generative grammar employs quantiﬁer raising to move
the quantiﬁer from its original syntactic position up to the desired semantic position
before semantic interpretation even occurs (Heim and Kratzer, 1998). Other mechanisms
such as Montague’s quantifying in (Montague, 1973), Cooper storage (Cooper, 1975),
and Carpenter’s scoping constructor (Carpenter, 1998) handle scope divergence during
semantic interpretation. Roughly speaking, these mechanisms delay application of a

28

Liang et al.

Learning Dependency-Based Compositional Semantics

quantiﬁer, “marking” its spot with a dummy pronoun (as in Montague’s quantifying
in) or putting it in a store (as in Cooper storage), and then “executing” the quantiﬁer at
a later point in the derivation either by performing a variable substitution or retrieving it
from the store. Continuations from programming languages is another solution (Barker,
2002; Shan, 2004), which sets the semantics of a quantiﬁer to be a function from its
continuation (which captures all the semantic content of the clause minus the quantiﬁer) to the ﬁnal denotation of the clause. Intuitively, continuations reverse the normal
evaluation order, allowing a quantiﬁer be remain in situ but still outscope the rest of the
clause. In fact, the mark and execute relations of DCS are analogous to the shift and reset
operators used in continuations. One of the challenges with allowing ﬂexible scope is
that free variables can yield invalid scopings, a well-known issue with Cooper storage
that the continuation-based approach solves. Invalid scopings are ﬁltered out by the
construction mechanism (Section 2.6).
One difference between mark-execute in DCS and many other mechanisms is that
DCS trees (which contain mark and execute relations) are the ﬁnal logical forms—the
handling of scope divergence occurs in the computing their denotations. The analog
in the other mechanisms resides in the construction mechanism—the actually ﬁnal
logical form is quite simple.9 Therefore, we have essentially pushed the inevitable
complexity from the construction mechanism into the semantics of the logical from.
This is a conscious design decision: We want our construction mechanism which maps
natural language to logical form to be simple and not burdened with complex linguistic
issues, for our focus is on learning this mapping. Unfortunately, the denotation of our
logical forms (Section 2.5.1) do become more complex than those of lambda calculus
expressions, but we believe this is a reasonable tradeoff to make for our particular
application.
2.6 Construction Mechanism
We have thus far deﬁned the syntax (Section 2.2) and semantics (Section 2.5) of DCS
trees, but we have only vaguely hinted at how these DCS trees might be connected
to natural language utterances by appealing to idealized examples. In this section, we
formally deﬁne the construction mechanism for DCS, which takes an utterance x and
produces a set of DCS trees ZL (x).
Since we motivated DCS trees based on dependency syntax, it might be tempting
to take a dependency parse tree of the utterance, replace the words with predicates,
and attach some relations on the edges to produce a DCS tree. To a ﬁrst approximation,
this is what we will do, but we need to be a bit more ﬂexible for several reasons: (i)
some nodes in the DCS tree do not have predicates (e.g., children of a E relation or
parent of an Xi relation); (ii) nodes have predicates that do not correspond to words
(e.g., in California cities, there is a implicit loc predicate that bridges CA and city);
(iii) some words might not correspond to any predicates in our world (e.g., please); and
(iv) the DCS tree might not always be aligned with the syntactic structure depending
on which syntactic formalism one ascribes to. While syntax was the inspiration for the
DCS formalism, we will not actually use it in construction.
It is also worth stressing the purpose of the construction mechanism. In linguistics,
the purpose of the construction mechanism is to try to generate the exact set of valid

9 In the continuation-based approach, this difference corresponds to the difference between assigning a
denotational versus an operational semantics.

29

Computational Linguistics

Volume ?, Number ?

logical forms for a sentence. We view the construction mechanism instead as simply a
way of creating a set of candidate logical forms. A separate step deﬁnes a distribution
over this set to favor certain logical forms over others. The construction mechanism
should therefore simply overapproximate the set of logical forms. Linguistic constraints
which are normally encoded in the construction mechanism (for example, in CCG,
that the disharmonic pair S/NP and S\NP cannot be coordinated, or that non-indeﬁnite
quantiﬁers cannot extend their scope beyond clause boundaries) would be instead
encoded as features (Section 3.1.1). Since feature weights are estimated from data, one
can view our approach as automatically learning the linguistic constraints relevant to
our end task.
2.6.1 Lexical Triggers. The construction mechanism assumes a ﬁxed set of lexical triggers
L. Each trigger is a pair (s, p), where s is a sequence of words (usually one) and p is a
predicate (e.g., s = California and p = CA). We use L(s) to denote the set of predicates p
triggered by s ((s, p) ∈ L). We should think of the lexical triggers L not as pinning down
the precise predicate for each word, but rather producing an overapproximation. For
example, L might contain {(city, city), (city, state), (city, river), . . . }, reﬂecting our
initial ignorance prior to learning.
We also deﬁne a set of trace predicates L( ), which can be introduced without an
overt lexical element. Their name is inspired by trace/null elements in syntax, but they
serve a more practical rather than a theoretical role here. As we shall see in Section 2.6.2,
trace predicates provide more ﬂexibility in the constructing logical forms, allowing us
to insert a predicate based on the partial logical form constructed thus far and assess its
compatibility with the words afterwards (based on features), rather than insisting on a
purely lexically-driven formalism. Section 4.1.3 describes the lexical triggers and trace
predicates that we use in our experiments.
2.6.2 Recursive Construction of DCS Trees. Given a set of lexical triggers L, we will
now describe a recursive mechanism for mapping an utterance x = (x1 , . . . , xn ) to
ZL (x), a set of candidate DCS trees for x. The basic approach is reminiscent of projective
labeled dependency parsing: For each span i..j of the utterance, we build a set of trees
Ci,j (x). The set of trees for the span 0..n is the ﬁnal result:
ZL (x) = C0,n (x).

(44)

Each set of DCS trees Ci,j (x) is constructed recursively by combining the trees of
its subspans Ci,k (x) and Ck ,j (x) for each pair of split points k, k (words between k and
k are ignored). These combinations are then augmented via a function A and ﬁltered
via a function F ; these functions will be speciﬁed later. Formally, Ci,j (x) is deﬁned
recursively as follows:
Ci,j (x) = F A { p

i..j

: p ∈ L(xi+1..j )} ∪

T2 (a, b))

.

i≤k≤k <j
a∈Ci,k (x)
b∈Ck ,j (x)

This recurrence has two parts:

r

30

The base case: we take the phrase (sequence of words) over span i..j and
look up the set of predicates p in the set of lexical triggers. For each

(45)

Liang et al.

Learning Dependency-Based Compositional Semantics

Ci,j (x)
city
1 1
1
population
c
argmax
population

1
loc
2
1
CA
city
1

c

1
loc
2

argmax

1
CA

Ci,k (x)

x:

i

most populous

Ck ,j (x)

k=k

city in California

j

Figure 17
Shows an example of the recursive construction of Ci,j (x), a set of DCS trees for span i..j.

predicate, we construct a one-node DCS tree. We also extend the deﬁnition
of DCS trees in Section 2.2 to allow each node to store the indices of the
span i..j that triggered the predicate at that node; this is denoted by p i..j .
This span information will be useful in Section 3.1.1, where we will need to
talk about how an utterance x is aligned with a DCS tree z.

r

The recursive case: T1 (a, b), which we will deﬁne shortly, that takes two
DCS trees, a and b, and returns a set of new DCS trees formed by
combining a and b. Figure 17 shows this recurrence graphically.

We now focus on how to combine two DCS trees. Deﬁne Td (a, b) as the set of DCS
trees that result by making either a or b the root and connecting the other via a chain
of relations and at most d − 1 trace predicates (d is a small integer that keeps the set of
DCS trees manageable):
Td (a, b) = Td (a, b) ∪ Td (b, a),

(46)

Here, Td (a, b) is the set of DCS trees where a is the root; for Td (a, b), b is the root. The
former is deﬁned recursively as follows:
T0 (a, b) = ∅,

(47)
{ a.p; a.e; r : b , a.p; a.e; r : Σ : b } ∪ Td−1 (a, p; r : b ).

Td (a, b) =
r∈R
p∈L( )

First, we consider all possible relations r ∈ R and try appending an edge to a with
relation r and child b ( a.p; a.e; r : b ); an aggregate relation Σ can be inserted in addi-

31

Computational Linguistics

Volume ?, Number ?

a = city
b = state
T1 (a, b)
city
1

city
1

1
state

1
∗∗

city

T1 (a, b)

city
1

state

Σ

city
1

1
loc
2

q

city
1
2
loc
1

1
border
2

1
1
state state

state

1
state

···

state state state state state state · · ·
1
1
1
1
1
q
1
1
1
2
1
city
∗∗
city
loc
loc border
2
1
2
Σ
1
1
1
city
city city
city

Figure 18
Given two DCS trees, a and b, T1 (a, b) and T1 (a, b) are the two sets of DCS trees formed by
combining a and b with a at the root and b at the root, respectively; one trace predicate can be
inserted in between. In this example, the DCS trees which survive ﬁltering (Section 2.6.3) are
shown.

tion ( a.p; a.e; r : Σ : b ). Of course, R contains an inﬁnite number of join and execute
relations, but only a small ﬁnite number of them make sense: we consider join relations
j
j only for j ∈ {1, . . . , A RITY (a.p)} and j ∈ {1, . . . , A RITY (b.p)}, and execute relations X i
for which i does not contain indices larger than the number of columns of b w . Next,
we further consider all possible trace predicates p ∈ L( ), and recursively try to connect
a with the intermediate p; r : b , now allowing d − 1 additional predicates. See Figure 18
for an example. In the other direction, Td is deﬁned similarly:
T0 (a, b) = ∅,
Td (a, b) =

(48)
{ b.p; r : a; b.e , b.p; r : Σ : a ; b.e } ∪ Td−1 (a, p; r : b ).

r∈R
p∈L( )

Inserting trace predicates allows us to build logical forms with more predicates
than are explicitly triggered by the words. This ability is useful for several reasons.
Sometimes, there is a predicate not overtly expressed, especially in noun compounds
(e.g., California cities). For semantically light words such as prepositions (e.g., for) it
is difﬁcult to enumerate all the possible predicates that it might trigger; it is simpler
computationally to try to insert trace predicates. We can even omit lexical triggers for
transitive verbs such as border because the corresponding predicate border can be
inserted as a trace predicate.
The function T1 (a, b) connects two DCS trees via a path of relations and trace predicates. The augmentation function A adds additional relations (speciﬁcally, E and/or Xi )
on a single DCS tree:
A(Z) =

{z, z; E : ø , Xi : z , Xi : z; E : ø
z∈Z
X i ∈R

32

},

(49)

Liang et al.

Learning Dependency-Based Compositional Semantics

2.6.3 Filtering using Abstract Interpretation. The construction procedure as described
thus far is extremely permissive, generating many DCS trees which are obviously
wrong—for example, state; 1 : >; 2 3 , which tries to compare a state with the num1
1
ber 3. There is nothing wrong this expression syntactically: its denotation will simply be
empty (with respect to the world). But semantically, this DCS tree is anomalous.
We cannot simply just discard DCS trees with empty denotations, because we
would incorrectly rule out state; 1 : border; 2 AK . The difference here is that even
1
1
though the denotation is empty in this world, it is possible that it might not be empty
in a different world where history and geology took another turn, whereas it is simply
impossible to compare cities and numbers.
Now let us quickly ﬂesh out this intuition before falling into a philosophical discussion about possible worlds. Given a world w, we deﬁne an abstract world α(w),
to be described shortly. We compute the denotation of a DCS tree z with respect to
this abstract world. If at any point in the computation we create an empty denotation,
we judge z to be impossible and throw it away. The ﬁltering function F is deﬁned as
follows:10
F (Z) = {z ∈ Z : ∀z subtree of z , z

α(w) .A

= ∅}.

(50)

Now we need to deﬁne the abstract world α(w). The intuition is to map concrete values to abstract values: 3 : length becomes ∗ : length, Oregon : state becomes
∗ : state, and in general, primitive value x : t becomes ∗ : t. We perform abstraction
on tuples componentwise, so that (Oregon : state, 3 : length) becomes (∗ : state, ∗ :
length). Our abstraction of sets is slightly more complex: the empty set maps to the
empty set, a set containing values all with the same abstract value a maps to {a}, and a
set containing values with more than one abstract value maps to a {MIXED}. Finally, a
world maps each predicate onto a set of (concrete) tuples; the corresponding abstract
world maps each predicate onto the set of abstract tuples. Formally, the abstraction
function is deﬁned as follows:
α(x : t) = ∗ : t,

[primitive values]
(51)
[tuples]
(52)

α((v1 , . . . , vn )) = (α(v1 ), . . . , α(vn )),

∅

α(A) = {α(x) : x ∈ A}


{MIXED}

if A = ∅,
if |{α(x) : x ∈ A}| = 1,
otherwise.

[sets]
(53)

α(w) = λp.{α(x) : x ∈ w(p)}.

[worlds]
(54)

10 To further reduce the search space, F imposes a few additional constraints, e.g., limiting the number of
columns to 2, and only allowing trace predicates between arity 1 predicates.

33

Computational Linguistics

Volume ?, Number ?

Example: states that border Texas
λx.state(x) ∧ border(x, TX)
<

state
1
1
border
2

λf.λx.f (x) ∧ border(x, TX)
>
λx.border(x, TX)

1

>
λx.state(x) λg.λf.λx.f (x) ∧ g(x) λy.λx.border(x, y)
states

that

border

TX

TX
Texas

states

(a) CCG construction

that border Texas

(b) DCS construction

Figure 19
Comparison between the construction mechanisms of CCG and DCS. There are three principal
differences: First, in CCG, words are mapped onto a lambda calculus expression; in DCS, words
are just mapped onto a predicate. Second, in CCG, lambda calculus expressions are built by
combining (e.g., via function application) two smaller expressions; in DCS, trees are combined
by inserting relations (and possibly other predicates between them). Third, in CCG, all words
map to a logical expression; in DCS, only a small subset of words (e.g., state and Texas) map to
predicates; the rest participate in features for scoring DCS trees.

As an example, the abstract world might look like this:
α(w)(>) = {(∗ : number, ∗ : number, ∗ : number), (∗ : length, ∗ : length, ∗ : length), . . . },
(55)
α(w)(state) = {(∗ : state)},

(56)

α(w)(AK) = {(∗ : state)},

(57)

α(w)(border) = {(∗ : state, ∗ : state)}.

(58)

Now returning our motivating example at the beginning of this section, we see that the bad DCS tree has an empty abstract denotation
state; 1 : >; 2 3
1
1
α(w) = ∅; ø . The good DCS tree has an non-empty abstract
denotation: state; 1 : border; 2 AK
1
1
α(w) = {(∗ : state)}; ø , as desired.
Remarks. Computing denotations on an abstract world is called abstract interpretation
(Cousot and Cousot, 1977) and is very powerful framework commonly used in the
programming languages community. The idea is to obtain information about a program
(in our case, a DCS tree) without running it concretely, but rather just by running it
abstractly. It is closely related to type systems, but the type of abstractions one uses is
often much richer than standard type systems.
2.6.4 Comparison with CCG. We now compare our construction mechanism with CCG
(see Figure 19 for an example). The main difference is that our lexical triggers contain
less information than a lexicon in a CCG. In CCG, the lexicon would have an entry such
as
major

34

N/N

: λf.λx.major(x) ∧ f (x),

(59)

Liang et al.

Learning Dependency-Based Compositional Semantics

which gives detailed information about how this word should interact with its context.
However, in DCS construction, each lexical trigger only has the minimal amount of
information:

major

major.

(60)

A lexical trigger speciﬁes a pre-theoretic “meaning” of a word which does not commit
to any formalisms. One advantage of this minimality is that lexical triggers could be
easily obtained from non-expert supervision: One would only have to associate words
with database table names (predicates).
In some sense, the DCS construction mechanism pushes the complexity out of the
lexicon. In linguistics, this complexity usually would end up in the grammar, which
would be undesirable. However, we do not have to respect this tradeoff, because
the construction mechanism only produces an overapproximation, which means it is
possible to have both a simple “lexicon” and a simple “grammar.”
There is an important practical rationale for this design decision. During learning,
we never just have one clean lexical entry per word. Rather, there are often many
possible lexical entries (and to handle disﬂuent utterances or utterances in free wordorder languages, we might actually need many of them (Kwiatkowski et al., 2010)):

major

N

major

N/N

: λf.λx.major(x) ∧ f (x)

(62)

major

N\N

: λf.λx.major(x) ∧ f (x)

(63)

...

: λx.major(x)

(61)

(64)

Now think of a DCS lexical trigger major major as simply a compact representation for
a set of CCG lexical entries. Furthermore, the choice of the lexical entry is made not
at the initial lexical base case, but rather during the recursive construction by inserting
relations between DCS subtrees. It is exactly at this point that the choice can be made,
because after all, the choice is one that depends on context. The general principle is to
compactly represent the indeterminacy until one can resolve it. Compactly representing
a set of CCG lexical entries can also be done within the CCG framework by factoring
lexical entries into a lexeme and a lexical template (Kwiatkowski et al., 2011).
Type raising is a combinator in CCG which traditionally converts x to λf.f (x). In
recent work, Zettlemoyer and Collins (2007) introduced more general type-changing
combinators to allow conversion from one entity into a related entity in general (a
kind of generalized metonymy). For example, in order to parse Boston ﬂights, Boston
is transformed to λx.to(x, Boston). This type changing is analogous to inserting trace
predicates in DCS, but there is an important distinction: Type changing is a unary operation and is unconstrained in that it changes logical forms into new ones without regard
for how they will be used downstream. Inserting trace predicates is a binary operation
which is constrained by the two predicates that it is mediating. In the example, to
would only be inserted to combine Boston with flight. This is another instance of
the general principle of delaying uncertain decisions until there is more information.

35

Computational Linguistics

Volume ?, Number ?

3. Learning
In Section 2, we deﬁned DCS trees and a construction mechanism for producing a set
of candidate DCS trees given an utterance. We now deﬁne a probability distribution
over that set (Section 3.1) and an algorithm for estimating the parameters (Section 3.2).
The number of candidate DCS trees grows exponentially, so we use beam search to
control this growth. The ﬁnal learning algorithm alternates between beam search and
optimization of the parameters, leading to a natural bootstrapping procedure which
integrates learning and search.
3.1 Semantic Parsing Model
The semantic parsing model speciﬁes a conditional distribution over a set of candidate DCS trees C(x) given an utterance x. This distribution depends on a function
φ(x, z) ∈ Rd , which takes a (x, z) pair and extracts a set of local features (see Section 3.1.1
for a full speciﬁcation). Associated with this feature vector is a parameter vector θ ∈ Rd .
The inner product between the two vectors, φ(x, z) θ, yields a numerical score, which
intuitively measures the compatibility of the utterance x with the DCS tree z. We exponentiate the score and normalize over C(x) to obtain a proper probability distribution:
p(z | x; C, θ) = exp{φ(x, z) θ − A(θ; x, C)},
A(θ; x, C) = log

(65)
(66)

exp{φ(x, z) θ},
z∈C(x)

where A(θ; x, C) is the log-partition function with respect to the candidate set function
C(x).
3.1.1 Features. We now deﬁne the feature vector φ(x, z) ∈ Rd , the core part of the
semantic parsing model. Each component j = 1, . . . , d of this vector is a feature, and
φ(x, z)j is the number of times that feature occurs in (x, z). Rather than working with
indices, we treat features as symbols (e.g., T RIGGER P RED[states, state]). Each feature
captures some property about (x, z) which abstracts away from the details of the speciﬁc
instance and allow us to generalize to new instances that share common features.
The features are organized into feature templates, where each feature template
instantiates a set of features. Figure 20 shows all the feature templates for a concrete
example. The feature templates are as follows:

r
r

P RED H IT contains the single feature P RED H IT, which ﬁres for each
predicate in z.
P RED contains features {P RED[α(p)] : p ∈ P}, each of which ﬁres on α(p),
the abstraction of predicate p, where

α(p) =

∗:t
p

if p = x : t
otherwise.

(67)

The purpose of the abstraction is to abstract away the details of concrete
values such as TX = Texas : state.

36

Liang et al.

Learning Dependency-Based Compositional Semantics

state
1
1
border
2

z:

1
TX
x: states

Feature template

Feature j

[Number of predicates]

that border Texas

PredHit

Count φ(x, z)j Parameter θj
3

2.721

1

0.570

1

−2.596

Pred[∗ : state]
[Predicate + relation]

Pred[state]
Pred[border]

[Predicate]

1

1.511

1

−0.262

1

−2.248

1

1.059

1

2.119

1

1.090

PredRel[state
PredRel[border

1]
1
2]
1

PredRel[∗ : state]
[Predicate + relation + predicate]

PredRelPred[state
PredRelPred[border

1 border]
1
2 ∗ : state]
1

[Word + trace predicate]

TriggerPred[states, state]

1

3.262

TriggerPred[Texas, Texas:state]

[Word + trigger predicate]

1

−2.272

[Word + trace relation]

TraceRel[that,
TraceRel[border,

1

[Word + trace predicate + relation] TracePredRel[that, state
TracePredRel[border, state

1]
1
1]
1

0.000

1

1]
1

0.000

1

1]
1

−0.253

1

border]

3.041

1

border]

TracePred[that,
TracePred[border,

0.000

1

0.000

Score: φ(x, z) θ = 13.184

Figure 20
For each utterance-DCS tree pair (x, z), we deﬁne a feature vector φ(x, z), whose j-th
component is the number of times a feature j occurs in (x, z). Each feature has an associated
parameter θj , which is estimated from data in Section 3.2. The inner product of the feature vector
and parameter vector yields a compatibility score.

r

P RED R EL contains features
{P RED R EL[α(p), q] : p ∈ P, q ∈ ({ , } × R)∗ }. A feature ﬁres when a
node x has predicate p and is connected via some path
q = (d1 , r1 ), . . . , (dm , rm ) to the lowest descendant node y with the
property that each node between x and y has a null predicate. Each (d, r)
on the path represents an edge labeled with relation r connecting to a left
(d = ) or right (d = ) child. If x has no children, then m = 0. The most

37

Computational Linguistics

r

r

r

r

r

Volume ?, Number ?

common case is when m = 1, but m = 2 also occurs with the aggregate and
execute relations (e.g., P RED R EL[count, 1
Σ] ﬁres for Figure 5(a)).
1
P RED R EL P RED contains features
{P RED R EL P RED[α(p), q, α(p )] : p, p ∈ P, q ∈ ({ , } × R)∗ }, which are
the same as P RED R EL, except that we include both the predicate p of x and
the predicate p of the descendant node y. These features do not ﬁre if
m = 0.
T RIGGER P RED contains features {T RIGGER P RED[s, p] : s ∈ W ∗ , p ∈ P},
where W = {it, Texas, . . . } is the set of words. Each of these features ﬁres
when a span of the utterance with words s triggers the predicate p—more
precisely, when a subtree p; e i..j exists with s = xi+1..j . Note that these
lexicalized features use the predicate p rather than the abstracted version
α(p).
T RACE P RED contains features
{T RACE P RED[s, p, d] : s ∈ W ∗ , p ∈ P, d ∈ { , }}, each of which ﬁres
when a trace predicate p has been inserted over a word s. The situation is
the following: Suppose we have a subtree a that ends at position k (there is
a predicate in a that is triggered by a phrase with right endpoint k) and
another subtree b that begins at k . Recall that in the construction
mechanism (46), we can insert a trace predicate p ∈ L( ) between the roots
of a and b. Then, for every word xj in between the spans of the two
subtrees (j = {k + 1, . . . , k }), the feature T RACE P RED[xj , p, d] ﬁres (d =
if b dominates a and d = if a dominates b).
T RACE R EL contains features
{T RACE R EL[s, d, r] : s ∈ W ∗ , d ∈ { , }, r ∈ R}, each of which ﬁres when
some trace predicate with parent relation r has been inserted over a word
s.
T RACE P RED R EL contains features
{T RACE P RED R EL[s, p, d, r] : s ∈ W ∗ , p ∈ P, d ∈ { , }, r ∈ R}, each of
which ﬁres when a predicate p is connected via child relation r to some
trace predicate over a word s.

These features are simple generic patterns which can be applied for modeling
essentially any distribution over sequences and labeled trees—there is nothing speciﬁc to DCS at all. The ﬁrst half of the feature templates (P RED H IT, P RED, P RED R EL,
P RED R EL P RED) capture properties of the tree independent of the utterance, and are
similar to ones used for syntactic dependency parsing. The other feature templates
(T RIGGER P RED, T RACE P RED, T RACE R EL, T RACE P RED R EL) connect predicates in the
DCS tree with words in the utterance, similar to those in a model of machine translation.
3.2 Parameter Estimation
We have now fully speciﬁed the details of the graphical model in Figure 2: Section 3.1
described semantic parsing and Section 2 described semantic evaluation. Next, we focus
on the inferential problem of estimating the parameters θ of the model from data.

38

Liang et al.

Learning Dependency-Based Compositional Semantics

3.2.1 Objective Function. We assume that our learning algorithm is given a training dataset D containing question-answer pairs (x, y). Because the logical forms are
unobserved, we work with log p(y | x; C, θ), the marginal log-likelihood of obtaining
the correct answer y given an utterance x. This marginal log-likelihood sums over all
z ∈ C(x) that evaluate to y:
log p(y | x; C, θ) = log p(z ∈ C y (x) | x; C, θ)

(68)

y

= A(θ; x, C ) − A(θ, x, C), where

(69)

def

(70)

C y (x) = {z ∈ C(x) : z

w

= y}.

Here, C y (x) is the set of DCS trees z with denotation y.
We call an example (x, y) ∈ D feasible if the candidate set of x contains a DCS
tree that evaluates to y (C y (x) = ∅). Deﬁne an objective function O(θ, C) containing
two terms: The ﬁrst term is the sum of the marginal log-likelihood over all feasible
training examples. The second term is a quadratic penalty on the parameters θ with
regularization parameter λ. Formally:
def

O(θ, C) =

log p(y | x; C, θ) −
(x,y)∈D
C y (x)=∅

λ
θ
2

2
2

(A(θ; x, C y ) − A(θ; x, C)) −

=
(x,y)∈D
C y (x)=∅

(71)

λ
θ 2.
2
2

We would like to maximize O(θ, C). The log-partition function A(θ; ·, ·) is convex,
but O(θ, C) is the difference of two log-partition functions and hence is not concave
(nor convex). Thus we resort to gradient-based optimization. A standard result is that
the derivative of the log-partition function is the expected feature vector (Wainwright
and Jordan, 2008). Using this, we obtain the gradient of our objective function:11
∂O(θ, C)
=
∂θ

Ep(z|x;C y ,θ) [φ(x, z)] − Ep(z|x;C,θ) [φ(x, z)] − λθ.

(72)

(x,y)∈D
C y (x)=∅

Updating the parameters in the direction of the gradient would move the parameters
towards the DCS trees that yield the correct answer (C y ) and away from over all
candidate DCS trees (C). We can use any standard numerical optimization algorithm
that requires only black-box access to a gradient. Section 4.3.4 will discuss the empirical
ramiﬁcations of the choice of optimization algorithm.
3.2.2 Algorithm. Given a candidate set function C(x), we can optimize (71) to obtain
estimates of the parameters θ. Ideally, we would use C(x) = ZL (x), the candidate sets
from our construction mechanism in Section 2.6, but we quickly run into the problem of
computing (72) efﬁciently. Note that ZL (x) (deﬁned in (44)) grows exponentially with

11 Notation: Ep(x) [f (x)] =

x

p(x)f (x).

39

Computational Linguistics

Volume ?, Number ?

Learning Algorithm
(0)

Initialize: θ ← (0, . . . , 0)
For each iteration t = 1, . . . , T :
˜
−Update candidate sets: C (t) (x) ← ZL,θ(t−1) (x)
(t)
−Update parameters: θ ← argmaxθ O(θ, C (t) )
Return θ(T )
Figure 21
The learning algorithm alternates between updating the candidate sets based on beam search
and updating the parameters using standard numerical optimization.

the length of x. This by itself is not a show stopper. Our features (Section 3.1.1) decompose along the edges of the DCS tree, so it is possible to use dynamic programming12 to
compute the second expectation Ep(z|x;ZL ,θ) [φ(x, z)] of (72). The problem is computing
y
the ﬁrst expectation Ep(z|x;ZL ,θ) [φ(x, z)], which sums over the subset of candidate DCS
trees z satisfying the constraint z w = y. Though this is a smaller set, there is no
efﬁcient dynamic program for this set since the constraint does not decompose along
y
the structure of the DCS tree. Therefore, we need to approximate ZL , and in fact, we
will approximate ZL as well so that the two expectations in (72) are coherent.
Recall that ZL (x) was built by recursively constructing a set of DCS trees Ci,j (x)
for each span i..j. In our approximation, we simply use beam search, which truncates
each Ci,j (x) to include the (at most) K DCS trees with the highest score φ(x, z) θ. We
˜
let Ci,j,θ (x) denote this approximation and deﬁne the set of candidate DCS trees with
respect to the beam search:
˜
˜
ZL,θ (x) = C0,n,θ (x).

(73)

We now have a chicken-and-egg problem: If we had good parameters θ, we could
˜
generate good candidate sets C(x) using beam search ZL,θ (x). If we had good candidate
sets C(x), we could generate good parameters by optimizing our objective O(θ, C) in
(71). This problem leads to a natural solution: simply alternate between the two steps
(Figure 21). This procedure is not guaranteed to converge, due to the heuristic nature of
the beam search, but we have found it to be convergent in practice.
Finally, we use the trained model with parameters θ to answer new questions x by
choosing the most likely answer y, summing out the latent logical form z:
def

˜
Fθ (x) = argmax p(y | x; θ, ZL,θ )

(74)

y

˜
p(z | x; θ, ZL,θ ).

= argmax
y

˜
z∈ZL,θ (x)
z w =y

12 The state of the dynamic program would be the span i..j and the head predicate over that span.

40

(75)

Liang et al.

Learning Dependency-Based Compositional Semantics

4. Experiments
We have now completed the conceptual part of this article—using DCS trees to represent logical forms (Section 2), and learning a probabilistic model over these trees
(Section 3). In this section, we evaluate and study our approach empirically. Our
main result is that our system can obtain comparable accuracies to state-of-the-art
systems that require annotated logical forms. All the code and data is available at
cs.stanford.edu/~pliang/software/.
4.1 Experimental Setup
We ﬁrst describe the datasets (Section 4.1.1) that we use to train and evaluate our system.
We then mention various choices in the model and learning algorithm (Section 4.1.2).
One of these choices is the lexical triggers, which is further discussed in Section 4.1.3.
4.1.1 Datasets. We tested our methods on two standard datasets, referred to in this
article as G EO and J OBS. These datasets were created by Ray Mooney’s group during
the 1990s and have been used to evaluate semantic parsers for over a decade.
US Geography. The G EO dataset, originally created by Zelle and Mooney (1996), contains
880 questions about US Geography and a database of facts encoded in Prolog. The
questions in G EO ask about general properties (e.g., area, elevation, population) of
geographical entities (e.g., cities, states, rivers, mountains). Across all the questions,
there are 280 word types, and the length of an utterance ranges from 4 to 19 words, with
an average of 8.5 words. The questions involve conjunctions, superlatives, negation, but
no generalized quantiﬁcation. Each question is annotated with a logical form in Prolog,
for example:
Utterance:
Logical form:

What is the highest point in Florida?
answer(A,highest(A,(place(A),loc(A,B),const(B,stateid(florida)))))

Since our approach learns from answers, not logical forms, we evaluated the annotated logical forms on the provided database to obtain the correct answers.
Recall that a world/database w maps each predicate p ∈ P to a set of tuples w(p).
Some predicates contain the set of tuples explicitly (e.g., mountain); others can be
derived (e.g., higher takes two entities x and y and returns true if elevation(x) >
elevation(y)). Other predicates are higher-order (e.g., sum, highest) in that they
take other predicates as arguments. We do not use the provided domain-speciﬁc higherorder predicates (e.g., highest), but rather provide domain-independent higherorder predicates (e.g., argmax) and the ordinary domain-speciﬁc predicates (e.g.,
elevation). This provides more compositionality and therefore better generalization.
Similarly, we use more and elevation instead of higher. Altogether, P contains 43
predicates plus one predicate for each value (e.g., CA).
Job Queries. The J OBS dataset (Tang and Mooney, 2001) contains 640 natural language
queries about job postings. Most of the questions ask for jobs matching various criteria:
job title, company, recruiter, location, salary, languages and platforms used, areas of
expertise, required/desired degrees, and required/desired years of experience. Across
all utterances, there are 388 word types, and the length of an utterance ranges from 2 to

41

Computational Linguistics

Volume ?, Number ?

23 words, with an average of 9.8 words. The utterances are mostly based on conjunctions
of criteria, with a sprinkling of negation and disjunction. Here is an example:
Utterance:
Logical form:

Are there any jobs using Java that are not with IBM?
answer(A,(job(A),language(A,’java’),¬company(A,’IBM’)))

The J OBS dataset comes with a database, which we can use as the world w. However,
when the logical forms are evaluated on this database, close to half of the answers are
empty (no jobs match the requested criteria). Therefore, there is a large discrepancy
between obtaining the correct logical form (which has been the focus of most work on
semantic parsing) and obtaining the correct answer (our focus).
To bring these two into better alignment, we generated a random database as
follows: We created m = 100 jobs. For each job j, we go through each predicate p (e.g.,
company) that takes two arguments, a job and a target value. For each of the possible
target values v, we add (j, v) to w(p) independently with probability α = 0.8. For
example, for p = company, j = job37, we might add (job37, IBM) to w(company).
The result is a database with a total of 23 predicates (which includes the domainindependent ones) in addition to the value predicates (e.g., IBM).
The goal of using randomness is to ensure that two different logical forms will most
likely yield different answers. For example, consider two logical forms:
z1 = λj.job(j) ∧ company(j, IBM),

(76)

z2 = λj.job(j) ∧ language(j, Java).

(77)

Under the random construction, the denotation of z1 is S1 , a random subset of the jobs,
where each job is included in S1 independently with probability α, and the denotation
of z2 is S2 , which has the same distribution as S1 but importantly is independent of S1 .
Therefore, the probability that S1 = S2 is [α2 + (1 − α)2 ]m , which is exponentially small
in m. This construction yields a world that is not entirely “realistic” (a job might have
multiple employers), but it ensures that if we get the correct answer, we probably also
obtain the correct logical form.
4.1.2 Settings. There are a number of settings which control the tradeoffs between
computation, expressiveness, and generalization power of our model, shown below.
For now, we will use generic settings chosen rather crudely; Section 4.3.4 will explore
the effect of changing these settings.
Lexical Triggers The lexical triggers L (Section 2.6.1) deﬁne the set of candidate DCS
trees for each utterance. There is a tradeoff between expressiveness and computational complexity: The more triggers we have, the more DCS trees we can consider
for a given utterance, but then either the candidate sets become too large or beam
search starts dropping the good DCS trees. Choosing lexical triggers is important
and requires additional supervision (Section 4.1.3).
Features Our probabilistic semantic parsing model is deﬁned in terms of feature templates (Section 3.1.1). Richer features increase expressiveness but also might lead
to overﬁtting. By default, we include all the feature templates.
Number of training examples (n) An important property of any learning algorithm is
its sample complexity—how many training examples are required to obtain a
certain level of accuracy? By default, all training examples are used.

42

Liang et al.

Learning Dependency-Based Compositional Semantics

Number of training iterations (T ) Our learning algorithm (Figure 21) alternates between updating candidate sets and updating parameters for T iterations. We use
T = 5 as the default value.
Beam size (K) The computation of the candidate sets in Figure 21 is based on beam
search where each intermediate state keeps at most K DCS trees. The default value
is K = 100.
Optimization algorithm To optimize an the objective function O(θ, C) our default is
to use the standard L-BFGS algorithm (Nocedal, 1980) with a backtracking line
search for choosing the step size.
Regularization (λ) The regularization parameter λ > 0 in the objective function O(θ, C)
is another knob for controlling the tradeoff between ﬁtting and overﬁtting. The
default is λ = 0.01.
4.1.3 Lexical Triggers. The lexical trigger set L (Section 2.6.1) is a set of entries (s, p),
where s is a sequence of words and p is a predicate. We run experiments on two sets of
lexical triggers: base triggers LB and augmented triggers LB+P .
Base Triggers. The base trigger set LB includes three types of entries:

r
r

r

Domain-independent triggers: For each domain-independent predicate
(e.g., argmax), we manually specify a few words associated with that
predicate (e.g., most). The full list is shown at the top of Figure 22.
Values: For each value x that appears in the world (speciﬁcally,
x ∈ vj ∈ w(p) for some tuple v, index j, and predicate p), LB contains an
entry (x, x) (e.g., (Boston, Boston : city)). Note that this rule implicitly
speciﬁes an inﬁnite number of triggers.
Regarding predicate names, we do not add entries such as (city, city),
because we want our system to be language-independent. In Turkish, for
instance, we would not have the luxury of lexicographical cues that
associate city with sehir. So we should think of the predicates as just
¸
symbols predicate1, predicate2, etc. On the other hand, values in the
database are generally proper nouns (e.g., city names) for which there are
generally strong cross-linguistic lexicographic similarities.
Part-of-speech (POS) triggers:13 For each domain-speciﬁc predicate p, we
specify a set of part-of-speech tags T . Implicitly, LB contains all pairs (x, p)
where the word x has a POS tag t ∈ T . For example, for city, we would
specify NN and NNS, which means that any word which is a singular or
plural common noun triggers the predicate city. Note that city triggers
city as desired, but state also triggers city.
The POS triggers for G EO and J OBS domains are shown in the left side of
Figure 22. Note that that some predicates such as traverse and loc are
not associated with any POS tags. Predicates corresponding to verbs and
prepositions are not included as overt lexical triggers, but rather included
as trace predicates L( ). In constructing the logical forms, nouns and

13 To perform POS tagging, we used the Berkeley Parser (Petrov et al., 2006), trained on the WSJ Treebank
(Marcus et al., 1993) and the Question Treebank (Judge et al., 2006)—thanks to Slav Petrov for providing
the trained parser.

43

Computational Linguistics

Volume ?, Number ?

Domain-independent triggers
no | not | dont | doesnt | outside | exclude
each | every
most
least | fewest
count | number | many
large | high | great
small | low
sum | combined | total
less | at most
more | at least
called | named

Geo POS triggers
nn | nns

nn | nns | jj

nn | nns
jj
wrb

city | state | country | lake |
mountain | river | place | person |
capital | population
len | negLen | size | negSize |
elevation | negElevation | density |
negDensity | area | negArea
usa:country
major
loc
loc | next to | traverse |
hasInhabitant

Jobs POS triggers
nn | nns

job | deg | exp | language | loc
salary greater than | require | desire |
title | company | recruiter | area |
platform | application | language | loc

not
every
argmax
argmin
count
affirm
negate
sum
less
more
nameObj

Geo prototypes
city
state
country
lake
mountain
river
point
where
major
capital
high point

city
state
country
lake
mountain
river
place
loc
major
capital
high point

person
population
long
short
large
small
high
low
dense
sparse
area

person
population
len
negLen
size
negSize
elevation
negElevation
density
negDensity
area

Jobs prototypes
(beginning of utterance)
degree
experience
language
location

job
deg
exp
language
loc

Figure 22
Lexical triggers used in our experiments.

adjectives serve as anchor points. Trace predicates can be inserted in
between these anchors. This strategy is more ﬂexible than requiring each
predicate to spring from some word.
Augmented Triggers. We now deﬁne the augmented trigger set LB+P , which contains more
domain-speciﬁc information than LB . Speciﬁcally, for each domain-speciﬁc predicate
(e.g., city), we manually specify a single prototype word (e.g., city) associated with that
predicate. Under LB+P , city would trigger only city because city is a prototype word,
but town would trigger all the NN predicates (city, state, country, etc.) because it is
not a prototype word.
Prototype triggers require only a modest amount of domain-speciﬁc supervision
(see the right side of Figure 22 for the entire list for G EO and J OBS). In fact, as we’ll see
in Section 4.2, prototype triggers are not absolutely required to obtain good accuracies,
but they give an extra boost and also improve computational efﬁciency by reducing the
set of candidate DCS trees.

44

Liang et al.

Learning Dependency-Based Compositional Semantics

Finally, to determine triggering, we stem all words using the Porter stemmer
(Porter, 1980), so that mountains triggers the same predicates as mountain. We also
decompose superlatives into two words (e.g., largest is mapped to most large), allowing
us to construct the logical form more compositionally.
4.2 Comparison with Other Systems
We now compare our approach with existing methods (Section 4.2). We used the same
training-test splits as Zettlemoyer and Collins (2005) (600 training and 280 test examples
for G EO, 500 training and 140 test examples for J OBS). For development, we created ﬁve
random splits of the training data. For each split, we put 70% of the examples into a
development training set and the remaining 30% into a development test set. The actual test
set was only used for obtaining ﬁnal numbers.
4.2.1 Systems that Learn from Question-Answer Pairs. We ﬁrst compare our system
(henceforth, LJK11) with Clarke et al. (2010) (henceforth, CGCR10), which is most
similar to our work in that it also learns from question-answer pairs without using
annotated logical forms. CGCR10 works with the FunQL language and casts semantic
parsing as integer linear programming (ILP). In each iteration, the learning algorithm
solves the ILP to predict the logical form for each training example. The examples with
correct predictions are fed to a structural SVM and the model parameters are updated.
Though similar in spirit, there are some important differences between CGCR10
and our approach. They use ILP instead of beam search and structural SVM instead of
log-linear models, but the main difference is which examples are used for learning. Our
approach learns on any feasible example (Section 3.2.1), one where the candidate set
contains a logical form that evaluates to the correct answer. CGCR10 uses a much more
stringent criterion: the highest scoring logical form must evaluate to the correct answer.
Therefore, for their algorithm to progress, the model already must be non-trivially good
before learning even starts. This is reﬂected in the amount of prior knowledge and initialization that CGCR10 employs before learning starts: WordNet features, and syntactic
parse trees, and a set of lexical triggers with 1.42 words per non-value predicate. Our
system with base triggers requires only simple indicator features, POS tags, and 0.5
words per non-value predicate.
CGCR10 created a version of G EO which contains 250 training and 250 test examples. Table 2 compares the empirical results on this split. We see that our system
(LJK11) with base triggers signiﬁcantly outperforms CGCR10 (84% over 73.2%), and it
even outperforms the version of CGCR10 that is trained using logical forms (84.0% over
80.4%). If we use augmented triggers, we widen the gap by another 3.6%.14
4.2.2 State-of-the-Art Systems. We now compare our system (LJK11) with state-of-theart systems, which all require annotated logical forms (except P RECISE). Here is a brief
overview of the systems:

r

C OCKTAIL (Tang and Mooney, 2001) uses inductive logic programming to
learn rules for driving the decisions of a shift-reduce semantic parser. It
assumes that a lexicon (mapping from words to predicates) is provided.

14 Note that the numbers for LJK11 differ from those presented in Liang et al. (2011), which reports results
based on 10 different splits rather than the setup used by CGCR10.

45

Computational Linguistics

System
CGCR10 w/answers
CGCR10 w/logical forms
LJK11 w/base triggers
LJK11 w/augmented triggers

Volume ?, Number ?

(Clarke et al., 2010)
(Clarke et al., 2010)
(Liang et al., 2011)
(Liang et al., 2011)

Accuracy
73.2
80.4
84.0
87.6

Table 2
Results on G EO with 250 training and 250 test examples. Our system (LJK11 with base triggers
and no logical forms) obtains higher test accuracy than CGCR10, even when CGCR10 is trained
using logical forms.

r

r
r
r
r
r
r

r

r
r

46

P RECISE (Popescu et al., 2003) does not use learning, but instead relies on
matching words to strings in the database using various heuristics based
on WordNet and the Charniak parser. Like our work, it also uses database
type constraints to rule out spurious logical forms. One of the unique
features of P RECISE is that it has 100% precision—it refuses to parse an
utterance which it deems semantically intractable.
S CISSOR (Ge and Mooney, 2005) learns a generative probabilistic model
that extends the Collins models (Collins, 1999) with semantic labels, so
that syntactic and semantic parsing can be done jointly.
S ILT (Kate et al., 2005) learns a set of transformation rules for mapping
utterances to logical forms.
K RISP (Kate and Mooney, 2006) uses SVMs with string kernels to drive the
local decisions of a chart-based semantic parser.
WASP (Wong and Mooney, 2006) uses log-linear synchronous grammars to
transform utterances into logical forms, starting with word alignments
obtained from the IBM models.
λ-WASP (Wong and Mooney, 2007) extends WASP to work with logical
forms that contain bound variables (lambda abstraction).
LNLZ08 (Lu et al., 2008) learns a generative model over hybrid trees, which
are logical forms augmented with natural language words. IBM model 1 is
used to initialize the parameters, and a discriminative reranking step
works on top of the generative model.
ZC05 (Zettlemoyer and Collins, 2005) learns a discriminative log-linear
model over CCG derivations. Starting with a manually-constructed
domain-independent lexicon, the training procedure grows the lexicon by
adding lexical entries derived from associating parts of an utterance with
parts of the annotated logical form.
ZC07 (Zettlemoyer and Collins, 2007) extends ZC05 with extra
(disharmonic) combinators to increase the expressive power of the model.
KZGS10 (Kwiatkowski et al., 2010) uses a restricted higher-order
uniﬁcation procedure, which iteratively breaks up a logical form into
smaller pieces. This approach gradually adds lexical entries of increasing
generality, thus obviating the need for the manually-speciﬁed templates

Liang et al.

Learning Dependency-Based Compositional Semantics

used by ZC05 and ZC07 for growing the lexicon. IBM model 1 is used to
initialize the parameters.

r

KZGS11 (Kwiatkowski et al., 2011) extends KZGS10 by factoring lexical
entries into a template plus a sequence of predicates which ﬁll the slots of
the template. This factorization improves generalization.

With the exception of P RECISE, all other systems require annotated logical forms,
whereas our system learns only from annotated answers. On the other hand, our system does rely on a few manually-speciﬁed lexical triggers, whereas many of the later
systems essentially require no manually-crafted lexica. For us, the lexical triggers play
a crucial role in the initial stages of learning because they constrain the set of candidate
DCS trees; otherwise we would face a hopelessly intractable search problem. The other
systems induce lexica using unsupervised word alignment (e.g., Wong and Mooney
(2006, 2007); Kwiatkowski et al. (2010, 2011)) and/or online lexicon learning (e.g.,
Zettlemoyer and Collins (2005, 2007); Kwiatkowski et al. (2010, 2011)). Unfortunately,
we cannot use these automatic techniques because they rely on having annotated logical
forms.
Table 3 shows the results for G EO. Semantic parsers are typically evaluated on
the accuracy of the logical forms: precision (the accuracy on utterances which are
successfully parsed) and recall (the accuracy on all utterances). We only focus on recall
(a lower bound on precision) and simply use the word accuracy to refer to recall.15 Our
system is evaluated only on answer accuracy because our model marginalizes out the
latent logical form. All other systems are evaluated on the accuracy of logical forms. To
calibrate, we also evaluated KZGS10 on answer accuracy and found that it was quite
similar to its logical form accuracy (88.9% versus 88.2%).16 This does not imply that our
system would necessarily have a high logical form accuracy because multiple logical
forms can produce the same answer, and our system does not receive a training signal to
tease them apart. Even with only base triggers, our system (LJK11) outperforms all but
two of the systems, falling short of KZGS10 by only one point (87.9% versus 88.9%).17
With augmented triggers, our system takes the lead (91.4% over 88.9%).
Table 4 shows the results for J OBS. The two learning-based systems (C OCKTAIL
and ZC05) are actually outperformed by P RECISE, which is able to use strong database
type constraints. By exploiting this information and doing learning, we obtain the best
results.
4.3 Empirical Properties
In this section, we try to gain intuition into properties of our approach. All experiments
in this section are performed on random development splits. Throughout this section,
“accuracy” means development test accuracy.
4.3.1 Error Analysis. To understand the type of errors our system makes, we examined
one of the development runs, which had 34 errors on the test set. We classiﬁed these

15 Our system produces a logical form for every utterance, and thus our precision is the same as our recall.
16 The 88.2% corresponds to 87.9% in Kwiatkowski et al. (2010). The difference is due to using a slightly
newer version of the code.
17 The 87.9% and 91.4% correspond to 88.6% and 91.1% in Liang et al. (2011). These differences are due to
minor differences in the code.

47

Computational Linguistics

System
C OCKTAIL
P RECISE
S CISSOR
S ILT
K RISP
WASP
λ-WASP
LNLZ08
ZC05
ZC07
KZGS10
KZGS11
LJK11 w/base triggers
LJK11 w/augmented triggers

Volume ?, Number ?

(Tang and Mooney, 2001)
(Popescu et al., 2003)
(Ge and Mooney, 2005)
(Kate et al., 2005)
(Kate and Mooney, 2006)
(Wong and Mooney, 2006)
(Wong and Mooney, 2007)
(Lu et al., 2008)
(Zettlemoyer and Collins, 2005)
(Zettlemoyer and Collins, 2007)
(Kwiatkowski et al., 2010)
(Kwiatkowski et al., 2010)
(Liang et al., 2011)
(Liang et al., 2011)

LF
79.4
77.5
72.3
54.1
71.7
74.8
86.6
81.8
79.3
86.1
88.2
88.6
–
–

Answer
–
77.5
–
–
–
–
–
–
–
–
88.9
–
87.9
91.4

Table 3
Results on G EO. Logical form accuracy (LF) and answer accuracy (Answer) of the various
systems. The ﬁrst group of systems are evaluated using 10-fold cross-validation on all 880
examples; the second are evaluated on the 680 + 200 split of Zettlemoyer and Collins (2005). Our
system (LJK11) with base triggers obtains comparable accuracy to past work, while with
augmented triggers, our system obtains the highest overall accuracy.

System
C OCKTAIL
P RECISE
ZC05
LJK11 w/base triggers
LJK11 w/augmented triggers

(Tang and Mooney, 2001)
(Popescu et al., 2003)
(Zettlemoyer and Collins, 2005)
(Liang et al., 2011)
(Liang et al., 2011)

LF
79.4
88.0
79.3
–
–

Answer
–
88.0
–
90.7
95.0

Table 4
Results on J OBS. Both P RECISE and our system use database type constraints, which results in a
decisive advantage over the other systems. In addition, LJK11 incorporates learning and
therefore obtains the highest accuracies.

errors into the following categories (the number of errors in each category is shown in
parentheses):

r

r

48

Incorrect POS tags (8): G EO is out-of-domain for our POS tagger, so the
tagger makes some basic errors which adversely affect the predicates that
can be lexically triggered. For example, the question
What states border states . . . is tagged as WP VBZ NN NNS . . . , which means
that the ﬁrst states cannot trigger state. In another example, major river is
tagged as NNP NNP, so these cannot trigger the appropriate predicates
either, and thus the desired DCS tree cannot even be constructed.
Non-projectivity (3): The candidate DCS trees are deﬁned by a projective
construction mechanism (Section 2.6) that prohibits edges in the DCS tree
from crossing. This means we cannot handle utterances such as
largest city by area, since the desired DCS tree would have city
dominating area dominating argmax. To construct this DCS tree, we
could allow local reordering of the words.

Liang et al.

r

r

r
r

Learning Dependency-Based Compositional Semantics

Unseen words (2): We never saw at least or sea level at training time. The
former has the correct lexical trigger, but not a sufﬁciently large feature
weight (0) to encourage its use. For the latter, the problem is more
structural: We have no lexical triggers for 0 : length, and only adding
more lexical triggers can solve this problem.
Wrong lexical triggers (7): Sometimes the error is localized to a single
lexical trigger. For example, the model incorrectly thinks Mississippi is the
state rather than the river, and that Rochester is the city in New York rather
than the name, even though there are contextual cues to disambiguate in
these cases.
Extra words (5): Sometimes, words trigger predicates that should be
ignored. For example, for population density, the ﬁrst word triggers
population, which is used rather than density.
Over-smoothing of DCS tree (9): The ﬁrst half of our features (Figure 20)
are deﬁned on the DCS tree alone; these produce a form of smoothing that
encourages DCS trees to look alike regardless of the words. We found
several instances where this essential tool for generalization went too far.
For example, in state of Nevada, the trace predicate border is inserted
between the two nouns, because it creates a structure more similar to that
of the common question what states border Nevada?

4.3.2 Visualization of Features. Having analyzed the behavior of our system for individual utterances, let us move from the token level to the type level and analyze
the learned parameters of our model. We do not look at raw feature weights, because
there are complex interactions between them not represented by examining individual
weights. Instead, we look at expected feature counts, which we think are more interpretable.
Consider a group of “competing” features J, for example J =
{T RIGGER P RED[city, p] : p ∈ P}. We deﬁne a distribution q(·) over J as follows:
q(j) =

Nj
j ∈J

Nj =

Nj

, where

(78)

Ep(z|x,ZL,θ ,θ) [φ(x, z)].
˜
(x,y)∈D

Think of q(j) as a marginal distribution (since all our features are positive) which
represents the relative frequencies with which the features j ∈ J ﬁre with respect to
˜
our training dataset D and trained model p(z | x, ZL,θ , θ). To appreciate the difference
between what this distribution and raw feature weights capture, suppose we had two
features, j1 and j2 , which are identical (φ(x, z)j1 ≡ φ(x, z)j2 ). The weights would be split
across the two features, but the features would have the same marginal distribution
(q(j1 ) = q(j2 )). Figure 23 shows some of the feature distributions learned.
4.3.3 Learning, Search, Bootstrapping. Recall from Section 3.2.1 that a training example
is feasible (with respect to our beam search) if the resulting candidate set contains a
DCS tree with the correct answer. Infeasible examples are skipped, but an example may
become feasible in a later iteration. A natural question is how many training examples

49

Computational Linguistics

Volume ?, Number ?

TriggerPred[city, ·]
city
river
capital
···

1.00
0.00
0.00
···

TriggerPred[peak, ·]
mountain
0.92
place
0.08
city
0.00
···
···

TriggerPred[sparse, ·]
elevation
1.00
density
0.00
size
0.00
···
···

TracePred[in, ·, ·]
loc
traverse
border
···

0.99
0.01
0.00
···

TracePred[have, ·, ·]
loc
0.68
border
0.20
traverse
0.12
···
···

TracePred[ﬂow, ·, ·]
traverse
border
loc
···

PredRelPred[·, ·, city]
ø x1,2
0.38

PredRelPred[·, ·, loc]
1
0.25
city
1

PredRelPred[·, ·, elevation]
1
0.65
place
1

øΣ
count
···

1
1

øΣ

0.19
0.19

state

···

···

1
2
1
1

mountain

0.17

ø

···

place

0.25

···

1
2

1
1

0.71
0.18
0.11
···

0.27
0.08
···

Figure 23
Learned feature distributions. In a feature group (e.g., T RIGGER P RED[city, ·]), each feature is
associated with the marginal probability that the feature ﬁres according to (78). Note that we
have successfully learned that city means city, but incorrectly learned that sparse means
elevation (due to the confounding fact that Alaska is the most sparse state and has the highest
elevation).

Fraction feasible

100

80

60

40

Random
Random
Random
Random
Random

20

1

2

3

4

5

1
2
3
4
5

6

iteration
Figure 24
The fraction of feasible training examples increases steadily as the parameters, and thus, the
beam search, improves. Each curve corresponds to a run on a different development split.

are feasible in each iteration. Figure 24 shows the answer: Initially, only around 30% of
the training examples are feasible; this is not surprising given that all the parameters

50

Liang et al.

Learning Dependency-Based Compositional Semantics

are zero, so our beam search is essentially unguided. However, training on just these
examples improves the parameters, and over the next few iterations, the number of
feasible examples steadily increases to around 97%.
In our algorithm, learning and search are deeply intertwined. Search is of course
needed to learn, but learning also improves search. The general approach is similar in
spirit to Searn (Daume et al., 2009), although we do not have any formal guarantees at
this point.
Our algorithm also has a bootstrapping ﬂavor. The “easy” examples are processed
ﬁrst, where easy is deﬁned by the ability of beam search to generate the correct answer.
This bootstrapping occurs quite naturally: Unlike most bootstrapping algorithms, we do
not have to set a conﬁdence threshold for accepting new training examples, something
that can be quite tricky to do. Instead, our threshold falls out of the discrete nature of
the beam search.
4.3.4 Effect of Various Settings. So far, we have used our approach with default settings
(Section 4.1.2). How sensitive is the approach to these choices? Table 5 shows the impact
of the feature templates. Figure 25 shows the effect of the number of training examples,
number of training iterations, beam size, and regularization parameter. The overall
conclusion is that there are no big surprises: Our default settings could be improved
on slightly, but these differences are often smaller than the variation across different
development splits.
Features
P RED
P RED + P RED R EL
P RED + P RED R EL + P RED R EL P RED
P RED + T RIGGER P RED
P RED + T RIGGER P RED + T RACE∗
P RED + P RED R EL + P RED R EL P RED + T RIGGER P RED + T RACE∗

Accuracy
13.4 ± 1.6
18.4 ± 3.5
23.1 ± 5.0
61.3 ± 1.1
76.4 ± 2.3
84.7 ± 3.5

Table 5
There are two classes of feature templates: lexical features (T RIGGER P RED,T RACE*) and
non-lexical features (P RED R EL,P RED R EL P RED). The lexical features are relatively much more
important for obtaining good accuracy (76.4% versus 23.1%), but adding the non-lexical features
makes a signiﬁcant contribution as well (84.7% versus 76.4%).

We now consider the choice of optimization algorithm to update the parameters
given candidate sets (see Figure 21). Thus far, we have been using L-BFGS (Nocedal, 1980), which is a batch algorithm: Each iteration, we construct the candidate
sets C (t) (x) for all the training examples before solving the optimization problem
argmaxθ O(θ, C (t) ). We now consider an online algorithm, stochastic gradient descent
(SGD) (Robbins and Monro, 1951), which updates the parameters after computing the
candidate set for each example. In particular, we iteratively scan through the training
examples in a random order. For each example (x, y), we compute the candidate set
using beam search. We then update the parameters in the direction of the gradient of
the marginal log-likelihood for that example (see (72)) with step size t−α :
θ(t+1) ← θ(t) + t−α

˜
∂ log p(y | x; ZL,θ(t) , θ)
∂θ

θ=θ (t)

.

(79)

51

Computational Linguistics

Volume ?, Number ?

80

Accuracy

100

80

Accuracy

100

60

40

Random
Random
Random
Random
Random

20

100

200

300

1
2
3
4
5

40

Random
Random
Random
Random
Random

20

400

5

examples
(a) Eﬀect of # training examples

10

15

20

1
2
3
4
5

25

30

iteration
(b) Eﬀect of # training iterations
100

80

90

Accuracy

100

Accuracy

60

60

40

80

70

60

20

1

3

10

30

100

Beam size (K)
(c) Eﬀect of beam size

300

0

0.001 0.003 0.01

0.03

0.1

0.3

Regularization (λ)
(d) Eﬀect of regularization

Figure 25
(a) The learning curve shows test accuracy as the number of training examples increases; about
300 examples sufﬁces to get around 80% accuracy. (b) Although our algorithm is not guaranteed
to converge, the test accuracy is fairly stable (with one exception) with more training
iterations—hardly any overﬁtting occurs. (c) As the beam size increases, the accuracy increases
monotonically, although the computational burden also increases. There is a small gain from our
default setting of K = 100 to the more expensive K = 300. (d) The accuracy is relatively
insensitive to the choice of the regularization parameter for a wide range of values. In fact, no
regularization is also acceptable. This is probably because the features are simple, and the lexical
triggers and beam search already provide some helpful biases.

The trickiest aspect of using SGD is selecting the correct step size: a small α leads to
quick progress but also instability; a large α leads to the opposite. We let L-BFGS and
SGD both take the same number of iterations (passes over the training set). Figure 26
shows that a very small value of α (less than 0.2) is best for our task, even though
only values between 0.5 and 1 guarantee convergence. Our setting is slightly different

52

Liang et al.

Learning Dependency-Based Compositional Semantics

100

100

80

Accuracy

Accuracy

90

80

70

60

40
L-BFGS

60

20

SGD (α = 0)
SGD (α = 0.6)

L-BFGS SGD
α=0

SGD
SGD
SGD
SGD
SGD
SGD
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 α = 0.6

Optimization algorithm
(a) Eﬀect of optimization algorithm

1

2

3

4

5

iteration
(b) Batch versus online

Figure 26
(a) Given the same number of iterations, compared to default batch algorithm (L-BFGS), the
online algorithm (stochastic gradient descent) is slightly better for aggressive step sizes (small α)
and worse for conservative step sizes (large α). (b) The online algorithm (with an appropriate
choice of α) obtains a reasonable accuracy much faster than L-BFGS.

since we are interleaving the SGD updates with beam search, which might also lead to
unpredictable consequences. Furthermore, the non-convexity of the objective function
exacerbates the unpredictability (Liang and Klein, 2009). Nonetheless, with a proper α,
SGD converges much faster than L-BFGS and even to a slightly better solution.
5. Discussion
The work we have presented in this article addresses three important themes. The
ﬁrst theme is semantic representation (Section 5.1): How do we parametrize the mapping
from utterances to their meanings? The second theme is program induction (Section 5.2):
How do we efﬁciently search through the space of logical structures given a weak
feedback signal? Finally, the last theme is grounded language (Section 5.3): How do we use
constraints from the world to guide learning of language and conversely use language
to interact with the world?
5.1 Semantic Representation
Since the late nineteenth century, philosophers and linguists have worked on elucidating the relationship between an utterance and its meaning. One of the pillars of formal
semantics is Frege’s principle of compositionality, that the meaning of an utterance is
built by composing the meaning of its parts. What these parts are and how they are
composed is the main question. The dominant paradigm, which stems from the seminal
work of Richard Montague in the early 1970s (Montague, 1973), states that parts are
lambda calculus expressions that correspond to syntactic constituents, and composition
is function application.
Consider the compositionality principle from a statistical point of view, where we
construe compositionality as factorization. Factorization, the way a statistical model
breaks into features, is necessary for generalization: It enables us to learn from previously seen examples and interpret new utterances. Projecting back to Frege’s original

53

Computational Linguistics

Volume ?, Number ?

principle, the parts are the features (Section 3.1.1), and composition is the DCS construction mechanism (Section 2.6) driven by parameters learned from training examples.
Taking the statistical view of compositionality, ﬁnding a good semantic representation becomes designing a good statistical model. But statistical modeling must also
deal with the additional issue of language acquisition or learning, which presents
complications: In absorbing training examples, our learning algorithm must inevitably
traverse through intermediate models that are wrong or incomplete. The algorithms
must therefore tolerate this degradation, and do so in a computationally efﬁcient way.
For example, in the line of work on learning probabilistic CCGs (Zettlemoyer and
Collins, 2005, 2007; Kwiatkowski et al., 2010), many candidate lexical entries must be
entertained for each word even when polysemy does not actually exist (Section 2.6.4).
To improve generalization, the lexicon can be further factorized (Kwiatkowski et al.,
2011), but this is all done within the constraints of CCG. DCS represents a departure
from this tradition, which replaces a heavily-lexicalized constituency-based formalism
with a lightly-lexicalized dependency-based formalism. We can think of DCS as a shift
in linguistic coordinate systems, which makes certain factorizations or features more
accessible. For example, we can deﬁne features on paths between predicates in a DCS
tree which capture certain lexical patterns much more easily than in a lambda calculus
expression or a CCG derivation.
DCS has a family resemblance to a semantic representation called natural logic
form (Alshawi et al., 2011), which is also motivated by the beneﬁts of working with
dependency-based logical forms. The goals and the detailed structure of the two semantic formalisms are different, however. Alshawi et al. (2011) focuses on parsing complex
sentences in an open domain where a structured database or world does not exist. While
they do equip their logical forms with a full model-theoretic semantics, the logical forms
are actually closer to dependency trees: quantiﬁer scope is left unspeciﬁed, and the
predicates are simply the words.
Perhaps not immediately apparent is the fact that DCS draws an important idea
from Discourse Representation Theory (DRT) (Kamp and Reyle, 1993)—not from the
treatment of anaphora and presupposition which it is known for, but something closer
to its core. This is the idea of having a logical form where all variables are existentially
quantiﬁed and constraints are combined via conjunction—a Discourse Representation
Structure (DRS) in DRT, or a basic DCS tree with only join relations. Computationally,
these logical structures conveniently encode CSPs. Linguistically, it appears that existential quantiﬁers play an important role and should be treated specially (Kamp and Reyle,
1993). DCS takes this core and focuses on semantic compositionality and computation,
while DRT focuses more on discourse and pragmatics.
In addition to the statistical view of DCS as a semantic representation, it is useful to think about DCS from the perspective of programming language design. Two
programming languages can be equally expressive, but what matters is how simple it
is to express a desired type of computation in a given language. In some sense, we
designed the DCS formal language to make it easy to represent computations expressed
by natural language. An important part of DCS is the mark-execute construct, a uniform
framework for dealing with the divergence between syntactic and semantic scope. This
construct allows us to build simple DCS tree structures and still handle the complexities
of phenomena such as quantiﬁer scope variation. Compared to lambda calculus, think
of DCS as a higher-level programming language tailored to natural language, which
results in simpler programs (DCS trees). Simpler programs are easier for us to work
with and easier for an algorithm to learn.

54

Liang et al.

Learning Dependency-Based Compositional Semantics

5.2 Program Induction
Searching over the space of programs is challenging. This is the central computational
challenge of program induction, that of inferring programs (logical forms) from their
behavior (denotations). This problem has been tackled by different communities in
various forms: program induction in AI, programming by demonstration in HCI, and
program synthesis in programming languages. The core computational difﬁculty is that
the supervision signal—the behavior—is a complex function of the program which
cannot be easily inverted. What program generated the output Arizona, Nevada, and
Oregon?
Perhaps somewhat counterintuitively, program induction is easier if we infer programs for not a single task but for multiple tasks. The intuition is that when the tasks
are related, the solution to one task can help another task, both computationally in
navigating the program space and statistically in choosing the appropriate program
if there are multiple feasible possibilities (Liang et al., 2010). In our semantic parsing
work, we want to infer a logical form for each utterance (task). Clearly the tasks are
related because they use the same vocabulary to talk about the same domain.
Natural language also makes program induction easier by providing side information (words) which can be used to guide the search. There have been several papers that
induce programs in this setting: Eisenstein et al. (2009) induces conjunctive formulae
from natural language instructions, Piantadosi et al. (2008) induces ﬁrst-order logic
formulae using CCG in a small domain assuming observed lexical semantics, and
Clarke et al. (2010) induces logical forms in semantic parsing. In the ideal case, the
words would determine the program predicates, and the utterance would determine
the entire program compositionally. But of course, this mapping is not given and must
be learned.
5.3 Grounded Language
In recent years, there has been an increased interest in connecting language with the
world.18 One of the primary issues in grounded language is alignment—ﬁguring out
what fragments of utterances refer to what aspects of the world. In fact, semantic
parsers trained on examples of utterances and annotated logical form (those discussed
in Section 4.2.2) need to solve the task of aligning words to predicates. Some can learn
from utterances paired with a set of logical forms, one of which is correct (Kate and
Mooney, 2007; Chen and Mooney, 2008). Liang et al. (2009) tackles the even more
difﬁcult alignment problem of segmenting and aligning a discourse to a database of
facts, where many parts on either side are irrelevant.
If we know how the world relates to language, we can leverage structure in the
world to guide the learning and interpretation of language. We saw that type constraints
from the database/world reduces the set of candidate logical forms and lead to more
accurate systems (Popescu et al., 2003; Liang et al., 2011). Even for syntactic parsing,
information from the denotation of an utterance can be helpful (Schuler, 2003).
One of the exciting aspects about using the world for learning language is that
it opens the door to many new types of supervision. We can obtain answers given a
world, which are cheaper to obtain than logical forms (Clarke et al., 2010; Liang et al.,

18 Here, world need not refer to the physical world, but could be any virtual world. The point is that the
world has non-trivial structure and exists extra-linguistically.

55

Computational Linguistics

Volume ?, Number ?

2011). Goldwasser et al. (2011) learns a semantic parser based on bootstrapping and
estimating the conﬁdence of its own predictions. Artzi and Zettlemoyer (2011) learns
a semantic parser not from annotated logical forms, but from user interactions with a
dialog system. Branavan et al. (2009, 2010, 2011) use reinforcement learning to follow
natural language instructions from a reward signal. In general, supervision from the
world is indirectly related to the learning task, but it is often much more plentiful and
natural to obtain.
The beneﬁts can also ﬂow from language to the world. For example, previous work
learned to interpret language to troubleshoot a Windows machine (Branavan et al., 2009,
2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire
(Eisenstein et al., 2009; Goldwasser and Roth, 2011), and navigate a map by following
directions (Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Even when the objective
in the world is deﬁned independently of language (e.g., in Civilization), language can
provide a useful bias towards the non-linguistic end goal.
5.4 Conclusions
The main conceptual contribution of this article is a new semantic formalism,
dependency-based compositional semantics (DCS), and techniques to learn a semantic
parser from question-answer pairs where the intermediate logical form (a DCS tree) is
induced in an unsupervised manner. Our ﬁnal question-answering system was able to
match the accuracies of state-of-the-art systems that learn from annotated logical forms.
There is currently a signiﬁcant conceptual gap between our question-answering
system (which can be construed as a natural language interface to a database) and opendomain question-answering systems. The former focuses on understanding a question
compositionally and computing the answer compositionally, while the latter focuses on
retrieving and ranking answers from a large unstructured textual corpus. The former
has depth; the latter has breadth. Developing methods that can both model the semantic
richness of language and scale up to an open-domain setting remains an open challenge.
We believe that it is possible to push our approach in the open-domain direction.
Neither DCS nor the learning algorithm is tied to having a clean rigid database, which
could instead be a database generated from a noisy information extraction process. The
key is to drive the learning with the desired behavior, the question-answer pairs. The
latent variable is the logical form or program, which just tries to compute the desired
answer by piecing together whatever information is available. Of course, there are many
open challenges ahead, but with the proper combination of linguistic, statistical, and
computational insight, we hope to eventually build systems with both breadth and
depth.
Acknowledgments
We thank Luke Zettlemoyer and Tom Kwiatkowski for providing us with data and answering
questions, as well as the anonymous reviewers for their detailed feedback. The ﬁrst author was
supported by an NSF Graduate Research Fellowship.

References
H. Alshawi, P. Chang, and M. Ringgaard. Deterministic statistical mapping of sentences
to underspeciﬁed semantics. In International Conference on Compositional Semantics
(IWCS), pages 15–24, 2011.

56

Liang et al.

Learning Dependency-Based Compositional Semantics

I. Androutsopoulos, G. D. Ritchie, and P. Thanisch. Natural language interfaces to
databases – an introduction. Journal of Natural Language Engineering, 1:29–81, 1995.
Y. Artzi and L. Zettlemoyer. Bootstrapping semantic parsers from conversations. In
Empirical Methods in Natural Language Processing (EMNLP), pages 421–432, 2011.
J. Baldridge and G. M. Kruijff. Coupling CCG with hybrid logic dependency semantics. In Association for Computational Linguistics (ACL), pages 319–326. Association for
Computational Linguistics, 2002.
C. Barker. Continuations and the nature of quantiﬁcation. Natural Language Semantics,
10:211–242, 2002.
J. Bos. A controlled fragment of DRT. In Workshop on Controlled Natural Language, pages
1–5, 2009.
J. Bos, S. Clark, M. Steedman, J. R. Curran, and J. Hockenmaier. Wide-coverage semantic representations from a CCG parser. In International Conference on Computational
Linguistics (COLING), pages 1240–1246. Association for Computational Linguistics,
2004.
S. Branavan, H. Chen, L. S. Zettlemoyer, and R. Barzilay. Reinforcement learning
for mapping instructions to actions. In Association for Computational Linguistics and
International Joint Conference on Natural Language Processing (ACL-IJCNLP), pages 82–
90, Singapore, 2009. Association for Computational Linguistics.
S. Branavan, L. Zettlemoyer, and R. Barzilay. Reading between the lines: Learning to
map high-level instructions to commands. In Association for Computational Linguistics
(ACL), pages 1268–1277. Association for Computational Linguistics, 2010.
S. Branavan, D. Silver, and R. Barzilay. Learning to win by reading manuals in a MonteCarlo framework. In Association for Computational Linguistics (ACL), pages 268–277.
Association for Computational Linguistics, 2011.
B. Carpenter. Type-Logical Semantics. MIT Press, 1998.
D. L. Chen and R. J. Mooney. Learning to sportscast: A test of grounded language
acquisition. In International Conference on Machine Learning (ICML), pages 128–135.
Omnipress, 2008.
D. L. Chen and R. J. Mooney. Learning to interpret natural language navigation instructions from observations. In Association for the Advancement of Artiﬁcial Intelligence
(AAAI), Cambridge, MA, 2011. MIT Press.
J. Clarke, D. Goldwasser, M. Chang, and D. Roth. Driving semantic parsing from the
world’s response. In Computational Natural Language Learning (CoNLL), pages 18–27,
2010.
M. Collins. Head-Driven Statistical Models for Natural Language Parsing. PhD thesis,
University of Pennsylvania, 1999.
R. Cooper. Montague’s semantic theory and transformational syntax. PhD thesis, University
of Massachusetts at Amherst, 1975.
P. Cousot and R. Cousot. Abstract interpretation: a uniﬁed lattice model for static
analysis of programs by construction or approximation of ﬁxpoints. In Principles of
Programming Languages (POPL), pages 238–252, 1977.
H. Daume, J. Langford, and D. Marcu. Search-based structured prediction. Machine
Learning Journal (MLJ), 75:297–325, 2009.
R. Dechter. Constraint Processing. Morgan Kaufmann, 2003.
J. Eisenstein, J. Clarke, D. Goldwasser, and D. Roth. Reading to learn: Constructing
features from semantic abstracts. In Empirical Methods in Natural Language Processing
(EMNLP), pages 958–967, Singapore, 2009.
R. Ge and R. J. Mooney. A statistical semantic parser that integrates syntax and semantics. In Computational Natural Language Learning (CoNLL), pages 9–16, Ann Arbor,

57

Computational Linguistics

Volume ?, Number ?

Michigan, 2005.
A. Giordani and A. Moschitti. Semantic mapping between natural language questions
and SQL queries via syntactic pairing. In International Conference on Applications of
Natural Language to Information Systems, pages 207–221, 2009.
D. Goldwasser and D. Roth. Learning from natural instructions. In International Joint
Conference on Artiﬁcial Intelligence (IJCAI), pages 1794–1800, 2011.
D. Goldwasser, R. Reichart, J. Clarke, and D. Roth. Conﬁdence driven unsupervised
semantic parsing. In Association for Computational Linguistics (ACL), pages 1486–1495.
Association for Computational Linguistics, 2011.
I. Heim and A. Kratzer. Semantics in Generative Grammar. Wiley-Blackwell, 1998.
J. Judge, A. Cahill, and J. v. Genabith. Question-bank: creating a corpus of parseannotated questions. In International Conference on Computational Linguistics and Association for Computational Linguistics (COLING/ACL), pages 497–504, Sydney, Australia,
2006. Association for Computational Linguistics.
H. Kamp and U. Reyle. From Discourse to Logic: An Introduction to the Model-theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer,
Dordrecht, 1993.
H. Kamp, J. v. Genabith, and U. Reyle. Discourse representation theory. In Handbook of
Philosophical Logic. 2005.
R. J. Kate and R. J. Mooney. Using string-kernels for learning semantic parsers. In
International Conference on Computational Linguistics and Association for Computational
Linguistics (COLING/ACL), pages 913–920, Sydney, Australia, 2006. Association for
Computational Linguistics.
R. J. Kate and R. J. Mooney. Learning language semantics from ambiguous supervision. In Association for the Advancement of Artiﬁcial Intelligence (AAAI), pages 895–900,
Cambridge, MA, 2007. MIT Press.
R. J. Kate, Y. W. Wong, and R. J. Mooney. Learning to transform natural to formal
languages. In Association for the Advancement of Artiﬁcial Intelligence (AAAI), pages
1062–1068, Cambridge, MA, 2005. MIT Press.
T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, and M. Steedman. Inducing probabilistic
CCG grammars from logical form with higher-order uniﬁcation. In Empirical Methods
in Natural Language Processing (EMNLP), 2010.
T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, and M. Steedman. Lexical generalization
in CCG grammar induction for semantic parsing. In Empirical Methods in Natural
Language Processing (EMNLP), pages 1512–1523, 2011.
P. Liang. Learning Dependency-Based Compositional Semantics. PhD thesis, University of
California Berkeley at Berkeley, 2011.
P. Liang and D. Klein. Online EM for unsupervised models. In North American Association for Computational Linguistics (NAACL). Association for Computational Linguistics, 2009.
P. Liang, M. I. Jordan, and D. Klein. Learning semantic correspondences with less
supervision. In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP), Singapore, 2009. Association for
Computational Linguistics.
P. Liang, M. I. Jordan, and D. Klein. Learning programs: A hierarchical Bayesian
approach. In International Conference on Machine Learning (ICML). Omnipress, 2010.
P. Liang, M. I. Jordan, and D. Klein. Learning dependency-based compositional semantics. In Association for Computational Linguistics (ACL), pages 590–599. Association for
Computational Linguistics, 2011.

58

Liang et al.

Learning Dependency-Based Compositional Semantics

W. Lu, H. T. Ng, W. S. Lee, and L. S. Zettlemoyer. A generative model for parsing
natural language to meaning representations. In Empirical Methods in Natural Language
Processing (EMNLP), pages 783–792, 2008.
M. P. Marcus, M. A. Marcinkiewicz, and B. Santorini. Building a large annotated corpus
of English: the Penn Treebank. Computational Linguistics, 19:313–330, 1993.
S. Miller, D. Stallard, R. Bobrow, and R. Schwartz. A fully statistical approach to natural
language interfaces. In Association for Computational Linguistics (ACL), pages 55–61.
Association for Computational Linguistics, 1996.
R. Montague. The proper treatment of quantiﬁcation in ordinary English. In Approaches
to Natural Language, pages 221–242, 1973.
J. Nocedal. Updating quasi-newton matrices with limited storage. Mathematics of
Computation, 35:773–782, 1980.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. Learning accurate, compact, and interpretable tree annotation. In International Conference on Computational Linguistics and
Association for Computational Linguistics (COLING/ACL), pages 433–440. Association
for Computational Linguistics, 2006.
S. T. Piantadosi, N. D. Goodman, B. A. Ellis, and J. B. Tenenbaum. A Bayesian model
of the acquisition of compositional semantics. In Proceedings of the Thirtieth Annual
Conference of the Cognitive Science Society, 2008.
A. Popescu, O. Etzioni, and H. Kautz. Towards a theory of natural language interfaces to
databases. In International Conference on Intelligent User Interfaces (IUI), pages 149–157,
2003.
M. F. Porter. An algorithm for sufﬁx stripping. Program, 14:130–137, 1980.
H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical
Statistics, 22(3):400–407, 1951.
W. Schuler. Using model-theoretic semantic interpretation to guide statistical parsing
and word recognition in a spoken language interface. In Association for Computational
Linguistics (ACL), pages 529–536. Association for Computational Linguistics, 2003.
C. Shan. Delimited continuations in natural language. Technical report, ArXiv, 2004.
M. Steedman. The Syntactic Process. MIT Press, 2000.
L. R. Tang and R. J. Mooney. Using multiple clause constructors in inductive logic
programming for semantic parsing. In European Conference on Machine Learning, pages
466–477, 2001.
A. Vogel and D. Jurafsky. Learning to follow navigational directions. In Association
for Computational Linguistics (ACL), pages 806–814. Association for Computational
Linguistics, 2010.
M. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1:1–307, 2008.
D. Warren and F. Pereira. An efﬁcient easily adaptable system for interpreting natural
language queries. Computational Linguistics, 8:110–122, 1982.
M. White. Efﬁcient realization of coordinate structures in combinatory categorial grammar. Research on Language and Computation, 4:39–75, 2006.
Y. W. Wong and R. J. Mooney. Learning for semantic parsing with statistical machine
translation. In North American Association for Computational Linguistics (NAACL), pages
439–446, New York City, 2006. Association for Computational Linguistics.
Y. W. Wong and R. J. Mooney. Learning synchronous grammars for semantic parsing
with lambda calculus. In Association for Computational Linguistics (ACL), pages 960–
967, Prague, Czech Republic, 2007. Association for Computational Linguistics.
W. A. Woods, R. M. Kaplan, and B. N. Webber. The lunar sciences natural language
information system: Final report. Technical report, BBN Report 2378, Bolt Beranek

59

Computational Linguistics

Volume ?, Number ?

and Newman Inc., 1972.
M. Zelle and R. J. Mooney. Learning to parse database queries using inductive logic
proramming. In Association for the Advancement of Artiﬁcial Intelligence (AAAI), pages
1050–1055, Cambridge, MA, 1996. MIT Press.
L. S. Zettlemoyer and M. Collins. Learning to map sentences to logical form: Structured classiﬁcation with probabilistic categorial grammars. In Uncertainty in Artiﬁcial
Intelligence (UAI), pages 658–666, 2005.
L. S. Zettlemoyer and M. Collins. Online learning of relaxed CCG grammars for parsing
to logical form. In Empirical Methods in Natural Language Processing and Computational
Natural Language Learning (EMNLP/CoNLL), pages 678–687, 2007.

60

