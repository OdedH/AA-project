Linking people in videos with “their” names
using coreference resolution (Supplementary
Material)
Vignesh Ramanathan∗ , Armand Joulin† , Percy Liang† , Li Fei-Fei†
∗

Department of Electrical Engineering, Stanford University
†
Computer Science Department, Stanford University
{vigneshr, armand, pliang, feifeili}@cs.stanford.edu

1

Episodes from the dataset

The episodes which are part of Development and Test set are shown in Tab. 1.

Development Set
Test Set
1. Numb3rs 3x11
15. Highlander 5x14
2. Castle 1x03
16. Highlander 5x20
3. Highlander 5x02
17. Castle 1x09
4. Highlander 5x06
18. The Mentalist 1x19
5. The Mentalist 1x08
19. Californication 1x01
6. The Mentalist 1x22
7. The Mentalist 3x11
8. The Good Wife 1x10
9. The Good Wife 1x20
10. Twin Peaks 2x03
11. Desperate Housewives 1x04
12. 30 Rock 1x12
13. Sliders 4x02
14. Numb3rs 3x05
Table 1. The episodes used in our experiments are shown.

2

Optimization in terms of the alignment matrix

We ﬁrst show that AT Y − Z 2 is equivalent to −2tr AT Y Z plus an addiF
tive constant, and then we provide the Dynamic Programming algorithm for
optimizing tr AT Y Z with respect to M .
We note that Z1P = 1M and Z ∈ {0, 1}M ×P . Hence, exactly M elements of
the matrix are set to 1. This results in Z 2 = tr(Z T Z) = M . Similarly, for the
F
matrix AT Y , we can show that AT Y 2 = tr AT Y Y T A = M .
F

2

Vignesh Ramanathan∗ , Armand Joulin† , Percy Liang† , Li Fei-Fei†

AT Y − Z

2
F

= tr Z T Z + tr AAT Y Y T − 2tr Y T AZ

(1)

T

= 2M − 2tr Y AZ .
Note that, in the absence of the integer relaxation, the matrix (AT Y ) has
the same properties as Z, where each row sums to 1, and the elements are in
{0, 1}. Hence, T r(Y T AAT Y ) = tr(Z T Z) = M . Hence, minimizing AT Y − Z 2
F
is equivalent to maximizing tr(Y T AZ).
We denote by Tm the set of tracks which are aligned with a mention m,
based on the crude alignment of the descriptions with the video. The Dynamic
program to maximize tr(Y T AZ) with respect to A is shown in Algo. 1.

Data: Y ∈ PT P , Z ∈ PM P , {Tm , ∀ m ∈ M}
Result: A ∈ {0, 1}T ×M
Initialization:
˜
A ← ZY T ;
for m = 0 → M do
for t = 0 → T do
Ctm ← 0, Itm ← 0;
end
end
Cost update:
for m = 1 → M do
for t = 1 → T do
Atm ← 0;
if t ∈ Tm then
/
˜
Atm ← −∞
end
˜
if Ct−1m ≤ Ctm−1 + Atm then
˜tm ;
Ctm ← Ctm−1 + A
Itm ← t;
end
Ctm ← Ct−1m ;
Itm ← It−1m ;
end
end
Backtracking:
t ← T, m ← M ;
while m ≥ 1 do
t ← Itm ;
Atm ← 1;
m ← m − 1;
end

Algorithm 1: Dynamic program algorithm for optimizing with respect to A

Title Suppressed Due to Excessive Length

3

3

Coreference features

The coreference features are based on the standard features used in coreference
resolution systems such as [2, 1]. They include two sets of features corresponding
to (i) features between a pair of diﬀerent mentions, and (ii) features extracted
from a single mention. These features are concatenated to form the ﬁnal pairwise
coreference feature Φmention , between the mentions i, j. The ﬁrst set of features
ij
are active when the two mentions are diﬀerent (i = j), and the second set of
features are active when the two mentions are the same (i = j). All the features
are discretized and represented by binary vectors.
The coreference features between a pair of diﬀerent mentions, are brieﬂy
explained below.
1. Sentence distance: The number of sentences between the two mentions.
2. Parse tree distance: The distance between the mentions on the semantic
parse tree.
3. Word distance: The number of words between the two mentions.
4. Animacy agreement: Indicates if the two mentions agree on animacy values.
5. Gender agreement: Indicates if the two mentions agree on gender values.
6. Cardinality agreement: Indicates if the two mentions agree on cardinality.
7. Head word agreement: Indicates if the mentions have the same headword.
8. Inside: Indicates if one mention is contained inside the other.
9. Appositions: Indicates if a mention is the apposition of the other.
10. Role Appositions: Indicates if a mention is the role apposition of the other.
11. Predicate Nominative: Indicates if a mention is the predicate nominative of
the other.
The coreference features extracted from a single mention are explained below:
1.
2.
3.
4.
5.
6.
7.

4

Mention type: The mention type such as pronoun, nominal, or a proper noun.
Subject: Indicates if the mention is a subject in the sentence.
Direct Object: Indicates if the mention is a direct object.
Gender : Gender of the mention.
Animacy: Animacy of the mention.
Cardinality: Cardinality indicating if the mention is singleton or pronoun.
Presence in cast list: Indicates if the word corresponding to the mention is
part of the cast list P.

Additional constraints for the mention naming model

First, we show the computation of the matrix B(Φmention , λmention ) used in the
clustering cost for coreference resolution of the main paper. Next, we explain
the complete formulation of the mention naming model to include additional
constraints such as gender agreement.
The M 2 × M 2 matrix B is obtained by ﬁrst computing the M 2 × M 2 coreference feature kernel Kc . Each element in Kc corresponds to two pairs of mentions.

4

Vignesh Ramanathan∗ , Armand Joulin† , Percy Liang† , Li Fei-Fei†

Since the ith element in the M 2 × M 2 vector vec(R) corresponds to (irow , icol )th
i
element in the matrix R, where irow = M , and icol = i − M 2i−1 , we use the
2M
same notation while computing the kernel matrix. The (i, j)th element in this
ij
kernel Kc is shown below.
ij
Kc = Φmention · Φmention
irow icol
jrow jcol

(2)

The matrix B is then computed as follows,

B(Φmention , λmention ) = λmention Π ΠKc Π + M 2 λmention I
where Π = I −

11T
1T 1

−1

Π,

(3)

and λmention is the regularization parameter.

Gender constraint. Let gm denote the gender of the mention m ∈ M. Two
mentions i, j are connected to each other only if their genders gi and gj are
equal. This is a very valuable cue, as noted in most of the coreference resolution
systems such as [1, 2].
Pronoun constraint. Let Mpro. be the set of pronouns from the script. A
mention belonging to this set is not allowed to connect to itself as an antecedent.
This constraint forces the name corresponding to a pronoun to be obtained from
another mention.
Cast constraint. Let Mcas. be the set of mentions such that, the word corresponding to the mention is the same as a person name from our cast list P. For
instance, the mention “John” in the sentence “John eats an apple”, if the cast
list includes the name “John”. Let, pm ∈ P be the cast name corresponding to
a mention m ∈ Mcas. . For such a mention m, we enforce Rmm to be equal to 1,
and the corresponding element Zmpm in the matrix Z to be equal to 1.

5

Modiﬁed version of coreference resolution from
Haghighi and Klein [1]

This baseline used for comparison in Tab. 2 of our paper can be viewed as a
probabilistic version of our unidirectional model. The model assumes that every
mention is associated with an antecedent mention, occurring before it in the
text. The choice of the antecedent mention is given by the M × M matrix U
with entries in 0, 1, where the (i, j)th element is set to 1, if the mention i is the
antecedent mention j. The probability of choosing i as the antecedent to j is
associated with the coreference feature Φmention and a weight vector wm . The
ij
coreference model is as shown in Eq. 4.

Title Suppressed Due to Excessive Length

p(Z, U |Φmention ; wm ) ∝ Φ(U, Φmention , wm )

Ψ (zi , · · · , z1 , ui )

5

(4)

i

Φ(uij , Φmention , wm ) = exp 1(uij = 1)wm · Φmention
ij
Ψ (zi , · · · , z1 , ui ) =

∀i ≤ j

1 − , if ∀ uji = 1, zi = zj
,
otherwise

where is a small value, zi is the ith column in Z, uij is the (i, j)th element of
U , and ui is its ith column.
In addtion to these factors, we also assign priors based on diﬀerent constraints, similar to our unidirectional model described in the previous section.
Following [1], we learn the model through a mean-ﬁeld approximation. We assume a distribution qz (Z) for Z and qu (U ) for U . The coreference resolution can
then be performed by solving the optimization problem shown below:
max Eqz ,qu L(Z, U |Φmention ; wm ) + Hq ,

qz ,qs ,wm

where L(Z, U |Φmention ; wm ) is the log-likelihood of p form Eq. 4 and Hq is the
entropy of qz , qu .

References
1. Haghighi, A., Klein, D.: Coreference resolution in a modular, entity-centered model.
In: HLT-NAACL (2010)
2. Lee, H., Peirsman, Y., Chang, A., Chambers, N., Surdeanu, M., Jurafsky, D.: Stanford’s mulit-pass sieve coreference resolution system at the conll-2011 shared task.
In: CoNLL-2011 Shared Task (2011)

