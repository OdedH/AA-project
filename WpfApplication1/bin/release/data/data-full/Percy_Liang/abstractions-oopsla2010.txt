A Dynamic Evaluation of the Precision
of Static Heap Abstractions
Percy Liang

Omer Tripp

Mayur Naik

UC Berkeley
pliang@cs.berkeley.edu

Tel-Aviv University
omertrip@post.tau.ac.il

Intel Labs Berkeley
mayur.naik@intel.com

Mooly Sagiv
Tel-Aviv University
msagiv@post.tau.ac.il

Abstract
The quality of a static analysis of heap-manipulating programs is largely determined by its heap abstraction. Object
allocation sites are a commonly-used abstraction, but are too
coarse for some clients. The goal of this paper is to investigate how various reﬁnements of allocation sites can improve
precision. In particular, we consider abstractions that use call
stack, object recency, and heap connectivity information. We
measure the precision of these abstractions dynamically for
four different clients motivated by concurrency and on nine
Java programs chosen from the DaCapo benchmark suite.
Our dynamic results shed new light on aspects of heap abstractions that matter for precision, which allows us to more
effectively navigate the large space of possible heap abstractions.
Categories and Subject Descriptors D.2.4 [Software Engineering]: Software/Program Veriﬁcation
General Terms
tion

Measurement, Experimentation, Veriﬁca-

Keywords heap abstractions, static analysis, dynamic analysis, concurrency

1.

Introduction

Many static analyses of heap-manipulating programs require
reasoning about the heap. This reasoning is driven by a
heap abstraction, a systematic way to partition the typically

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior speciﬁc permission and/or a fee.
OOPSLA/SPLASH’10, October 17–21, 2010, Reno/Tahoe, Nevada, USA.
Copyright c 2010 ACM 978-1-4503-0203-6/10/10. . . $10.00

unbounded number of concrete objects at run-time into a
ﬁnite set of abstract objects. The choice of heap abstraction
impacts the precision and scalability—and ultimately the
usability—of a static analysis.
Object allocation sites are perhaps the most popular kind
of heap abstraction. Analyses based on this abstraction place
all objects allocated at the same site in the program into
the same partition. Though useful in some cases, allocation
sites are too coarse to prove many properties of interest.
Consequently, a plethora of reﬁnements have been proposed
in the literature (e.g., [4, 20, 24, 27, 31]). The goal of this
paper is to understand which types of reﬁnement are most
useful for various clients.
Abstractions We focus on a family of heap abstractions
that reﬁne object allocation sites by augmenting the abstraction of an object with information of the following kind:
Call stack We add the chain of the k most recent call sites
on the stack of the thread creating the object. The resulting heap abstraction, known as k-CFA [31] with heap
cloning or heap specialization, is popular in points-to
analyses for both procedural and object-oriented languages (e.g. C and Java).
Object recency If an object is the i-th to last allocated at
its allocation site, the recency index of that object is
min{i−1, r}, where r is a ﬁxed maximum depth. Adding
the recency index allows us to distinguish the last r objects created at an allocation site and from all other objects created earlier at that site.1 This heap abstraction,
called the recency abstraction [4, 24], is particularly useful for ﬁne-grained reasoning about loops, as it allows
distinctions between objects created in different iterations of the same loop.
1 Note

that in this paper, we use the term recency to refer to recency of
allocation, not recency of access.

Heap connectivity We distinguish objects by their connectivity properties in the heap, e.g., by associating an object o with the allocation sites of other objects that can
reach o through the heap graph. These heap connectivity
predicates are common in shape analysis [27], and allow
reasoning about complex data structures.
Clients As we will see, the precision of a heap abstraction
depends heavily on the client. In this study, we study four
clients for Java which are motivated by concurrency—static
race and deadlock detection, in particular.
The T HREAD E SCAPE client asks whether a particular
heap-accessing statement in the program (that is, an access
to an instance ﬁeld or array element) ever accesses objects
which are reachable from a static ﬁeld (and thus potentially
accessible by more than one thread). The S HAREDACCESS
client asks a stronger question: whether that object is actually accessed by multiple threads. These two clients are useful for static race detection: a statement is race-free if it only
accesses thread-local data.
The S HARED L OCK client is related, asking whether a
lock acquisition statement in the program ever holds a lock
that is ever held by more than one thread. This client is
similarly useful for static deadlock detection: a statement
cannot be involved in a deadlock if it holds a lock that is
only ever held by one thread.
Finally, the N ON S TATIONARY F IELD client asks whether
a given instance ﬁeld f in the program is stationary [32],
that is, whether for every object o, all writes to o.f precede
all reads of o.f . This client is again useful for race detection:
a pair of read-write statements accessing f cannot race if f
is stationary.
Methodology We evaluated our heap abstractions on the
clients described above on nine concurrent Java programs
from the DaCapo benchmarks suite [5]. While our motivation is ultimately static analysis, our methodology for evaluating our family of abstractions and clients is based on a dynamic analysis. Speciﬁcally, a program is run concretely, and
abstractions are computed on the ﬂy, against which queries
are answered. Working in this setting allows us to focus only
on heap abstractions, since we assume that all other aspects
static analyses must contend with (e.g., primitive data, destructive updates, merge points, and method summarization)
are handled optimally.
This dynamic setting therefore provides an upper bound
on the precision of the best possible static analysis that uses
a given heap abstraction. While we cannot say deﬁnitively
that an abstraction will work well within a static analysis due
to other compounding factors, we can certainly show that a
heap abstraction is ineffective for some client. For example,
for the T HREAD E SCAPE client on the luindex benchmark,
only 6.3% of the queries reported to be escaping by using
the allocation site abstraction are actually escaping. In this
case, the heap abstraction is clearly a bottleneck: no amount
of work on the other aspects of static analysis can help.

Summary of Main Results
1. We show that the precision of an abstraction on a client
is in part driven by whether the abstraction is in line
with the properties of the client. For example, for the
N ON S TATIONARY F IELD client, R ECENCY (deﬁned in
Section 4.2) works quite well because both the client and
the abstraction involve temporal properties. On the other
hand, increasing k has virtually no impact.
2. We evaluated the effect of varying the call site depth k
for abstractions based on k-CFA. For T HREAD E SCAPE,
we showed that as k increases, the precision undergoes a
sharp phase transition, with the critical k value occurring
between k = 3 and k = 6.
3. We found that R ECENCY is an important dimension overall, leading to the highest precision on three of the four
clients. We also show that increasing the recency depth r
improves precision past r = 1, which has been the only
case studied in past work.
4. We show that adding reﬁnements along multiple dimensions simultaneously can be important. In one case,
R EACH F ROM does not improve precision over A LLOC
until we use k-CFA with k ≥ 5. In another case, increasing the recency depth from r = 1 to r = 2 is useless
unless k is large enough.
5. We use the number of abstract objects (which we call
abstraction size) to measure the potential scalability of
an abstraction. We found that R ECENCY offers the best
tradeoff between precision and size.
The rest of the paper is organized as follows. Section 2
formalizes our methodology. Section 3 describes our four
clients and Section 4 describes our family of heap abstractions. Sections 5 and 6 describe the benchmarks and experimental setup, respectively. Section 7 presents our results.
Section 8 surveys related work, and Section 9 concludes.

2.

Methodology

We present the general framework for our empirical study.
The basic idea is this: We run a dynamic analysis that maintains the concrete environment, heap, and various other instrumentation. At various points along the execution trace,
the abstraction is applied to the concrete state to produce an
abstract state, which is used to answer client queries.
2.1

Program Syntax and Semantics

We now present our dynamic analysis. Figure 1 provides
the relevant notation. A program is described by a set of
program points P, where each program point p ∈ P has
a statement stmt(p) ∈ S. Figure 1 provides the full list
of statements; For example, an instance ﬁeld read takes the
form v1 = v2 .f for local variables v1 , v2 ∈ V and instance
ﬁeld f ∈ F.2 The statement spawn v creates a new thread by
2 We

use f to denote both instance ﬁelds and array indices.

Syntactic domains:

For abstractions:

(program point) p
(static ﬁeld) g
(local variable) v
(instance ﬁeld or array index) f
s ∈
s ::=
|
|
|
(stmt. at point) stmt ∈

(primitive stmt.)

∈
∈
∈
∈

(allocation site) h ∈ H
(allocation site of object) as ∈ O → H
(objects in order of creation) os ∈ O∗
(method call site)
i ∈ I
(method call stack of object) cs ∈ O → I∗

P
G
V
F

S
v = null | v = new
v1 = v2 | v = g | g = v
v1 = v2 .f | v1 .f = v2
spawn v | lock v
P→S

For clients:
(thread-escaping objects) esc ∈ P(O)
(threads accessing an object) accs ∈ O → P(T)
(threads locking an object) lcks ∈ O → P(T)
(object-ﬁeld pairs read) rds ∈ P(O × F)

Semantic domains:
(object) o ∈
(environment) ρ ∈
(thread ID) t ∈
(threads) θ ∈
(heap) σ ∈
(auxiliary instr.) u ∈
(state) ω ∈
(trace) r ::=
(query)

q

∈

O
Λ = V → (O ∪ {null})
T
Θ = T → (P × Λ)
Σ = (O × F) → (O ∪ {null})
U
Ω = T×Θ×Σ×U
[ω1 , ..., ωn ]
Q ⊂ (Ω → bool )

Figure 1. Program trace syntax and semantic domains. Let
ω.t, ω.θ, ω.σ, and ω.u correspond to the components of
a state ω. For convenience, also deﬁne ω.p = ω.θ(ω.t).p
to be the program point of the current thread ω.t, and let
ω.ρ = ω.θ(ω.t).ρ be the environment of thread ω.t.

Figure 2. Auxiliary instrumentation u ∈ U needed by various abstractions and clients. Let ω.esc, ω.accs, ω.lcks, and
ω.rds denote the instrumentation collected for state ω. Sections 3 and 4 provide the semantics of these quantities.

(abstract object)
(abstraction function)

a ∈ A
α ∈ (Ω × O) → A

(abstract env.) ρα
(abstract threads) θα
(abstract heap) σ α
(abstract aux. instr.) uα
(abstract state) ω α
(abstract query) q α

∈
∈
∈
∈
∈
∈

Λα = V → A
Θα = T → (P × Λα )
Σα = (A × F) → P(A)
Uα
Ωα = T × Θ α × Σα × Uα
Q ⊂ (Ω → bool )

Figure 3. Abstract versions of our semantic domains.
calling java.lang.Thread.start() with this set to the
object pointed to by v. The statement lock v acquires a lock
on the object pointed to by v. We are not concerned with the
control-ﬂow graph of the program as our analysis is dynamic
and depends only on the execution trace (deﬁned below).
Having established the syntax, we now describe the semantics of program execution. When the program executes,
there are a set of threads indexed by a set of thread IDs T. For
each thread ID t ∈ T, θ(t) speciﬁes two pieces of information about that thread: (1) a current program point θ(t).p ∈ P
and (2) an environment θ(t).ρ ∈ Λ, which maps each local
variable v ∈ V to the concrete object θ(t).ρ(v) ∈ O that
v points to. All threads share a heap σ ∈ Σ, which is a directed graph whose nodes are concrete objects and edges are
pointers labeled with an instance ﬁeld or array index. In particular, σ(o, f ) = o means object o ∈ O points to o ∈ O
via ﬁeld f ∈ F.
At any time during program execution, there is a state
ω ∈ Ω, which contains the following information: (1) the
ID ω.t ∈ T of the thread that is about the execute, (2)
the threads ω.θ ∈ Θ, (3) the heap ω.σ ∈ Σ, and (4) any
auxiliary instrumentation ω.u ∈ U which is needed either

by the abstraction or client. This instrumentation (detailed
in Figure 2) includes information such as object allocation
sites and call stack information.
A full program execution is represented by a trace r,
which is a sequence of states [ω1 , . . . , ωn ]. We omit the
concrete semantics for the various statements as it is standard. The auxiliary instrumentation warrants more discussion, which we defer to Section 3.
2.2

Abstractions

An abstraction function α, the central object of interest in
this paper, maps a concrete object o ∈ O, in the context of
a concrete state ω ∈ Ω, to an abstract object a = α(ω, o)
in some abstract domain A (see Figure 3).3 Intuitively, α
deﬁnes an equivalence relation over objects such that objects
in the same equivalence class are not distinguished. For
example, the classical object allocation site abstraction maps
o ∈ O to the site h ∈ H where o was allocated. However,
the abstraction function can in general depend on any aspect
3 For

convenience, deﬁne α(ω, null) = null.

of the current state ω, which will be crucial for deﬁning the
reachability and recency abstractions (Section 4).
The abstraction function α can be used to map concrete
objects to abstract objects, but in order to answer queries,
we will use α to map a concrete state ω to an abstract state
ω α . We construct ω α by applying α to the various parts of
ω = (t, θ, σ, u) as follows:
1. For the current thread ID t, no abstraction is performed.
2. For the thread θ(t) = (p, ρ) with program point p and
environment ρ, we deﬁne θα (t) = (p, ρα ), where the
abstract environment ρα is computed by applying the
abstraction α to the object ρ(v) to which a variable v ∈ V
points:
ρα (v) = α(ω, ρ(v)).
(1)
3. For the heap σ, we deﬁne the abstract heap σ α by collapsing objects in the heap graph that map to the same
abstract object:
σ α (a, f )

= {a ∈ A : ∃o, o ∈ O, σ(o, f ) = o ,
a = α(ω, o), a = α(ω, o )}.

(2)

Note that in the abstract graph, there might be more than
one edge leaving a node with the same ﬁeld label.
4. For a given auxiliary instrumentation u, the abstract instrumentation uα consists of abstracted versions of the
information needed for clients (the concrete versions are
described in Section 3):
• The abstract escaping set escα consists of the set of

abstract values taken on by some concrete object in
the concrete escaping set esc:
escα = {α(ω, o) : o ∈ esc}.

(3)

• Whereas accs maps a concrete object to the set of

threads that have accessed it, accsα maps an abstract
object a to the set of threads that have accessed any
concrete object with abstraction a:
accsα (a) =

accs(o).

(4)

o:α(ω,o)=a

• Similarly, lcksα maps an abstract object a to all the

threads that have locked any concrete object with abstraction a:
lcksα (a) =

lcks(o).

(5)

o:α(ω,o)=a

• Finally, rdsα is the set of all pairs (a, f ) such that

some object with abstraction a had its ﬁeld f read:
rdsα = {(α(ω, o), f ) : (o, f ) ∈ rds}.

(6)

From these four cases, we can observe the general recipe
for constructing abstract instrumentations: for sets whose
elements involve objects (e.g., esc and rds), project these
objects onto their abstractions; for functions mapping
objects to sets (e.g., accs and lcks), construct a mapping
from abstract values to a union of those sets.
2.3

Answering Queries

A client is speciﬁed by a set of queries which each operate
on a trace. An example of a query for T HREAD E SCAPE is:
at program point p, does variable v ever point to an object
which is reachable from a static ﬁeld or was the argument of
spawn?
It will be useful to formulate a query q on a trace r =
[ω1 , . . . , ωn ] in terms of a disjunction over individual queries
on each state ωi in the trace:
n

q(r) =

q(ωi ).

(7)

i=1

For example, the T HREAD E SCAPE query speciﬁed by (p, v)
is true if at any point in the trace where the current statement
is p, v points to thread escaping data (see Section 3.1 for
more details).
Henceforth, we will consider the client to be deﬁned by a
set of queries Q, where each query q ∈ Q maps a concrete
state ω to a boolean indicating whether a given property
holds on that state. These queries induce the quantity of
interest via a disjunction over the states in the dynamic trace
(7). Note that a static answer to the query would involve a
further disjunction over all possible traces of a program.
To evaluate an abstraction with respect to a client, we
must be able to answer queries against the abstraction. For a
query q ∈ Q and an abstraction α, we let q α ∈ Ωα → bool
denote an abstract query.
The optimal abstract query, based on supervaluational semantics, would return true for an abstract state if the concrete
query is true for any state ω with that abstract state:
α
qopt (x) =

q(ω).

(8)

ω:ω α =x

This query is both sound and complete, but is in general
a difﬁcult quantity to compute, so we will present sound
approximations—that is, q α for which the following condition holds:
q(ω) = 1

⇒

q α (ω α ) = 1.

(9)

We measure the quality of an abstraction α by precision,
the fraction of queries answered true under the abstraction
which are actually true concretely:
precision(α, r) =

|{q ∈ Q : q(r)}|
.
|{q ∈ Q : q α (rα )}|

(10)

Note that queries are based on static code artifacts (for
example, for T HREAD E SCAPE, queries correspond to all

variables at all heap-accessing program points), not on dynamic objects. Therefore, a small change in a single object which is pointed to by many variables can affect many
queries, and thus have a large impact on precision. Some
of this sensitivity is intrinsic to the clients. For example, in
T HREAD E SCAPE, adding a single link in the heap can cause
an arbitrary large set of objects to escape.

set esc of the next state ω is deﬁned to be the set of objects
o which are reachable via the heap graph ω.σ (denoted
ω.σ
o
o ) from an object o satisfying any of the following
three conditions:

3.

3. the current statement executed is spawn v and v points to
o (that is, stmt(ω.p) ≡ spawn v and ω.ρ(v) = o). This
condition captures the fact that objects o which are passed
into newly created threads (via spawn) also escape.

Clients

We study four clients motivated by concurrency. In particular, these clients can be used by higher-level analyses for
ﬁndings concurrency defects such as races and deadlocks.
Some have additional applications which we will discuss
later.
We chose the clients to satisfy three requirements: (1) the
client should be useful for solving a real-world problem;
(2) the client should have a clear evaluation metric based
on precision; and (3) the client should require reasoning
about the heap and thus depend on the quality of the heap
abstraction. For low-level clients with no clear application,
it would be hard to appreciate the effect of the abstraction.
On the other hand, high-level clients are more problematic
from a methodological perspective, as they often require
more than a good heap abstraction and might be harder to
evaluate.
For each client, we formulate the property of interest in
terms of queries of the form q ∈ Ω → bool. We show how
these queries can be computed form the auxiliary instrumentation. We also deﬁne the abstract query q α .
3.1

T HREAD E SCAPE

A key problem in the analysis of concurrent programs is
identifying which data in a program is thread-local, i.e.,
reachable from at most one thread. Information about threadlocality is useful for reducing false positives in static race
and deadlock analyses [25], as well as reducing the runtime overhead of software-transactional memory [35] and
dynamic analyses for ﬁnding concurrency defects [10].
More efﬁcient memory allocators and garbage collectors for
multi-threaded programs, as well as optimizations in multithreaded programs under sequentially-consistent memory
models, can also beneﬁt from thread-locality [15].
One way to obtain this information is by asking threadescape queries: At a program point p ∈ P, can a given
variable v ∈ V ever point to an object which is reachable
from more than one thread (e.g., by following a series of ﬁeld
pointers from a static ﬁeld)? This question can be expressed
as a disjunction over the states ω in the trace (7) of the
following query:
T HREAD E SCAPE(p, v)(ω)

(11)

ω.p = p ∧ ω.ρ(v) ∈ ω.esc.
We now deﬁne the escaping set esc. The set esc of the
initial state ω1 is empty. Given the set esc of a state ω, the

1. o ∈ esc,
2. the current statement sets some static ﬁeld g ∈ G to point
to o (that is, stmt(ω.p) ≡ g = v and ω.ρ(v) = o), or

Now, we need to deﬁne the set of queries Q. Motivated
by race detection, we include query T HREAD E SCAPE(p, v)
if p is an instance ﬁeld or array element read/write statement
and v is the variable whose ﬁeld is being accessed, namely
v.f = y or y = v.f for some variable y.
Given an abstraction α, the natural abstract query would
be as follows:
T HREAD E SCAPEα (p, v)(ω α )
α

(12)
α

α

α

α

ω .p = p ∧ ω .ρ (v) ∈ ω .esc .
However, this abstract query is costly to evaluate, because
we would need to compute graph reachability to ascertain
α(ω, o) ∈ ω α .escα for each state ω in the trace. We therefore
deﬁne a new set ω.esc, which is a relaxation of the escaping
set ω.esc (that is, ω.esc ⊂ ω.esc): The transfer function
for esc is analogous to that of esc, with the exception that
reachability is deﬁned with respect to the abstract heap—
ω α .σ α
that is, o reaches o iff α(ω, o)
α(ω, o ).
Intuitively, we are using the abstraction to update the
escaping information directly, instead of only using it to
answer queries. The resulting query under the relaxation is
the same as (12), only with escα replaced with
escα

{α(ω, o) : o ∈ ω.esc}.

(13)

Note that ω.escα ⊂ ω.escα , so the resulting relaxed abstract
query is still sound.
3.2

S HAREDACCESS

Another property that captures the notion of thread nonlocality is S HAREDACCESS. Unlike T HREAD E SCAPE, which
deems an object to be non-local simply when it is reachable
from more than one thread, S HAREDACCESS deems an object to be non-local when it is actually accessed from more
than one thread—a stronger property.
We deﬁne an access to be an instance ﬁeld or array element read/write. Intuitively, an object o is considered thread
shared if there are two states along the execution trace
ω1 and ω2 , such that the two statements stmt(ω1 .p) and
stmt(ω2 .p) access some ﬁeld of the same object but are
executing under different threads (ω1 .t = ω2 .t). This property is easy to answer given the the auxiliary instrumentation

ω.accs, which provides for each object the set of threads that
have accessed it:
S HAREDACCESS(p, v)(ω)

(14)

ω.p = p ∧ |ω.accs(ω.ρ(v))| > 1.
The set of queries Q corresponds to all ﬁeld accessing statements, as in T HREAD E SCAPE (Section 3.1).
We now deﬁne the access sets accs. For the initial state,
accs(o) is empty for each object o. Given the set accs(o) of
state ω, the set accs (o) of the next state ω includes threads
t which satisfy any of the following:
1. t ∈ accs(o), or
2. t is the current thread (ω.t = t) and a ﬁeld of o is accessed
(that is, stmt(ω.p) ∈ {x.f = y, y = x.f } for any y and
ω.ρ(x) = o).
The abstract query S HAREDACCESSα (p, v) is answered
by seeing if v points to an object with an abstraction ω.ρα (v)
that has been accessed by more than one thread:
S HAREDACCESSα (p, v)(ω α )

(15)

ω α .p = p ∧ |ω α .accsα (ω α .ρα (v))| > 1.
Recall that ω α .accsα (a) is the union of ω.accs(o) over
objects o with abstraction a.
3.3

2. t is the current thread (ω.t = t) and a lock is placed on o
(stmt(ω.p) = lock v and ω.ρ(v) = o).
The abstract query S HARED L OCKα (p, v) is deﬁned according to S HARED L OCK(p, v), but replacing ω with ω α , ρ with
ρα , and lcks with lcksα in (17).
3.4

Stationary ﬁelds were ﬁrst introduced by Unkel and Lam [32]
as a generalization of the final keyword in Java. A ﬁeld is
considered stationary if all instances of the class declaring
the ﬁeld satisfy the property that all writes to the ﬁeld occur
before all reads.
As noted in [32], knowing which ﬁelds are stationary provides an object-oriented basis for reasoning about aliasing
relations across time; such information can be used, e.g., by
a deadlock analysis when reasoning about aliasing between
locks stored as object ﬁelds. A more immediate application
is in race detection, where a pair of read/write statements on
the same ﬁeld f is race-free if f is stationary.
We deﬁne the query on the negation of the stationary-ﬁeld
property. A ﬁeld is non-stationary if there exists a state ω in
the trace such that N ON S TATIONARY F IELD(f )(ω) returns
true, where N ON S TATIONARY F IELD(f )(ω) returns true if
the current statement (stmt(ω.p)) writes to ﬁeld f of an
object o which has been previously read ((o, f ) ∈ ω.rds).
Formally:

S HARED L OCK

N ON S TATIONARY F IELD(f )(ω)

A thread-shared lock is an object used by a lock acquisition
statement that is executed by more than one thread. The
statement lock v captures the three cases of lock acquisition
in Java: (1) synchronized static methods, in which the lock
object is the class object; (2) synchronized instance methods,
in which the lock object is the this object; and (3) blocks
of the form synchronized(v) { ... }, in which the lock
object is v.
One natural application of the S HARED L OCK client is
synchronization removal [2, 3, 6–8, 26]. However, in recent years this problem has been obviated by advances
in hardware and JVMs. Static deadlock detection, on the
other hand, remains an important problem, which can beneﬁt greatly from knowing which synchronization operations
can safely be ignored.
By analogy to S HAREDACCESS, we deﬁne S HARED L OCK
by replacing accs with lcks:
S HARED L OCK(p, v)(ω)

(16)

ω.p = p ∧ |ω.lcks(ω.ρ(v))| > 1.
The deﬁnition of lock sets lcks is similar to that of accs.
Initially, lcks(o) is empty. Given the set lcks(o) of state ω,
the set lcks (o) of the next state ω includes threads t which
satisfy any of the following:
1. t ∈ lcks(o), or

N ON S TATIONARY F IELD

(17)

(stmt(ω.p) ≡ x.f = y) ∧ (ω.ρ(x), f ) ∈ ω.rds.
We need to deﬁne rds. Given the set rds of state ω, the
set rds of the next state ω includes each (o, f ) satisfying
any of the following:
1. (o, f ) ∈ rds, or
2. the current statement reads from ﬁeld f of object o (that
is, stmt(ω.p) ≡ y = x.f for any y and ω.ρ(x) = o).
The abstract query N ON S TATIONARY F IELDα (f ) is answered analogously to N ON S TATIONARY F IELD(f ), but replacing ω with ω α , ρ with ρα , and rds with rdsα .

4.

Abstractions

In this section, we present a family of heap abstractions that
we will study. Abstractions in this family reﬁne the classic
allocation site abstraction along three dimensions: call stack,
object recency, and heap connectivity.
Recall that an abstraction function α maps an object o ∈
O in a state ω ∈ Ω to an abstract object α(ω, o) ∈ A, where
this mapping is computed using the appropriate auxiliary
instrumentation ω.u ∈ U (see Figure 2). The allocation
site abstraction, denoted A LLOC, maps an object to the site
where it was allocated:
A LLOC(ω, o) = ω.as(o).

(18)

Although very popular, the plain allocation site abstraction can be too coarse to prove many properties [17]. In the
subsequent three sections, we will walk through the three dimensions of reﬁnement, using a T HREAD E SCAPE example
as motivation (Figure 4).
4.1

Call Stack

Consider Example 1 in Figure 4. Variables x and y point to
distinct objects, but because they are allocated at the same
allocation site (h1), the allocation site abstraction cannot
distinguish between the two objects, and thus x cannot be
proven thread-local at p1.
The most common way to reﬁne this abstraction is to use
k-CFA with heap cloning; let {A LLOCk : k = 0, 1, 2, . . . }
denote these abstractions. Speciﬁcally, A LLOCk maps an
object o to the allocation site of o (ω.as(o)) and the k most
recent call sites on the stack of the thread at the point at
which o was allocated (ω.cs(o)[1..k]):
A LLOCk (ω, o) = ω.as(o), ω.cs(o)[1..k] .

(19)

When k = 0, we recover the original allocation site abstraction. With call stack information, we can see that A LLOCk=1
can make the relevant distinctions in Example 1 to prove x
thread-local at p1.
The calling context is especially important in code where
factory methods are frequently used, since in this case, many
different objects are allocated at only one site and cannot be
distinguished by A LLOC. Large k values might be especially
important when such methods exist deep in heavily-reused
code such as the JDK standard library. One of the goals of
this paper is to study how large k must be in order to prove
various queries.
We can also implement k-object sensitivity [20] in our
framework by simply replacing the call sites in (19) with
the appropriate allocation sites, but we did not pursue this
empirically.
4.2

Object Recency

In some cases, no amount of call stack information (even
k = ∞) can help distinguish enough objects to prove a
query. Consider Example 2 in Figure 4. The program repeatedly creates an object and renders it thread escaping. Therefore, at p1, all objects except for the most recent one are
escaping. But since all objects have the same allocation site
and call stack, even A LLOCk=∞ cannot prove x thread-local
at p1.
This example therefore motivates reﬁning allocation site
abstractions to distinguish objects by their creation time.
This is object recency idea, proposed by [4], which allows
ﬁne-grained reasoning about loops.
Recall that ω.os is the sequence of objects which have
been allocated so far (in that order). For an object o (whose
abstraction we’re trying to compute), deﬁne the subsequence
of ω.os which contains only objects with the same A LLOCk

abstraction as o:
relosk (ω, o) =

(20)

[o : o ∈ ω.os, A LLOCk (ω, o) = A LLOCk (ω, o )].
Now deﬁne the recency index of object o to be the position
of o relative to the end of list relosk (ω, o), truncated at r:
recidxk (ω, o) =

(21)

min{indexof (reverse(relosk (ω, o)), o), r}.
We have recidxk (ω, o) = 0 if o is the last element of
relosk (ω, o), 1 if it is next to last, etc.
Finally, deﬁne abstraction R ECENCYr to map an object o
k
to its A LLOCk abstraction along with its recency index:
R ECENCYr (ω, o) = A LLOCk (ω, o), recidxk (ω, o) . (22)
k
Note that when r = 0, we recover A LLOCk . For r >
0, we can distinguish between r + 1 objects with the
same allocation site abstraction. The only setting considered in past work is r = 1, so for convenience, we simply write R ECENCYk for R ECENCYr=1 , R ECENCYr for
k
R ECENCYr , and R ECENCY for R ECENCYr=1 .
k=0
k=0
Returning to Example 2, we see that R ECENCY distinguishes between the last allocated object (which x points to)
and the others, allowing us to prove the query thread-local.
The form of Example 2 is a common paradigm in serverlike programs, where new objects are repeatedly constructed
and subsequently released to other threads. The point is that
during the construction phase, the objects are thread-local,
but in order to prove this, one needs to distinguish the objects
in the current loop iteration from the ones in previous loop
iterations.
4.3

Heap Connectivity

Note that the R ECENCYr abstraction is heavily tied to single
allocation sites; objects allocated at a site eventually collapse
to the same abstraction after r objects are created. For programs that maintain complex data structures, objects allocated at one site might enter into a diverse set of relationships
and have different properties over time. For these programs,
more sophisticated shape analysis might be important.
We consider two kinds of abstractions, P OINTED T O B Yk
[33] and R EACH F ROMk [27], which combine shape predicates with k-CFA. Standard shape analysis predicates are
based on local variable names [16, 27], which offer more
distinctions than allocation sites. However, we use allocation
sites instead of variable names in order to focus on the effect
of adding shape information without conﬂating the contribution of variable names (which are another orthogonal dimension of reﬁnement which warrants further investigation).
Speciﬁcally, P OINTED T O B Yk maps an object o to the set
of allocation sites of objects which can reach o in at most
one step:
P OINTED T O B Yk (ω, o) =

(23)

{A LLOCk (ω, o ) : o = o ∨ o .f = o}.

getnew() {
return new
}
p2: x = getnew()
p3: y = getnew()
spawn y
p1: ... x.f ...
h1:

h1: s = new
spawn s
h2: x = new
y = x
while (*) {
h3:
z = new
y.f = z
if (x.f == y)
s.f = z
y = z
}
x = x.f
p1: ... x.f ...

while (*) {
x = new
p1:
... x.f ...
spawn x
}

Example 1

Example 2

Example 3
h1,0

h1

x

x
h1

x
h2,0

s
h3,1

h3,0

y

Alloc

Allock=∞

Recency
{h1}

h1,p2

x

x
h1,1

h1,p3

h1,0

x
{h2}

s

{h2,h3}

{h1,h2,h3}

y

Allock=1

Recency

ReachFrom

Figure 4. Three examples that show the strengths and weaknesses of various abstractions. In each example, the goal is to
prove that x is thread-local at p1, corresponding to the query at the ﬁeld-accessing statement ... x.f .... The heap graphs
at query time for two abstractions are shown below each code snippet. In Example 1, x is local but y escapes. Since both are
allocated at h1, the allocation site abstraction (A LLOC) cannot prove x local, but A LLOCk=1 , which augments h1 with the call
site (p2 and p3) can. In Example 2, no k value sufﬁces to distinguish x from the rest, but object recency does differentiate
the last object allocated from the rest. In Example 3, R ECENCY is insufﬁcient to distinguish x from the other elements of the
linked-list, but R EACH F ROM can because the other elements are reachable from an additional allocation site h1.
Note this is a reﬂexive version of the pointed-to-by relation
(the allocation site of o is always included in the set), which
is non-standard. Similarly, R EACH F ROMk maps an object o
to the set of allocation sites of objects which can reach o in
a ﬁnite number of steps:
R EACH F ROMk (ω, o) = {A LLOCk (ω, o ) : o

ω.σ

o}. (24)

Consider Example 3 in Figure 4. Here, a linked-list is created whose third node is rendered escaping. R ECENCY cannot distinguish between the second node and any following
node except the last. One could increase r to let R ECENCY
make more distinctions, but r would have to grow linearly
with the list’s length, rendering the approach impractical.

Turning to R EACH F ROM, note that the second node is
reachable from allocation sites h2 (the ﬁrst node) and h3
(the second node), while the third node onwards are in addition reachable from h1. Therefore, R EACH F ROM is able to
separate the second node and deem it thread-local.
R ECENCY and R EACH F ROM really capture different aspects of the heap—one does not strictly dominates the other.
Which one works better depends on the benchmark and
client involved, and thus for the remainder of the paper, we
turn to an empirical study to provide more insight.
An implementation note: computing the R EACH F ROM
abstraction is expensive since the abstraction of an object
o depends on other objects in the heap, and thus each lo-

cal heap update requires computing reachability information
and updating the abstraction for a potentially large set of
nodes. We use a dynamic data structure which maintains,
for each object o, the set of objects that can reach o. We efﬁciently handle cases where a node is not on a cycle with any
of its immediate predecessors; various other optimizations
are also employed.
A ﬁnal remark: Note that P OINTED T O B Y, R EACH F ROM,
and R ECENCY are state-dependent in that α(ω, o) depends
on ω. This dependence gives these abstractions more power,
but also at some computational expense. In contrast, A LLOCk
for any k value is state-independent.

5.

Benchmarks

We experimented with nine Java programs from the DaCapo
benchmark suite (version 9.12) [5]:

struments each class that was loaded (with the exception of
java.lang.J9VMInternals) to generate an event whenever one of the following types of actions is executed in a
method of that class:
• an object allocation (each new and newarray),
• a write to a static ﬁeld of reference type (each putstatic),
• a read or write to an instance ﬁeld or an array element of

primitive or reference type (each getfield, putfield,
aload, and astore),
• an explicit thread creation site (each call to the start()

method of class java.lang.Thread),
• a lock acquisition site (each monitorenter as well as

the entry point of each synchronized method), and
• the points immediately before and after method calls

(each invokevirtual, invokestatic, etc.).
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan

A parser generator and translator generator
A simulation and analysis framework for
AVR microcontrollers
A Scalable Vector Graphics (SVG) toolkit
An output-independent print formatter
An SQL relational-database engine
A text indexing tool
A text search tool
A source-code analyzer
An XSLT processor for transforming XML

The suite provides three progressively larger inputs for each
benchmark, via the “-s [small|default|large]” options, henceforth called S MALL, M EDIUM, and L ARGE inputs, respectively. Due to computational constraints, we used S MALL
inputs for our experiments. In Section 6, we show that the
effect of the larger inputs on our conclusions is likely to be
insigniﬁcant.
Table 1 provides various statistics of the benchmarks.
The numbers refer only to classes, methods, and bytecodes
that were visited during execution under S MALL inputs.
The “app.” columns provide numbers for application code
(i.e., excluding the JDK standard library) while the “total”
columns provide numbers for the entire code.

6.

Experimental Setup

Our experiments were performed using IBM J9VM 1.6.0
on 32-bit Linux machines. We implemented all our abstractions and clients using Chord [1], an extensible static and
dynamic program analysis framework for Java bytecode,
built on top of the Joeq compiler infrastructure [34] and the
Javassist bytecode instrumentation library [9]. Chord takes
as input the class ﬁles, main entry point, and input data for
each benchmark. Chord ﬁrst runs the uninstrumented benchmark on the provided input data, and uses a lightweight
JVM agent to observe all classes that are loaded, including both application and JDK library classes. It then in-

Each of these events is required by some abstraction (e.g.,
the pre- and post-method call events are required by k-CFA)
or by some client (e.g., the putstatic event is required by
the T HREAD E SCAPE client to detect when objects become
reachable from a static ﬁeld).
Chord then runs the instrumented benchmark on the input
data. Chord allows for the option of processing the generated
events on-the-ﬂy in a separate JVM with an uninstrumented
JDK that communicates with the event-generating JVM via
a POSIX pipe.4 We did not employ this on-the-ﬂy option as
it produced non-deterministic traces for highly concurrent
benchmarks. Instead, we ran the program once and wrote
the trace of generated events to a binary ﬁle on disk. This
allowed us to perform our analysis across different abstractions and clients on the same trace, yielding results which
are meaningful to compare. However, saving to disk forced
us to use the S MALL inputs for the DaCapo benchmarks because the M EDIUM and L ARGE inputs resulted in enormous
traces. The “# events generated” column in Table 2 shows
the number of events generated on various input sizes; entries marked “?” denote that the experiment either ran for
too long or ran out of memory.
While the number of reachable queries did generally increase for larger inputs as more application code became
reachable, there was not much variation in the answers for
the queries that were reachable under both S MALL and
L ARGE inputs. This observation is quantiﬁed in Table 2
for the T HREAD E SCAPE client. The column “% change in
reachable queries” has entries of the form (−n, +m) meaning that the number of queries reachable under the indicated
larger input but not under the S MALL input was m% of
the queries reachable under the S MALL input; likewise, the
number of queries reachable under the S MALL input but not
4 Using

separate JVMs circumvents performance and correctness issues
that would arise when event-processing code itself calls instrumented JDK
libraries if one JVM were used.

benchmark

version

antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan

2.7.2
cvs-20090612
1.7
0.95
1.8.0.4
2.4.1
2.4.1
4.2.5
2.7.1

# classes
app.
total
89
290
399
678
613 1,300
868 1,357
111
465
170
495
126
448
420
817
400
720

# methods
app.
total
845 1,663
1,726 2,882
2,308 5,676
4,467 6,764
1,013 2,597
1,019 2,453
734 2,142
2,394 4,086
2,529 3,879

# bytecodes
app.
total
102,426 147,774
89,397 161,925
157,575 388,601
373,657 511,713
103,879 212,472
73,527 161,152
55,053 132,677
173,045 268,497
184,390 261,396

# threads
app. total
1
5
4
8
2
8
1
5
42
46
1
5
9
13
2
7
9
12

Table 1. Statistics of the DaCapo benchmarks used in this study.
benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan

# events generated (in millions)
S MALL M EDIUM L ARGE
45.7
772
1,926
18.3
3,193
18,468
59.4
572
731
44.1
235
50.1
849
2,035
6.0
?
?
16.6
2,184
4,662
13.2
940
?
29.6
2,219
?

% change in reachable queries
M EDIUM
L ARGE
−0.4, +90.1 −0.4, +90.1
−0.0,
+0.2 −0.3,
+5.8
−0.0, +21.5 −0.0, +38.2
−5.9,
+5.2
−0.0,
+0.3 −0.0,
+0.3
?
?
−0.0,
+1.8 −0.0,
+1.8
−0.4, +11.1
?
−0.0,
+0.0
?

% change in true queries
M EDIUM
L ARGE
−0.0, +0.0 −0.0, +0.0
−0.0, +0.0 −0.0, +0.5
−0.0, +6.0 −0.0, +6.0
−0.3, +0.2
−0.0, +0.0 −0.0, +0.0
?
?
−0.0, +0.0 −0.0, +0.0
−0.0, +4.2
?
−0.0, +0.0
?

Table 2. Trace lengths and variation in results for T HREAD E SCAPE on different input data sets. A “-” means that the input
size does not exist, and “?” means the experiment ran out of resources.
abstraction sub-family
{A LLOCk }k∈N
{R ECENCYr }k∈N,r∈N
k
{P OINTED T O B Yk }k∈N
{R EACH F ROMk }k∈N

reﬁnements
k-CFA
k-CFA, object recency to depth r
k-CFA, heap connectivity
k-CFA, heap connectivity

Table 3. Abstractions we consider in this study.

result space, we structure this section around the following
questions:
• Independent of abstraction, what is the fraction of true

queries (queries for which the answer is true) for a given
client? (Section 7.1)
• Which abstraction works best for a given client? (Sec-

tion 7.2)
under the indicated larger input was n%. The most signiﬁcant increases are for antlr (90%) and batik (38%).
The column “% change in true queries” is deﬁned analogously with true queries instead of reachable queries. By this
metric, even the most signiﬁcant changes are quite small: 6%
for batik and 4% for pmd.

7.

Results

This section presents our empirical results on the family of
abstractions considered in Section 4. Recall that we consider
reﬁnements of the basic allocation site abstraction (A LLOC)
along three dimensions: k-CFA, object recency, and heap
connectivity. Table 3 describes the abstractions we studied
empirically.
For each abstraction, we obtain precision numbers for
four clients and nine benchmarks. To navigate this large

• What is the effect of the k in k-CFA? (Section 7.3)
• What is the effect of the recency depth r? (Section 7.4)
• How scalable are the high-precision abstractions? (Sec-

tion 7.5)
7.1

Client Statistics

Table 4 shows the queries which were true in the concrete
execution for each benchmark and client (without abstraction). For the N ON S TATIONARY F IELD client, the fraction
of true queries is stable across benchmarks, but for the other
three clients, this fraction varies considerably. In particular,
variation in T HREAD E SCAPE and S HAREDACCESS correlate with the amount and nature of concurrency in the benchmark program (Table 1).
Recall that T HREAD E SCAPE measures reachability while
S HAREDACCESS measures actual accesses. Indeed, we see
the latter client has strictly fewer true queries, and moreover,

benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan

T HREAD E SCAPE
# true # total percent
17
3490
0.5
1983
5169
38.4
312
5028
6.2
3791 13734
27.6
1674
3817
43.9
139
3616
3.8
144
2490
5.8
513
6345
8.1
3702
7717
48.0

S HAREDACCESS
# true # total percent
0
3490
0.0
1755
5169
34.0
0
5028
0.0
0 13734
0.0
1095
3817
28.7
0
3616
0.0
51
2490
2.0
45
6345
0.7
496
7717
6.4

S HARED L OCK
# true # total percent
0
78
0.0
17
76
22.4
13
165
7.9
5
123
4.1
41
135
30.4
5
160
3.1
20
105
19.0
16
94
17.0
43
116
37.1

N ON S TATIONARY F IELD
# true # total percent
101
377
26.8
132
1037
12.7
215
988
21.8
391
2114
18.5
157
576
27.3
202
637
31.7
109
459
23.7
161
928
17.3
291
1306
22.3

Table 4. For each benchmark (row) and client (column), we report the number of total queries issued (|Q|), the number of
queries for which the answer is true, and the corresponding percentage. For all clients except for S HARED L OCK, only queries
from application code are reported; for S HARED L OCK, queries from the JDK standard library are also included because there
are few locks in application code.
the gap between the two clients is quite substantial for some
benchmarks (notably fop and xalan), suggesting generally
a higher use of static ﬁelds.
7.2

Effect of Abstraction on Clients

In this section, we focus on four abstractions (A LLOC,
A LLOCk=5 , R ECENCY, and R EACH F ROM), which allows us
to explore the three dimensions of reﬁnement independently.
Tables 5–8 provide the precision results for the four clients
on all nine benchmarks. Benchmark-client pairs where all
queries are false are marked with “-” as a placeholder. A
bold number indicates that it is within 1% of the precision
of the best abstraction on that benchmark-client pair.
Let us start with the T HREAD E SCAPE client. From Table 5, we see that the plain allocation site abstraction is
quite imprecise (average precision of 34.8%). A LLOCk=5
improves the precision signiﬁcantly for the majority of
the benchmarks (e.g., fop), but has little impact on others (e.g., batik). R ECENCY is on average less effective
than A LLOCk=5 , though there are exceptions (e.g., hsqldb).
R EACH F ROM performs slightly better than R ECENCY.
The S HAREDACCESS and S HARED L OCK clients have
similar behavior, as seen in Tables 6 and 7. In contrast to
T HREAD E SCAPE, these two clients receive little improvement from A LLOCk=5 . On the other hand, R ECENCY is
quite effective, outperforming or tying the other three abstractions uniformly across all benchmarks. R EACH F ROM
seems to perform similarly to A LLOC and A LLOCk=5 , suggesting that these clients and benchmarks do not need sophisticated reasoning about the shape of the heap. Instead,
the simple temporal notion captured by R ECENCY seems to
sufﬁce.
For N ON S TATIONARY F IELD, the case for R ECENCY is
stronger. From Table 8, we see that there is a huge gap
between the precision of R ECENCY (90.7%) and the other
abstractions. Both A LLOC and A LLOCk=5 perform equally
poorly (40–50%). R EACH F ROM sits approximately half way

in between. It is intuitive that R ECENCY performs well on
N ON S TATIONARY F IELD, as this client is intrinsically built
around a temporal property (writes must precede reads), and
R ECENCY focuses on making temporal distinctions.
benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan
average

A LLOC

A LLOCk=5

R ECENCY

R EACH F ROM

48.6
54.7
13.5
36.3
62.6
6.3
14.3
12.4
64.0
34.8

85.0
62.3
15.1
99.3
69.0
97.2
90.0
87.1
78.9
76.0

81.0
69.2
20.9
42.8
94.3
6.8
19.0
14.9
78.7
47.5

100.0
77.8
20.6
41.3
?
6.8
19.6
14.6
76.6
?

Table 5. Precision results for the T HREAD E SCAPE client.
benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan
average

A LLOC

A LLOCk=5

R ECENCY

R EACH F ROM

96.2
51.3
3.5
1.9
11.2
32.8

96.2
56.8
3.5
2.0
11.2
34.0

98.6
87.0
3.6
18.4
15.0
44.5

?
?
3.5
3.1
13.3
?

Table 6. Precision results for the S HAREDACCESS client.
To conclude this section, there is a fair amount of variation in the precision of abstractions. However, two trends
stand out: (1) R ECENCY is a clear winner in three of the four
clients, and in the exceptional T HREAD E SCAPE, k-CFA provides the most utility. So far, we have not seen R EACH F ROM
to be very helpful, but we will see a case for R EACH F ROM

benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan
average

A LLOC

A LLOCk=5

R ECENCY

R EACH F ROM

70.8
100.0
50.0
77.4
50.0
29.9
40.0
55.1
59.1

70.8
100.0
100.0
78.8
100.0
32.8
43.2
55.1
72.6

85.0
100.0
100.0
91.1
100.0
33.9
72.7
59.7
80.3

?
81.2
?
?
100.0
32.3
40.0
58.1
?

Table 7. Precision results for the S HARED L OCK client.
benchmark
antlr
avrora
batik
fop
hsqldb
luindex
lusearch
pmd
xalan
average

A LLOC

A LLOCk=5

R ECENCY

R EACH F ROM

59.1
33.2
35.8
42.0
45.4
78.0
38.2
37.8
44.0
45.9

60.1
33.6
36.1
44.9
49.5
84.2
38.2
39.9
44.5
47.9

91.0
93.6
99.5
90.9
94.6
94.8
64.9
96.4
90.4
90.7

78.3
77.2
65.3
68.2
?
94.8
56.5
69.4
74.2
?

Table 8. Precision results for the N ON S TATIONARY F IELD
client.
in Section 7.3. As mentioned in Section 4, shape analysis
typically considers reachability from local variables rather
than from allocation sites [16]. Since local variables generally offer ﬁner distinctions than allocation sites, we expect
a variable-based variant of R EACH F ROM to perform better.
However, the use of variables is an orthogonal dimension
(we could imagine R ECENCY based on variables as well),
which is outside the scope of this study.
7.3

Effect of k-CFA

In the previous section, we saw that A LLOCk=5 was very
useful for T HREAD E SCAPE but not for the other clients. Is it
because k needed to be higher? Could we have done just as
well with k < 5 for T HREAD E SCAPE? This section answers
these questions.
Figure 5 plots the precision as a function of k for the
four sub-families of abstractions in Table 3 (taking r = 1).
First, consider the T HREAD E SCAPE client (ﬁrst row). We
see that all abstractions work extremely poorly (precision
around 20%) for small values of k, but there is a phase transition where the precision shoots up to nearly 100%. The
critical value varies across abstractions and benchmarks, but
is around k = 3 to k = 6. A partial explanation to the phase
transition is as follows: Recall that T HREAD E SCAPE is deﬁned in terms of reachability, which is a sensitive property:

a localized over-abstraction can render the entire subgraph
downstream to be escaping.
Note that on the batik benchmark, even for k = ∞, both
A LLOCk and R ECENCYk fail to undergo the positive transition, but the heap connectivity abstractions (P OINTED T O B Y
and R EACH F ROM) do. On the remaining benchmarks,
P OINTED T O B Y and R EACH F ROM compare favorably with
the other abstractions. After all, the T HREAD E SCAPE client
is deﬁned in terms of reachability. In fact, we can redeﬁne
R EACH F ROM (24) to include a special label for static ﬁelds.
This change actually has extremely positive consequences:
the modiﬁed R EACH F ROM abstraction would always have
100% precision as it will never conﬂate objects reachable
from static ﬁelds from those which are not.
On the other clients, we see that increasing k does not
help in general (even with k = ∞). A notable exception
is the pmd benchmark, where extremely large values of k
make a signiﬁcant difference. In a separate experiment on
S HAREDACCESS, we saw that the precision did not reach
its limit until k = 18. Further investigation is required to
understand what properties of pmd make it an outlier, and
in particular, which of its objects actually require a large k
value.
In summary, the utility of k depends heavily on the
client (T HREAD E SCAPE versus others), and to a lesser extent on the benchmark (with the exception of pmd). Furthermore, we ﬁnd that R EACH F ROM performs well on
T HREAD E SCAPE—it just takes larger k values to realize
its potential, an instance of the synergy between two dimensions of reﬁnement.
7.4

Effect of Recency Depth r

In Section 7.2, we saw that R ECENCYr=1 performed well. In
this section, we investigate whether increasing the recency
depth r adds any additional value.
We study two sub-families of abstractions, R ECENCYr
k=0
5
and R ECENCYr
k=∞ , for 0 ≤ r ≤ 6. The results are given
in Table 9. We see that for most benchmark-client pairs, the
precision increases by a fair amount as r increases until some
point, larger values of r cease to be useful. An exception is
lusearch, whose precision increases steadily up to r = 6
across all clients. In general, there seems to be a greater
consistency across clients than for benchmarks, whereas for
k-CFA, the effect was the opposite.
Finally, the gains from increasing k and increasing r are
in general subadditive. However, one notable exception is
T HREAD E SCAPE on batik, where going from r = 1 to
r = 2 when k = 0 increases precision by only 0.5%
whereas going from r = 1 to r = 2 when k = ∞ increases
precision by 75.6%. We saw a similar superadditive effect on
the same benchmark-client pair in Section 7.3, where going
5 Note

that unlike k = ∞, r = ∞ trivially allows us to distinguish all
objects and thus always achieve 100% precision.

80

60
40
20

60
40

60
40

20

0

1

2

3

4

5

6

7

20

8 ∞

0

k
(a) (ThreadEscape, batik)

Precision

100

80

Precision

100

80

Precision

100

80

Precision

100

1

2

3

4

5

6

7

8 ∞

40
20

0

k
(b) (ThreadEscape, luindex)

60

1

2

3

4

5

6

7

8 ∞

0

k
(c) (ThreadEscape, lusearch)

2

3

4

5

6

8 ∞

7

k
(d) (ThreadEscape, pmd)

80

60
40
20

60
Alloc
Recency
PointedToBy
ReachFrom

40
20

0

1

2

3

4

5

6

7

8 ∞

0

1

2

3

4

5

6

7

60
40
20

8 ∞

60
40
20

0

1

2

3

4

5

6

7

8 ∞

0

100

100

80

80

2

3

4

5

6

8 ∞

7

100

80

1

80

60
40
20

60
40

60
40

20

0

1

2

3

4

5

6

7

20

8 ∞

0

k
(i) (SharedLock, batik)

1

2

3

4

5

6

7

8 ∞

60
40
20

0

k
(j) (SharedLock, luindex)

k
(h) (SharedAccess, pmd)

Precision

100

Precision

k
(g) (SharedAccess, lusearch)

Precision

k
(f) (SharedAccess, luindex)

Precision

k
(e) (SharedAccess, batik)

Precision

100

80

Precision

100

80

Precision

100

80

Precision

100

1

2

3

4

5

6

7

8 ∞

0

k
(k) (SharedLock, lusearch)

1

2

3

4

5

6

8 ∞

7

k
(l) (SharedLock, pmd)
100

80

80

60
40
20

60
40
20

0

1

2

3

4

5

6

7

8 ∞

k
(m) (NonStationaryField, batik)

Precision

100

80

Precision

100

80

Precision

100

Precision

1

60
40
20

0

1

2

3

4

5

6

7

8 ∞

k
(n) (NonStationaryField, luindex)

60
40
20

0

1

2

3

4

5

6

7

8 ∞

k
(o) (NonStationaryField, lusearch)

0

1

2

3

4

5

6

7

8 ∞

k
(p) (NonStationaryField, pmd)

Figure 5. Effect of varying k for various abstractions. For T HREAD E SCAPE, there is a sharp increase in precision around a
critical value of k, but the precision does not depend much on k for the other clients (except on the pmd benchmark).
from A LLOC to R EACH F ROM is useless if k < 5 but very
useful if k ≥ 5.
7.5

Tradeoff between Abstraction Precision and Size

Thus far, we have focused on evaluating the precision of abstractions. However, another important property of abstractions is how well they can scale inside a static analysis.
To get at the notion of scalability in our dynamic analysis
framework, we introduce the size of an abstraction α, which
we deﬁne to be the number of abstract objects |A|.
Figure 6 plots the precision versus size of various abstractions. Good abstractions live in the lower right-hand
corner of the plot (exhibiting high precision with low complexity). As a baseline, we created a R ANDOM abstraction. To construct this abstraction, we ﬁx a ﬁnite set of
abstract values, A = {1, . . . , n}, and assign each ob-

ject o independently to a random element of A. We tried
n ∈ {1000, 10000, 100000, ∞}, where n = ∞ corresponds
exactly to the concrete result.
R ANDOM performs quite poorly on T HREAD E SCAPE.
As mentioned earlier, T HREAD E SCAPE requires global reasoning about the heap, which is sensitive to arbitrary collapsing of concrete objects. On the other hand, for the
N ON S TATIONARY F IELD client, R ANDOM actually performs much better than the A LLOC, P OINTED T O B Y and
R EACH F ROM abstractions. This is an artifact of the client:
when random objects of different types are collapsed, no information is actually lost with respect to stationarity because
the two objects do not even have any ﬁelds in common.
Note that as k increases, the size of the abstraction
increases substantially, while the precision does not increase appreciably apart from the phase transitions. (Note

N ON S T F LD S HRD L CK S HRDACC T HR E SC

batik
luindex
lusearch
pmd
batik
luindex
lusearch
pmd
batik
luindex
lusearch
pmd
batik
luindex
lusearch
pmd

r=0
13.5
6.3
14.3
12.4
3.5
1.9
100.0
50.0
29.9
40.0
35.8
78.0
38.2
37.8

r=1
20.9
6.8
19.0
14.9
3.6
18.4
100.0
100.0
33.9
72.7
99.5
94.8
64.9
96.4

R ECENCYr
k=0
r=2 r=3 r=4
21.4
22.1
22.5
7.1
7.1
7.1
22.4
22.7
23.0
14.9
14.9
15.0
3.9
5.3
5.6
20.5
22.1
25.0
100.0 100.0 100.0
100.0 100.0 100.0
35.7
40.0
40.8
80.0
80.0
80.0
99.5
99.5
99.5
99.0
99.0
99.0
73.6
87.9
88.6
97.0
97.6
97.6

r=5
22.6
7.2
23.2
15.0
6.7
29.6
100.0
100.0
46.5
80.0
99.5
99.0
90.1
98.2

r=6
22.7
7.2
23.5
15.0
10.6
29.6
100.0
100.0
74.1
80.0
99.5
99.0
90.8
98.2

r=0
15.1
97.2
90.0
87.4
3.5
100.0
100.0
100.0
32.8
100.0
36.1
84.2
38.2
65.2

r=1
23.4
100.0
100.0
93.6
3.6
100.0
100.0
100.0
33.9
100.0
99.5
98.1
65.3
98.2

R ECENCYr
k=∞
r=2 r=3 r=4
99.0
99.0
99.0
100.0 100.0 100.0
100.0 100.0 100.0
93.6
93.6
93.6
4.0
5.5
6.0
100.0 100.0 100.0
100.0 100.0 100.0
100.0 100.0 100.0
35.7
40.8
41.7
100.0 100.0 100.0
99.5
99.5
99.5
99.0
99.0
99.0
79.0
93.2
95.6
98.8
98.8
98.8

r=5
99.0
100.0
100.0
93.6
7.6
100.0
100.0
100.0
47.6
100.0
99.5
99.0
95.6
99.4

r=6
99.0
100.0
100.0
93.6
14.6
100.0
100.0
100.0
76.9
100.0
99.5
99.0
95.6
99.4

Table 9. Effect of increasing the recency depth r. Each cell shows the precision for the given R ECENCY abstraction with a
particular benchmark and client. Bold entries indicate precision within 1% of r = 6.
that the Y-axis is on a log scale.) Shape-based abstractions
(P OINTED T O B Y and R EACH F ROM), though sometimes effective for T HREAD E SCAPE, are quite costly because the
abstract values are sets of allocation sites, which suffer from
a combinatorial explosion. The number of abstract values
may even exceed the number of concrete objects, since a
single object may take on many abstractions during its lifetime as its connected heap changes.
Summary Although there is a fair amount of variation in
precision across benchmarks and clients, this variation can
be explained in terms of two main trends: First, the best
abstractions for a client tend to correlate with the properties of the client: N ON S TATIONARY F IELD involves temporal properties and thus beneﬁts from R ECENCY, which offers
temporal distinctions; T HREAD E SCAPE involves heap connectivity properties and thus beneﬁts from R EACH F ROM.
Second, there are non-trivial interactions between the various reﬁnement dimensions (in one example, the potential of
R EACH F ROM is only realized with k-CFA for large enough
k). Overall, we showed that A LLOC is clearly insufﬁcient,
and R ECENCY is a important dimension worthy of further
exploration.

8.

Related Work

A comprehensive presentation and evaluation of the k-CFA
heap abstraction, as well as other k-limited abstractions like
k-object-sensitivity, is presented in [17]. The recency abstraction was introduced in [4]. Shape analysis, which is
a static technique for verifying properties of dynamicallyallocated data structures, is presented in [27]. Here, we survey work on evaluating the impact of k-limited heap abstractions on points-to and call-graph algorithms (Section 8.1)
and work on using connectivity-based heap abstractions to

improve garbage collectors (Section 8.2) and detect memory
bloat (Section 8.3).

8.1

Points-to and Call Graph Algorithms

Liang et al. [19] present a set of empirical studies investigating the effect of calling contexts on the precision of
Andersen’s algorithm. In particular, the effect of contextsensitive naming schemes on precision is evaluated, and the
traditional calling context sensitivity is compared to object
context sensitivity. The precision of the points-to information computed by each of the algorithms is evaluated visa-vis dynamically-collected data. In an earlier and closely
related study [18], the authors perform a similar set of experiments (again, using reference information collected at runtime as an approximation of precise reference information),
concluding that hybrid approaches for identifying instances
and computing points-to information are needed.
Lhot´ k and Hendren [17] follow a similar approach. They
a
conduct an empirical study on a set of large Java benchmarks
to evaluate the precision of subset-based points-to analysis
under three variations of context sensitivity: call string, object sensitivity, and the BDD-based context-sensitive algorithm proposed by Zhu and Calman, and by Whaley and
Lam. They evaluate the effects of these variations on the
number of contexts generated, the number of distinct pointsto sets constructed, and the precision of call-graph construction, virtual-call resolution, and cast-safety analysis. Our
study is complementary to theirs: we measure the effect of
k-CFA on the precision of clients for much higher values
of k, but for a single execution, whereas they measure the
same for smaller values of k but over all executions. Some
abstractions we consider are different from theirs (e.g., they
do not evaluate heap connectivity and we do not evaluate k-

275.9

5.3
0.7

38.1
5.3
0.7

20

40

60

80

100

40

60

80

100

38.1
5.3
0.7

38.1
5.3

40

60

80

100

80

100

20

40

60

80

60

80

100

2000.0
275.9

38.1
5.3

100

38.1
5.3
0.7

20

precision
(f) (SharedAccess, luindex)

40

precision
(d) (ThreadEscape, pmd)

0.7
20

precision
(e) (SharedAccess, batik)

60

275.9

0.7
20

5.3

2000.0
Random
Alloc
Recency
PointedToBy
ReachFrom

size ratio

size ratio

size ratio

275.9

40

precision
(c) (ThreadEscape, lusearch)

2000.0

275.9

38.1

0.7
20

precision
(b) (ThreadEscape, luindex)

2000.0

5.3
0.7

20

precision
(a) (ThreadEscape, batik)

38.1

size ratio

38.1

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

40

60

80

100

20

precision
(g) (SharedAccess, lusearch)

40

60

80

100

precision
(h) (SharedAccess, pmd)

275.9

38.1
5.3
0.7

38.1
5.3
0.7

20

40

60

80

100

38.1
5.3
0.7

20

precision
(i) (SharedLock, batik)

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

40

60

80

100

5.3
0.7

20

precision
(j) (SharedLock, luindex)

38.1

40

60

80

100

20

precision
(k) (SharedLock, lusearch)

40

60

80

100

precision
(l) (SharedLock, pmd)

275.9

38.1
5.3
0.7

38.1
5.3
0.7

20

40

60

80

100

precision
(m) (NonStationaryField, batik)

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

275.9

size ratio

2000.0

38.1
5.3
0.7

20

40

60

80

100

precision
(n) (NonStationaryField, luindex)

38.1
5.3
0.7

20

40

60

80

100

precision
(o) (NonStationaryField, lusearch)

20

40

60

80

100

precision
(p) (NonStationaryField, pmd)

Figure 6. Tradeoff between abstraction precision and size ratio for two clients and four benchmarks. (Note the logarithmic
scale.) The size ratio is size of the abstraction |A| divided by the size of the A LLOC abstraction. Multiple points for a given
abstraction indicate increasing values of k which monotonically increases both precision and size. Note that the upper-rightmost
R ANDOM point corresponds to the concrete execution.
object sensitivity). Finally, all our clients are motivated by
concurrency and are different from theirs.
8.2

Garbage Collection

Hirzel and Hind [13] explore whether the connectivity of
objects can yield useful partitions or improve existing partitioning schemes. They consider direct points-to relations,
as well as transitive reachability relations, and conclude that
connectivity correlates strongly with object lifetimes, and is
therefore useful for partitioning objects.
Shaham et al. [30] study the potential impact of different
kinds of liveness information on the space consumption of
a program in a garbage-collected environment. They measure the time difference between the actual time an object is
reclaimed by the garbage collector and the earliest time in

which this could have been done assuming the availability
of liveness information. Four kinds of liveness information
are considered: stack reference, global reference, heap reference, and any combination of the above.
Inoue et al. [14] introduce a precise method for predicting
object lifetimes, where the granularity of predictions is equal
to the smallest unit of allocation. They construct predictors
based on execution traces including accurate records of each
object’s allocation and death, and rely on a (ﬁxed-length)
preﬁx of the stack at the time of allocation to disambiguate
allocation contexts and thus improve the precision of the predictor. Their empirical results suggest that for some applications, object lifetimes can be predicted to the byte using the
allocation-context heuristic. This ﬁnding resonates well with

our empirical results, which show that the T HREAD E SCAPE
client beneﬁts greatly from high k values.
The approach taken in [14] is inspired by the work of
Seidl and Zorn [28, 29], which attempts to predict the reference and lifetime behavior of heap objects according to four
categories: highly referenced, short lived, low referenced,
and other. Similar to [14], prediction relies on a training trace
containing extensive information, including the number of
loads and stores to each object, the call stack at the time of
each allocation, and the size of the allocated object. Seidl
and Zorn use a stack-based prediction scheme, and conclude
that it is important to choose the right depth for the stack
predictor. Their experiments suggest that a depth of 3 yields
an effective predictor.
While all four of these studies provide insightful observations that may be leveraged by a static analysis, their goal
differs from ours. Our goal is to evaluate static abstractions
explicitly, so as to provide insight to static-analysis developers, whereas these studies focus on (concrete) empirical
results, and establish heuristics that may beneﬁt a garbage
collector.
8.3

Memory Bloat

Mitchell [21] investigates ways to summarize the memory
footprint of object-oriented applications in order to discover
cases where high-overhead collections, bulky data models
and large caches are used. As part of the analysis, he develops a catalog of ownership structures, which are shown to be
prevalent in large-scale applications, and are therefore powerful units of aggregation and ﬁltering. In a related study,
Mitchell and Sevitsky [22] study applications posing large
runtime memory requirements. They introduce “health signatures” to distinguish cases where a large memory footprint
enables an important requirement (e.g., the use of a cache
to ameliorate a performance problem) from instances where
memory is used excessively.
Also closely related is Yeti [23], a tool for summarizing
memory usage to uncover the costs of design decisions. This
is accomplished through a series of progressive abstractions
and corresponding visualizations. The goal behind Yeti is to
assist developers in discovering instances where large-scale
Java applications suffer from memory problems due to an
inefﬁcient design, or lifetime bugs such as leaks.
Similar to our study, these works are concerned with abstracting the concrete heap. However, the abstractions advocated by these studies are not inspired by static analysis;
rather, they are more heuristic in nature, and are tuned toward an interactive process wherein “simpliﬁcation” of the
concrete heap is beneﬁcial (indeed mandated) as part of a
reasoning process leading to the identiﬁcation of evasive
bugs and design ﬂaws.
Dufour et al. [11] introduce blended analysis, an algorithm combining a dynamic representation of the program’s
calling structure with a static analysis applied to a region of
that calling structure with observed performance problems.

In a case study they perform, they show that blended escape
analysis is highly effective at localizing a performance problem due to overuse of temporary structures. In a subsequent
study [12], new metrics are added to quantify key properties
of temporary data structures and their uses, and an empirical evaluation is conducted to characterize temporaries in
framework-intensive applications.
Dufour’s studies are similar to our work in that a static
representation of the program is computed on top of a dynamic trace. However, whereas Dufour’s focus is on localizing a particular problem or behavior (which is present during
the concrete execution), our goal is to understand which heap
abstractions are likely to be good for static analysis.

9.

Conclusion

With the goal of ﬁnding good heap abstractions for static
analysis, we have investigated a family heap abstractions on
four clients and nine benchmarks. Our evaluation of these
abstractions revealed many interesting properties about the
role and utility of k-CFA, object recency and heap connectivity. We believe these results can serve as a useful guide
for developing static analyses.

References
[1] Chord: A static and dynamic program analysis framework for
Java. http://code.google.com/p/jchord/.
[2] J. Aldrich, C. Chambers, E. G. Sirer, and S. J. Eggers. Static
analyses for eliminating unnecessary synchronization from
Java programs. In Proceedings of the 6th Intl. Static Analysis
Symp. (SAS), pages 19–38, 1999.
[3] J. Aldrich, E. Sirer, C. Chambers, and S. J. Eggers. Comprehensive synchronization elimination for Java. Science of
Computer Programming, 47(2-3):91–120, 2003.
[4] G. Balakrishnan and T. W. Reps. Recency-abstraction for
heap-allocated storage. In Proceedings of the 13th Intl. Static
Analysis Symp. (SAS), pages 221–239, 2006.
[5] S. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S.
McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton,
S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B.
Moss, A. Phansalkar, D. Stefanovi´ , T. VanDrunen, D. von
c
Dincklage, and B. Wiedermann. The DaCapo benchmarks:
Java benchmarking development and analysis. In Proceedings
of the 21st ACM SIGPLAN Conf. on Object-Oriented Programing Systems, Languages and Applications (OOPSLA),
pages 169–190, 2006.
[6] B. Blanchet. Escape analysis for Java: Theory and practice.
ACM Transactions on Programming Languages and Systems,
25(6):713–775, 2003.
[7] B. Blanchet. Escape analysis for object-oriented languages:
Application to Java. In Proceedings of the 14th ACM SIGPLAN Conf. on Object-Oriented Programming Systems, Languages and Applications (OOPSLA), pages 20–34, 1999.
[8] J. Bogda and U. H¨ lzle. Removing unnecessary synchroo
nization in Java. In Proceedings of the 14th ACM SIGPLAN

Conf. on Object-Oriented Programming Systems, Languages
and Applications (OOPSLA), pages 35–46, 1999.

on Object-Oriented Programming Systems, Languages and
Applications (OOPSLA), pages 245–260, 2007.

[9] S. Chiba and M. Nishizawa. An easy-to-use toolkit for efﬁcient Java bytecode translators. In Proceedings of the 2nd Intl.
Conf. on Generative Programming and Component Engineering (GPCE), pages 364–376, 2003.

[23] N. Mitchell, E. Schonberg, and G. Sevitsky. Making sense
of large heaps. In Proceedings of the 23rd European Conf. on
Object-Oriented Programming (ECOOP), pages 77–97, 2009.

[10] J.-D. Choi, K. Lee, A. Loginov, R. O’Callahan, V. Sarkar, and
M. Sridharan. Efﬁcient and precise datarace detection for
multithreaded object-oriented programs. In Proceedings of
the ACM SIGPLAN Conf. on Programming Language Design
and Implementation (PLDI), pages 258–269, 2002.
[11] B. Dufour, B. G. Ryder, and G. Sevitsky. Blended analysis for
performance understanding of framework-based applications.
In Proceedings of the ACM SIGSOFT Intl. Symp. on Software
Testing and Analysis (ISSTA), pages 118–128, 2007.
[12] B. Dufour, B. G. Ryder, and G. Sevitsky. A scalable technique
for characterizing the usage of temporaries in frameworkintensive Java applications. In Proceedings of the 16th ACM
SIGSOFT Intl. Symp. on Foundations of Software Engineering
(FSE), pages 59–70, 2008.
[13] M. Hirzel, J. Henkel, A. Diwan, and M. Hind. Understanding the connectivity of heap objects. In Proceedings of the
Workshop on Memory Systems Performance (MSP) and the
Intl. Symp. on Memory Management (ISMM), pages 143–156,
2003.
[14] H. Inoue, D. Stefanovic, and S. Forrest. On the prediction of
java object lifetimes. IEEE Transactions on Computers, 55:
880–892, 2006.
[15] K. Lee and S. P. Midkiff. A two-phase escape analysis for parallel Java programs. In Proceedings of the 15th Intl. Conf. on
Parallel Architectures and Compilation Techniques (PACT),
pages 53–62, 2006.
[16] T. Lev-Ami, T. Reps, M. Sagiv, and R. Wilhelm. Putting static
analysis to work for veriﬁcation: A case study. In In Intl.
Symp. on Software Testing and Analysis, pages 26–38, 2000.
[17] O. Lhot´ k and L. Hendren. Context-sensitive points-to anala
ysis: is it worth it? In Proceedings of the 15th Intl. Conf. on
Compiler Construction, pages 47–64, 2006.
[18] D. Liang, M. Pennings, and M. J. Harrold. Evaluating the precision of static reference analysis using proﬁling. In Proceedings of the ACM SIGSOFT Intl. Symp. on Software Testing and
Analysis (ISSTA), pages 22–32, 2002.
[19] D. Liang, M. Pennings, and M. J. Harrold. Evaluating the
impact of context-sensitivity on andersen’s algorithm for java
programs. In Proceedings of the ACM SIGPLAN-SIGSOFT
Workshop on Program Analysis For Software Tools and Engineering (PASTE), pages 6–12, 2006.
[20] A. Milanova, A. Rountev, and B. Ryder. Parameterized object
sensitivity for points-to and side-effect analyses for Java. In
Proceedings of the ACM SIGSOFT Intl. Symp. on Software
Testing and Analysis (ISSTA), pages 1–11, 2002.
[21] N. Mitchell. The runtime structure of object ownership. In
Proceedings of the 20th European Conf. on Object-Oriented
Programming (ECOOP), pages 74–98, 2006.
[22] N. Mitchell and G. Sevitsky. The causes of bloat, the limits
of health. In Proceedings of the 22nd ACM SIGPLAN Conf.

[24] M. Naik and A. Aiken. Conditional must not aliasing for static
race detection. In Proceedings of the 34th ACM SIGPLANSIGACT Symp. on Principles of Programming Languages
(POPL), pages 327–338, 2007.
[25] M. Naik, A. Aiken, and J. Whaley. Effective static race
detection for Java. In Proceedings of the ACM SIGPLAN
Conf. on Programming Language Design and Implementation
(PLDI), pages 308–319, 2006.
[26] E. Ruf. Effective synchronization removal for Java. In Proceedings of the ACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI), pages 208–218,
2000.
[27] M. Sagiv, T. W. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic. ACM Transactions on Programming
Languages and Systems, 24(3):217–298, 2002.
[28] M. L. Seidl and B. G. Zorn. Segregating heap objects by
reference behavior and lifetime. SIGOPS Oper. Syst. Rev., 32
(5):12–23, 1998.
[29] M. L. Seidl, M. L. Seidl, M. L. Seidl, B. G. Zorn, B. G.
Zorn, and B. G. Zorn. Predicting references to dynamically
allocated objects. Technical report, 1997.
[30] R. Shaham, E. K. Kolodner, and M. Sagiv. Estimating the
impact of heap liveness information on space consumption in
Java. In Proceedings of the Workshop on Memory Systems
Performance (MSP) and the Intl. Symp. on Memory Management (ISMM), pages 171–182, 2002.
[31] O. Shivers. Control-ﬂow analysis in Scheme. In Proceedings of the ACM SIGPLAN Conf. on Programming Language
Design and Implementation (PLDI), pages 164–174, 1988.
[32] C. Unkel and M. S. Lam. Automatic inference of stationary
ﬁelds: a generalization of Java’s ﬁnal ﬁelds. In Proceedings
of the 35th ACM SIGPLAN-SIGACT Symp. on Principles of
Programming Languages (POPL), pages 183–195, 2008.
[33] E. Y.-B. Wang. Analysis of Recursive Types in an Imperative
Language. PhD thesis, Univ. of Calif., Berkeley, CA, 1994.
[34] J. Whaley. Joeq: A virtual machine and compiler infrastructure. Science of Computer Programming, 57(3):339–356,
2005.
[35] R. M. Yoo, Y. Ni, A. Welc, B. Saha, A.-R. Adl-Tabatabai,
and H.-H. S. Lee. Kicking the tires of software transactional
memory: why the going gets tough. In Proceedings of the 20th
ACM Symp. on Parallelism in Algorithms and Architectures
(SPAA), pages 265–274, 2008.

