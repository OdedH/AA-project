An Asymptotic Analysis of Estimators:
Generative, Discriminative, Pseudolikelihood
ICML 2008

Helsinki, Finland

July 6, 2008

Percy Liang

Michael I. Jordan

UC Berkeley

Goal: structured prediction
x ⇒ y = (y1, . . . , y )
We focus on probabilistic models of x and y

2

Goal: structured prediction
x ⇒ y = (y1, . . . , y )
We focus on probabilistic models of x and y
Many approaches
Discriminative (logistic regression, conditional random ﬁelds)
Generative (Naive Bayes, Bayesian networks, HMMs)

2

Goal: structured prediction
x ⇒ y = (y1, . . . , y )
We focus on probabilistic models of x and y
Many approaches
Discriminative (logistic regression, conditional random ﬁelds)
Generative (Naive Bayes, Bayesian networks, HMMs)
Pseudolikelihood [Besag, 1975]

2

Goal: structured prediction
x ⇒ y = (y1, . . . , y )
We focus on probabilistic models of x and y
Many approaches
Discriminative (logistic regression, conditional random ﬁelds)
Generative (Naive Bayes, Bayesian networks, HMMs)
Pseudolikelihood [Besag, 1975]
Composite likelihood [Lindsay, 1988]
Multi-conditional learning [McCallum, et al., 2006]
Piecewise training [Sutton & McCallum, 2005]
Variational relaxations [Wainwright, 2006]
Agreement-based learning [Liang, et al., 2008]
...how to choose among these approaches?

2

Goal: structured prediction
x ⇒ y = (y1, . . . , y )
We focus on probabilistic models of x and y
Many approaches
Discriminative (logistic regression, conditional random ﬁelds)
Generative (Naive Bayes, Bayesian networks, HMMs)
Pseudolikelihood [Besag, 1975]
Composite likelihood [Lindsay, 1988]
Multi-conditional learning [McCallum, et al., 2006]
Piecewise training [Sutton & McCallum, 2005]
Variational relaxations [Wainwright, 2006]
Agreement-based learning [Liang, et al., 2008]
...how to choose among these approaches?

Our work:
• Put ﬁrst three in a uniﬁed composite likelihood framework
• Compare their statistical properties theoretically
2

Existing intuitions:
• Discriminative: lower bias
Generative: lower variance
[Ng & Jordan, 2002; Bouchard & Triggs, 2004]

3

Existing intuitions:
• Discriminative: lower bias
Generative: lower variance
[Ng & Jordan, 2002; Bouchard & Triggs, 2004]

• Pseudolikelihood: slower statistical convergence
[Besag, 1975]

3

Existing intuitions:
• Discriminative: lower bias
Generative: lower variance
[Ng & Jordan, 2002; Bouchard & Triggs, 2004]

• Pseudolikelihood: slower statistical convergence
[Besag, 1975]

Our general result:
Derive the (excess) risk of composite likelihood estimators

3

Existing intuitions:
• Discriminative: lower bias
Generative: lower variance
[Ng & Jordan, 2002; Bouchard & Triggs, 2004]

• Pseudolikelihood: slower statistical convergence
[Besag, 1975]

Our general result:
Derive the (excess) risk of composite likelihood estimators
Speciﬁc conclusions:
If the model is well-speciﬁed:
Risk(generative) < Risk(discriminative) < Risk(pseudolikelihood)

3

Existing intuitions:
• Discriminative: lower bias
Generative: lower variance
[Ng & Jordan, 2002; Bouchard & Triggs, 2004]

• Pseudolikelihood: slower statistical convergence
[Besag, 1975]

Our general result:
Derive the (excess) risk of composite likelihood estimators
Speciﬁc conclusions:
If the model is well-speciﬁed:
Risk(generative) < Risk(discriminative) < Risk(pseudolikelihood)

If the model is misspeciﬁed:
Risk(discriminative) < Risk(pseudolikelihood), Risk(generative)
3

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

ˆ
ˆ
Discriminative: θd = argmax E log pθ (y | x)
θ

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

ˆ
ˆ
Discriminative: θd = argmax E[log pθ (x, y) − log pθ (x)]
θ

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

ˆ
ˆ
Discriminative: θd = argmax E[log pθ (x, y) − log pθ (x)]
θ

(x, y)

= {(x, ∗)}

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

ˆ
ˆ
Discriminative: θd = argmax E[log pθ (x, y) − log pθ (x)]
θ

(x, y)

= {(x, ∗)}

ˆ
ˆ
More generally: θ = argmax E[log pθ (x, y) − log pθ (r(x, y))]
θ

(x, y)

= r(x, y)

4

Model-based estimators and neighborhoods
ˆ
ˆ
Generative: θg = argmax E log pθ (x, y)
θ

(x, y)

= {(∗, ∗)}

ˆ
ˆ
Discriminative: θd = argmax E[log pθ (x, y) − log pθ (x)]
θ

(x, y)

= {(x, ∗)}

ˆ
ˆ
More generally: θ = argmax E[log pθ (x, y) − log pθ (r(x, y))]
θ

(x, y)

= r(x, y)

r(x, y) is subset of input-output space we want to contrast

4

Composite likelihood estimators
Discriminative pseudolikelihood:
y1

yj

y

x

ˆ
ˆ
θp = argmax E
θ

log p(yj | x, y\{yj })
j=1

5

Composite likelihood estimators
Discriminative pseudolikelihood:
y1

yj

y

x

ˆ
θp = argmax
θ

ˆ
E[log p(yj | x, y\{yj })]
j=1

5

Composite likelihood estimators
Discriminative pseudolikelihood:
y1

yj

y

x

ˆ
θp = argmax
θ

ˆ
E[log p(x, y) − log p(x, y\{yj })]
j=1

5

Composite likelihood estimators
Discriminative pseudolikelihood:
y1

yj

y

x

ˆ
θp = argmax
θ

ˆ
E[log p(x, y) − log p(x, y\{yj })]
j=1

rj (x,y)

5

Composite likelihood estimators
Discriminative pseudolikelihood:
y1

yj

y

x

ˆ
θp = argmax
θ

ˆ
E[log p(x, y) − log p(x, y\{yj })]
j=1

rj (x,y)

General composite likelihood:
ˆ
ˆ
wj E[log pθ (x, y) − log pθ (rj (x, y))]
θ = argmax
θ

j

(x, y)

= r1(x, y)
= r2(x, y)
5

Review of exponential families
log pθ (x, y | r(x, y)) =
φ(x, y) ·
features

θ
parameters

− log

(x ,y )∈r(x,y) exp{φ(x
log-partition function

, y ) θ}

6

Review of exponential families
log pθ (x, y | r(x, y)) =
φ(x, y) ·
features

θ
parameters

− log

(x ,y )∈r(x,y) exp{φ(x
log-partition function

, y ) θ}

Moment-generating properties:
Mean:
log pθ (x, y | r(x, y)) = φ − Eθ [φ | r]
Variance:
2

log pθ (x, y | r(x, y)) = −varθ [φ | r]

Derivatives are useful for asymptotic Taylor expansions

6

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ

Parameters θ

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise
Parameters θ

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise
Parameters θ

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

Sensitivity ↑ ⇒ Risk ↓

7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

Sensitivity ↑ ⇒ Risk ↓
Generative
Discriminative
var(φ)
?
E var(φ | X)
7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

Sensitivity ↑ ⇒ Risk ↓
Generative
Discriminative
var(φ)
= E var(φ | X) + var E(φ | X)
7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

Sensitivity ↑ ⇒ Risk ↓
Generative
Discriminative
var(φ)
E var(φ | X)
7

Sketch of arguments for comparing estimators
(x, y)

= r(x, y)

Intuition:
Grow r ⇒ model more about data
⇒ data tells us more about parameters
For exponential families:
θ → mean φ

Features φ
noise

slope = variance of φ over

def

= sensitivity

Parameters θ

Sensitivity ↑ ⇒ Risk ↓
Generative
Discriminative
var(φ)
E var(φ | X)
Risk(generative) < Risk(discriminative)

7

Overview of asymptotic analysis
How accurately can we estimate the parameters?
ParameterError = O

Σ
√
n

Σ: asymptotic variance of parameters
n: number of training examples

8

Overview of asymptotic analysis
How accurately can we estimate the parameters?
ParameterError = O

Σ
√
n

Σ: asymptotic variance of parameters
n: number of training examples

How fast can we drive the excess risk (expected log-loss) to 0?
In general, get normal rate:
Risk = O

Σ
√
n

8

Overview of asymptotic analysis
How accurately can we estimate the parameters?
ParameterError = O

Σ
√
n

Σ: asymptotic variance of parameters
n: number of training examples

How fast can we drive the excess risk (expected log-loss) to 0?
In general, get normal rate:
Risk = O

Σ
√
n

But if some condition is satisﬁed, get fast rate:
Risk = O Σ
n

8

Overview of asymptotic analysis
How accurately can we estimate the parameters?
ParameterError = O

Σ
√
n

Σ: asymptotic variance of parameters
n: number of training examples

How fast can we drive the excess risk (expected log-loss) to 0?
In general, get normal rate:
Risk = O

Σ
√
n

But if some condition is satisﬁed, get fast rate:
Risk = O Σ
n
Issues:
• O(n− 1 ) or O(n−1)?
2
• Compare Σ
8

Overview of asymptotic analysis
How accurately can we estimate the parameters?
ParameterError = O

Σ
√
n

Σ: asymptotic variance of parameters
n: number of training examples

How fast can we drive the excess risk (expected log-loss) to 0?
In general, get normal rate:
Risk = O

Σ
√
n

But if some condition is satisﬁed, get fast rate:
Risk = O Σ
n
Issues:
Agenda:
• O(n− 1 ) or O(n−1)? 1. Well-speciﬁed, one component
2
2. Well-speciﬁed, multiple components
• Compare Σ
3. Misspeciﬁed
8

Well-speciﬁed case
Risk = O Σ for all consistent estimators
n
Thus, suﬃcient to just compare Σs of diﬀerent estimators...

9

Well-speciﬁed case
Risk = O Σ for all consistent estimators
n
Thus, suﬃcient to just compare Σs of diﬀerent estimators...
Estimator:
ˆ
ˆ
θ = argmaxθ E[log pθ (x, y) − log pθ (r(x, y))]
(x, y)

= r(x, y)

9

Well-speciﬁed case
Risk = O Σ for all consistent estimators
n
Thus, suﬃcient to just compare Σs of diﬀerent estimators...
Estimator:
ˆ
ˆ
θ = argmaxθ E[log pθ (x, y) − log pθ (r(x, y))]
(x, y)

= r(x, y)

Asymptotic variance:
Σ = Γ−1, where Γ = E var(φ | r) is the sensitivity

9

Well-speciﬁed case
Risk = O Σ for all consistent estimators
n
Thus, suﬃcient to just compare Σs of diﬀerent estimators...
Estimator:
ˆ
ˆ
θ = argmaxθ E[log pθ (x, y) − log pθ (r(x, y))]
(x, y)

= r(x, y)

Asymptotic variance:
Σ = Γ−1, where Γ = E var(φ | r) is the sensitivity
Proof:
By Taylor expansion and moment-generating properties.
9

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

10

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

Comparison theorem:
If model is well-speciﬁed and
r1(x, y) ⊃ r2(x, y)
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)

10

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

Comparison theorem:
If model is well-speciﬁed and
r1(x, y) ⊃ r2(x, y)
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)
Proof:
Σj = E var(φ | rj )−1

10

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

Comparison theorem:
If model is well-speciﬁed and
r1(x, y) ⊃ r2(x, y)
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)
Proof:
Σj = E var(φ | rj )−1

Σ1

Σ2

10

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

Comparison theorem:
If model is well-speciﬁed and
r1(x, y) ⊃ r2(x, y)
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)
Proof:
−1

Σj = E var(φ | rj )

Σ1

Σ2

Risk = O

Σj
n

10

Well-speciﬁed case: comparing two estimators
Two estimators:
ˆ
ˆ
θj = argmaxθ E[log pθ (x, y) − log pθ (rj (x, y))] for j = 1, 2
(x, y)

= r1(x, y)
= r2(x, y)

Comparison theorem:
If model is well-speciﬁed and
r1(x, y) ⊃ r2(x, y)
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)
Proof:
−1

Σj = E var(φ | rj )

Σ1

Σ2

Risk = O

Σj
n

Modeling more reduces error (when model is well-speciﬁed)
10

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity
Cc 0 : correction due to multiple components

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity
Cc 0 : correction due to multiple components
Comparison theorem:
If the model is well-speciﬁed and
ˆ
ˆ
θ1: one component r1 θ2: multiple components {r2,j }

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity
Cc 0 : correction due to multiple components
Comparison theorem:
If the model is well-speciﬁed and
ˆ
ˆ
θ1: one component r1 θ2: multiple components {r2,j }
r1(x, y) ⊃ r2,j (x, y) for all components j

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity
Cc 0 : correction due to multiple components
Comparison theorem:
If the model is well-speciﬁed and
ˆ
ˆ
θ1: one component r1 θ2: multiple components {r2,j }
r1(x, y) ⊃ r2,j (x, y) for all components j
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)

11

Multiple components
Asymptotic variance:
Σ = Γ−1 + Γ−1CcΓ−1
Γ = j wj E var(φ | rj ) is the sensitivity
Cc 0 : correction due to multiple components
Comparison theorem:
If the model is well-speciﬁed and
ˆ
ˆ
θ1: one component r1 θ2: multiple components {r2,j }
r1(x, y) ⊃ r2,j (x, y) for all components j
Then
ˆ
ˆ
Risk(θ1) ≤ Risk(θ2)
ˆ
Note: does not apply if θ1 has more than one component
11

Misspeciﬁed case
Result:
For any estimator in general, get normal rate:
Risk = O

Σ
√
n

12

Misspeciﬁed case
Result:
For any estimator in general, get normal rate:
Risk = O

Σ
√
n

But for the discriminative estimator, get fast rate:
Risk = O

Σ
n

12

Misspeciﬁed case
Result:
For any estimator in general, get normal rate:
Risk = O

Σ
√
n

But for the discriminative estimator, get fast rate:
Risk = O

Σ
n

Corollary:
Risk(discriminative) < Risk(pseudolikelihood), Risk(generative)

12

Misspeciﬁed case
Result:
For any estimator in general, get normal rate:
Risk = O

Σ
√
n

But for the discriminative estimator, get fast rate:
Risk = O

Σ
n

Corollary:
Risk(discriminative) < Risk(pseudolikelihood), Risk(generative)

Key desirable property: training criterion = test criterion

12

Verifying the error rates empirically
Setup:
Learn

y1 y2
x

from n training examples

Estimate (excess) risk from 10,000 trials

13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

var(Risk)

generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

√

n · var(Risk)

generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

n · var(Risk)

generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

n · var(Risk)

generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

All: O(n−1)
13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

Misspeciﬁed
generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

var(Risk)

n · var(Risk)

generate from

20K 40K 60K 80K 100K

n

All: O(n−1)
13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

Misspeciﬁed

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

n · var(Risk)

generate from

√

n · var(Risk)

generate from

20K 40K 60K 80K 100K

n

All: O(n−1)
13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

Misspeciﬁed
generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n

n · var(Risk)

n · var(Risk)

generate from

20K 40K 60K 80K 100K

n

All: O(n−1)
13

Verifying the error rates empirically
Setup:
Learn

y1 y2

from n training examples

x

Estimate (excess) risk from 10,000 trials
Well-speciﬁed

Misspeciﬁed
generate from

Generative
Discriminative
Pseudolikelihood
20K 40K 60K 80K 100K

n · var(Risk)

n · var(Risk)

generate from

20K 40K 60K 80K 100K

n

n

All: O(n−1)

Fully dis.: O(n−1)
−1
others: O(n 2 )
13

Application: part-of-speech tagging
Task:
y: Det Noun Verb Det Noun
x: The

cat

ate

a

ﬁsh

14

Application: part-of-speech tagging
Task:
y: Det Noun Verb Det Noun
x: The

cat

ate

a

ﬁsh

Data: Wall Street Journal news articles (40K sentences)

14

Application: part-of-speech tagging
Task:
y: Det Noun Verb Det Noun
x: The

cat

ate

a

ﬁsh

Data: Wall Street Journal news articles (40K sentences)
Synthetic data (well-speciﬁed)
Test error

12.0
8.0
4.0

Gen.

Dis. Pseudo.

14

Application: part-of-speech tagging
Task:
y: Det Noun Verb Det Noun
x: The

cat

ate

a

ﬁsh

Data: Wall Street Journal news articles (40K sentences)
Synthetic data (well-speciﬁed)

Real data (misspeciﬁed)
6.0

Test error

Test error

12.0
8.0
4.0

Gen.

Dis. Pseudo.

4.0
2.0

Gen.

Dis. Pseudo.

14

Summary
Unifying composite likelihood framework for
generative, discriminative, pseudolikelihood estimators

15

Summary
Unifying composite likelihood framework for
generative, discriminative, pseudolikelihood estimators
Asymptotic statistics:
a powerful tool for comparing estimators

15

Summary
Unifying composite likelihood framework for
generative, discriminative, pseudolikelihood estimators
Asymptotic statistics:
a powerful tool for comparing estimators
General conclusions:
• Well-speciﬁed case: modeling more of data reduces error
• Desirable: training criterion = test criterion

15

