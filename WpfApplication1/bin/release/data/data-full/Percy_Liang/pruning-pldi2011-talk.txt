Scaling Abstraction Reﬁnement via Pruning
PLDI - San Jose, CA

June 8, 2011

Percy Liang

Mayur Naik

UC Berkeley

Intel Labs Berkeley

The Big Picture
Program

2

The Big Picture
Program

Static
Analysis

2

The Big Picture
Program

A
Static
Analysis

2

The Big Picture
ﬁne/expensive

Program

A
Static
Analysis
precise

2

The Big Picture
ﬁne/expensive

Program

A
Static
Analysis
coarse/cheap

imprecise

2

The Big Picture
ﬁne/expensive

Program

A
Static
Analysis
coarse/cheap

precise

selected reﬁnement
[Heintze & Tardieu 2001]
[Guyer & Lin 2003]
[Sridharan et al. 2005]
[Zheng & Rugina 2008]
[Liang et al. 2011]
2

The Big Picture
ﬁne/expensive

Program

A
Static
Analysis
coarse/cheap

precise

selected reﬁnement
[Heintze & Tardieu 2001]
[Guyer & Lin 2003]
[Sridharan et al. 2005]
[Zheng & Rugina 2008]
[Liang et al. 2011]

pruning
NEW!
2

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C

v = new C
x = getnew()

y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C
u → h1

v = new C
x = getnew()

y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C
u → h1

v = new C
x = getnew()

v → h2

y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C
u → h1

v = new C
x = getnew()

v → h2

y = getnew()

x → h2

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C
u → h1

v = new C
x = getnew()
x → h2

v → h2

y = getnew()
y → h2

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
u = new C
u → h1

v = new C
x = getnew()

v → h2

y = getnew()
y → h2

x → h2
ALIAS(x,y)

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

0-CFA:
v = new C

el

ev

an
t

u = new C
irr

u → h1

x = getnew()

v → h2

y = getnew()
y → h2

x → h2
ALIAS(x,y)

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

1-CFA on pruned:
v:i1 = new C v:i2 = new C

el

ev

an
t

u = new C
irr

u → h1

x = getnew()

y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

1-CFA on pruned:
v:i1 = new C v:i2 = new C

el

ev

an
t

u = new C
irr

u → h1

x = getnew() v:i1 → h2:i1 v:i2 → h2:i2 y = getnew()

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

1-CFA on pruned:
v:i1 = new C v:i2 = new C

el

ev

an
t

u = new C
irr

u → h1

x = getnew() v:i1 → h2:i1 v:i2 → h2:i2 y = getnew()
x → h2:i1

y → h2:i2

3

An Example of Pruning

h1:
h2:

i1:
i2:

getnew() {
u = new C
v = new C
return v
}
x = getnew()
y = getnew()

Query: do x and y alias? (no)

1-CFA on pruned:
v:i1 = new C v:i2 = new C

el

ev

an
t

u = new C
irr

u → h1

x = getnew() v:i1 → h2:i1 v:i2 → h2:i2 y = getnew()
y → h2:i2

x → h2:i1
(not aliasing - query proven)

3

General Pruning Framework
Input tuples A0

v = new C · · ·

4

General Pruning Framework
Input tuples A0

v = new C · · ·

Query tuple xq

ALIAS(x,y)

4

General Pruning Framework
Input tuples A0

v = new C · · ·

Query tuple xq

ALIAS(x,y)

Datalog rules

v2 → h ⇐ v2 = v1 , v1 → h
···

4

General Pruning Framework
Input tuples A0

v = new C · · ·

Query tuple xq

ALIAS(x,y)

Datalog rules

v2 → h ⇐ v2 = v1 , v1 → h
···
P
subset of A0 used to derive xq
A0

Prune/prove operator P
A0

xq

4

General Pruning Framework
Input tuples A0

v = new C · · ·

Query tuple xq

ALIAS(x,y)

Datalog rules

v2 → h ⇐ v2 = v1 , v1 → h
···
P
subset of A0 used to derive xq
A0

Prune/prove operator P

P(A0 )
A0

xq

4

General Pruning Framework
Input tuples A0

v = new C · · ·

Query tuple xq

ALIAS(x,y)

Datalog rules

v2 → h ⇐ v2 = v1 , v1 → h
···
P
subset of A0 used to derive xq
A0

Prune/prove operator P

P(A0 )
A0

xq
Query proven ⇔ P(A0 ) = ∅
4

Prune and Reﬁne
(abstract tuples)

A0

u = new C v = new C · · ·

5

Prune and Reﬁne
(abstract tuples)

Prune

A0
P

u = new C v = new C · · ·
run 0-CFA

5

Prune and Reﬁne
(abstract tuples)

Prune
(relevant tuples)

A0
P
˜
A0

u = new C v = new C · · ·
run 0-CFA
u = new C v = new C

5

Prune and Reﬁne
(abstract tuples)

Prune
(relevant tuples)

Reﬁne

A0
P
˜
A0

u = new C v = new C · · ·
run 0-CFA
u = new C v = new C

α1

5

Prune and Reﬁne
(abstract tuples)

Prune
(relevant tuples)

Reﬁne
(reﬁned tuples)

A0
P
˜
A0

u = new C v = new C · · ·
run 0-CFA
u = new C v = new C

α1
A1

v:i1 = new C v:i2 = new C

5

Prune and Reﬁne
(abstract tuples)

Prune
(relevant tuples)

Reﬁne
(reﬁned tuples)

Prune

A0
P
˜
A0

u = new C v = new C · · ·
run 0-CFA
u = new C v = new C

α1
A1
P

v:i1 = new C v:i2 = new C
run 1-CFA

5

Prune and Reﬁne
(abstract tuples)

A0

Prune
(relevant tuples)

P
˜
A0

Reﬁne
(reﬁned tuples)

u = new C v = new C · · ·
run 0-CFA
u = new C v = new C

α1
A1

Prune

P
∅

v:i1 = new C v:i2 = new C
run 1-CFA
⇒ query is proven

5

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0

α1

α2

···

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

For t = 0, 1, 2, . . . :
˜
˜
Prune: At = P(At ). If At = ∅: return proven.
˜
Reﬁne: At+1 = αt+1 (At ).

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

For t = 0, 1, 2, . . . :
˜
˜
Prune: At = P(At ). If At = ∅: return proven.
˜
Reﬁne: At+1 = αt+1 (At ).
Main Result:
Prune-Reﬁne after t iterations

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

For t = 0, 1, 2, . . . :
˜
˜
Prune: At = P(At ). If At = ∅: return proven.
˜
Reﬁne: At+1 = αt+1 (At ).
Main Result:
Prune-Reﬁne after t iterations

Full Analysis on αt

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

For t = 0, 1, 2, . . . :
˜
˜
Prune: At = P(At ). If At = ∅: return proven.
˜
Reﬁne: At+1 = αt+1 (At ).
Main Result:
Prune-Reﬁne after t iterations

=

Full Analysis on αt

6

Prune-Reﬁne Algorithm
Input:
Sequence of abstractions: α0
A0 , initial set of tuples

α1

α2

···

For t = 0, 1, 2, . . . :
˜
˜
Prune: At = P(At ). If At = ∅: return proven.
˜
Reﬁne: At+1 = αt+1 (At ).
Main Result:
Prune-Reﬁne after t iterations
fast

=

Full Analysis on αt
slow

6

Rest of Talk

Pre-Pruning Extension

Experiments

7

Pre-Pruning

˜
At−1
v = new C

8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C
v:h3 = new C
v:h4 = new C
v:h5 = new C

8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C

Prune P
expensive!

v:h3 = new C
v:h4 = new C
v:h5 = new C

8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C

Prune P

v:h3 = new C
v:h4 = new C
v:h5 = new C

βt

αt

Bt
v:t0 = new C
v:t1 = new C
8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C

Prune P

v:h3 = new C
v:h4 = new C
v:h5 = new C

βt

αt

Bt
v:t0 = new C
v:t1 = new C

Prune P

˜
Bt
v:t0 = new C
v:t1 = new C
8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C

Prune P

v:h3 = new C
v:h4 = new C
v:h5 = new C
αt
βt

αt

Bt
v:t0 = new C
v:t1 = new C

Prune P

˜
Bt
v:t0 = new C
v:t1 = new C
8

Pre-Pruning
At
v:h0 = new C
˜
At−1
v = new C

Reﬁne αt

v:h1 = new C
v:h2 = new C

Prune P
cheaper

v:h3 = new C
v:h4 = new C
v:h5 = new C
αt
βt

αt

Bt
v:t0 = new C
v:t1 = new C

Prune P

˜
Bt
v:t0 = new C
v:t1 = new C
8

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

Choose abstraction τ ;

9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

Choose abstraction τ ; set βt = αt ◦ τ

9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

amount pre-pruned

Choose abstraction τ ; set βt = αt ◦ τ

cost
9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

Choose abstraction τ ; set βt = αt ◦ τ
amount pre-pruned

τ = λx.x (no abstraction)

cost
9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

amount pre-pruned

Choose abstraction τ ; set βt = αt ◦ τ
τ = λx.x (no abstraction)

τ = λx.⊥ (total abstraction)
cost
9

Which Abstractions for Pre-Pruning?
(main)

α0

α1

α2

···

(auxiliary)

β0

β1

β2

···

amount pre-pruned

Choose abstraction τ ; set βt = αt ◦ τ
τ = λx.x (no abstraction)
good τ (complementary to αt )

τ = λx.⊥ (total abstraction)
cost
9

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C

10

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C
Type-based: τ = replace alloc. sites with types [Smaragdakis et al. 2011]
τ
v:h5:h8 = new C
v:t1:t0 = new C

10

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C
Type-based: τ = replace alloc. sites with types [Smaragdakis et al. 2011]
τ
v:h5:h8 = new C
v:t1:t0 = new C
We use τ = type of containing class × type of allocation site

10

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C
Type-based: τ = replace alloc. sites with types [Smaragdakis et al. 2011]
τ
v:h5:h8 = new C
v:t1:t0 = new C
We use τ = type of containing class × type of allocation site
class C1 {
h1:
x = new C2
}

10

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C
Type-based: τ = replace alloc. sites with types [Smaragdakis et al. 2011]
τ
v:h5:h8 = new C
v:t1:t0 = new C
We use τ = type of containing class × type of allocation site
class C1 {
τ
h1:
x = new C2
h1
(C1,C2)
}

10

Type-Based Abstractions for Pre-Pruning
k-limited: αk = take length k preﬁx
α1
v:h5:h8 = new C
v:h5 = new C
Type-based: τ = replace alloc. sites with types [Smaragdakis et al. 2011]
τ
v:h5:h8 = new C
v:t1:t0 = new C
We use τ = type of containing class × type of allocation site
class C1 {
τ
h1:
x = new C2
h1
(C1,C2)
}

Composed: β1 = α1 ◦ τ
v:h5:h8 = new C

β1
v:t1 = new C

10

Rest of Talk

Pre-Pruning Extension

Experiments

11

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):

12

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):
Downcast safety checking (downcast): x = (C)y

12

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):
Downcast safety checking (downcast): x = (C)y
Monomorphic call site detection (monosite): x.g()

12

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):
Downcast safety checking (downcast): x = (C)y
Monomorphic call site detection (monosite): x.g()
Race detection (race): x.f = ... | y.f = ...

12

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):
Downcast safety checking (downcast): x = (C)y
Monomorphic call site detection (monosite): x.g()
Race detection (race): x.f = ... | y.f = ...
Benchmarks:
elevator
hedc
weblech
lusearch
avrora

description
discrete event simulation program
web crawler
website downloading and mirroring tool
text indexing and search tool
AVR microcontroller simulation/analysis framework

# bytecodes
39K
151K
230K
267K
312K

# alloc. sites
637
1,494
2,545
2,822
4,823

12

Experimental Setup
Clients (based on ﬂow-insensitive k-object-sensitivity):
Downcast safety checking (downcast): x = (C)y
Monomorphic call site detection (monosite): x.g()
Race detection (race): x.f = ... | y.f = ...
Benchmarks:
elevator
hedc
weblech
lusearch
avrora

description
discrete event simulation program
web crawler
website downloading and mirroring tool
text indexing and search tool
AVR microcontroller simulation/analysis framework

# bytecodes
39K
151K
230K
267K
312K

# alloc. sites
637
1,494
2,545
2,822
4,823

Details:
64-bit IBM J9VM 1.6, Chord with bddbddb Datalog solver
Terminate a process if it exceeds 8GB of memory
12

Curbing the Exponential Growth
Methods:
no pruning

13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]

13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning

13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning
Prune-Reﬁne with pre-pruning

13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning
Prune-Reﬁne with pre-pruning
|At | = number of tuples passed into P (Datalog solver)

13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning
Prune-Reﬁne with pre-pruning
|At | = number of tuples passed into P (Datalog solver)
1.3e7

7.6e6

1.0e7

|At |

1.7e7
1.4e7

6.1e6

7.6e6

1.0e7

4.6e6

|At |

5.1e6
2.5e6

|At |

6.8e6
3.4e6

1

2

3

4

t
(a) downcast/weblech

5

3.0e6
1.5e6

2

4

6

8

10

t
(b) downcast/lusearch

4

8

12

16

t
(c) downcast/avrora
13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning
Prune-Reﬁne with pre-pruning
|At | = number of tuples passed into P (Datalog solver)
1.4e7

1.7e7

1.1e7

|At |

1.7e7
1.4e7

1.4e7

8.2e6

1.0e7

1.1e7

|At |

5.5e6
2.7e6

|At |

6.8e6
3.4e6

1

2

3

4

t
(a) monosite/weblech

5

7.0e6
3.5e6

1

2

3

4

t
(b) monosite/lusearch

5

2

4

6

8

t
(c) monosite/avrora
13

Curbing the Exponential Growth
Methods:
no pruning
selected reﬁnement [Liang et al. 2011]
Prune-Reﬁne without pre-pruning
Prune-Reﬁne with pre-pruning
|At | = number of tuples passed into P (Datalog solver)
2.0e7

1.4e6

1.6e7

|At |

1.7e7
1.4e7

1.1e6

1.2e7

1.0e7

8.3e5

|At |

7.8e6
3.9e6

|At |

6.8e6
3.4e6

1

2

3

t
(a) race/weblech

4

5

5.6e5
2.8e5

1

2

3

t
(b) race/lusearch

4

1

2

3

4

t
(c) race/avrora
13

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

At
100%

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

Pre-Prune
At

At

100%

22%

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

Pre-Prune

Prune P

At

At

˜
At

100%

22%

18%

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

Pre-Prune

Prune P

At

At

˜
At

100%

22%

18%

Reﬁne αt+1

At+1
272%

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

Pre-Prune

Prune P

At

At

˜
At

100%

22%

Reﬁne αt+1

18%

At+1
272%

(numbers averaged across all clients/benchmarks/iterations)

14

How Much is Pruned?

In each iteration, what fraction of tuples are kept?

Pre-Prune

Prune P

At

At

˜
At

100%

22%

Reﬁne αt+1

18%

At+1
272%

(numbers averaged across all clients/benchmarks/iterations)

Take Away: Pruning (especially pre-pruning) helps a lot to maintain tractability

14

Impact on Queries Proven
How many queries remain unproven?

15

Impact on Queries Proven
How many queries remain unproven?
client/benchmark \ k
downcast/elevator
downcast/hedc
downcast/weblech
downcast/lusearch
downcast/avrora
monosite/elevator
monosite/hedc
monosite/weblech
monosite/lusearch
monosite/avrora
race/elevator
race/hedc
race/weblech
race/lusearch
race/avrora

1
0
10
24
36
12
1
164
273
593
288
475
23,033
7,286
33,845
62,060

2
8
14
14
10
1
149
258
454
278
440
22,043
4,742
23,509
61,807

3
3
6
6
6
1
149
252
447
272
437
21,966
4,669
16,957
61,734

4
2
6
5
6
1
149
252
447
437
-

5
2
5
6
1
437
-

15

Impact on Queries Proven
How many queries remain unproven?
client/benchmark \ k
downcast/elevator
downcast/hedc
downcast/weblech
downcast/lusearch
downcast/avrora
monosite/elevator
monosite/hedc
monosite/weblech
monosite/lusearch
monosite/avrora
race/elevator
race/hedc
race/weblech
race/lusearch
race/avrora

1
0
10
24
36
12
1
164
273
593
288
475
23,033
7,286
33,845
62,060

2
8
14
14
10
1
149
258
454
278
440
22,043
4,742
23,509
61,807

3
3
6
6
6
1
149
252
447
272
437
21,966
4,669
16,957
61,734

4
2
6
5
6
1
149
252
447
437
-

5
2
5
6
1
437
-

Take Away: By using Prune-Reﬁne, able to prove two additional queries
15

Conclusion
• Goal: scale up static analyses

16

Conclusion
• Goal: scale up static analyses
• Contribution: new general pruning framework

16

Conclusion
• Goal: scale up static analyses
• Contribution: new general pruning framework
• Key Idea: use coarse abstraction to remove irrelevant tuples

16

Conclusion
• Goal: scale up static analyses
• Contribution: new general pruning framework
• Key Idea: use coarse abstraction to remove irrelevant tuples
• Theoretical Result: pruning is correct

16

Conclusion
• Goal: scale up static analyses
• Contribution: new general pruning framework
• Key Idea: use coarse abstraction to remove irrelevant tuples
• Theoretical Result: pruning is correct
• Empirical Result: enable much ﬁner abstractions

16

Conclusion
• Goal: scale up static analyses
• Contribution: new general pruning framework
• Key Idea: use coarse abstraction to remove irrelevant tuples
• Theoretical Result: pruning is correct
• Empirical Result: enable much ﬁner abstractions
http://code.google.com/p/jchord

Thank you!
16

