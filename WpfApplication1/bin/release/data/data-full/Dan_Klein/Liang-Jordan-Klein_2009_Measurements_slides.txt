Learning from Measurements
in Exponential Families
ICML – Montreal
June 16, 2009

Percy Liang

Michael Jordan

Dan Klein

The big picture
target
∗ human
predictor p

2

The big picture
target
∗ human
predictor p
y:

Example:

feat feat feat

x: View
avail

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

1

size

size size ...

... 2 bedroom 1 bath ...

2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]

2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]

2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

Outline:
1. Coherently learn from diverse measurements
2

The big picture
target
∗ human
predictor p
y:

Example:

information

feat feat feat

x: View
avail

learning
algorithm

of

feat

...

Los Gatos Foothills ...

avail avail ... size

Available July

feat

learned
predictor p
ˆ

1

size

size size ...

... 2 bedroom 1 bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

Outline:
1. Coherently learn from diverse measurements
2. Actively select the best measurements
2

Measurements
X1 , Y1
X2 , Y2
X3 , Y3
... ...
Xi , Yi
... ...
Xn , Yn

3

Measurements
σ( X1 , Y1 )
σ( X2 , Y2 )
σ( X3 , Y3 )
... ...
σ( Xi , Yi )
... ...
σ( Xn , Yn )

Measurement features: σ(x, y) ∈ Rk

3

Measurements
σ( X1 , Y1 )
σ( X2 , Y2 )
σ( X3 , Y3 )
... ...
σ( Xi , Yi )
... ...
σ( Xn , Yn )
+ noise
+τ

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

σ(Xi, Yi) + noise

τ=
i=1

3

Measurements
σ( X1 , Y1 )
σ( X2 , Y2 )
σ( X3 , Y3 )
... ...
σ( Xi , Yi )
... ...
σ( Xn , Yn )
+ noise
+τ

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

σ(Xi, Yi) + noise

τ=
i=1

Xi
τ
Yi
n

3

Measurements
σ( X1 , Y1 )
σ( X2 , Y2 )
σ( X3 , Y3 )
... ...
σ( Xi , Yi )
... ...
σ( Xn , Yn )
+ noise
+τ

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

σ(Xi, Yi) + noise

τ=
i=1

Xi
τ
Yi
n

Set σ to reveal various types of information about Y through τ

3

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) = i I[xi = View, yi = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) = i I[xi = View, yi = *]
Label proportions:
σj (x, y) = i I[yi = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) = i I[xi = View, yi = *]
Label proportions:
σj (x, y) = i I[yi = *]
Label preference:
σj (x, y) = i I[yi = feat] − I[yi = avail]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) = i I[xi = View, yi = *]
Label proportions:
σj (x, y) = i I[yi = *]
Label preference:
σj (x, y) = i I[yi = feat] − I[yi = avail]
Can get measurement values τ without looking at all examples
4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) = i I[xi = View, yi = *]
Label proportions:
σj (x, y) = i I[yi = *]
Label preference:
σj (x, y) = i I[yi = feat] − I[yi = avail]
Can get measurement values τ without looking at all examples
Next: How to combine these diverse measurements coherently?
4

Prediction model
Bayesian framework:
Xi
τ
Yi
n

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd: model features

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd: model features
θ ∈ Rd: model parameters
5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd: model features
θ ∈ Rd: model parameters
A(θ; x) = exp{ φ(x, y), θ }dy: log-partition function
5

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(Y, θ) || p(θ, Y | τ, X))
q∈QY θ

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(Y, θ) || p(θ, Y | τ, X))
q∈QY θ

Approximations:
˜
• QY θ : mean-ﬁeld factorization of q(Y ) and degenerate θ

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(Y, θ) || p(θ, Y | τ, X))
q∈QY θ

Approximations:
˜
• QY θ : mean-ﬁeld factorization of q(Y ) and degenerate θ
• KL: measurements only hold in expectation (w.r.t. q(Y ))

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(Y, θ) || p(θ, Y | τ, X))
q∈QY θ

Approximations:
˜
• QY θ : mean-ﬁeld factorization of q(Y ) and degenerate θ
• KL: measurements only hold in expectation (w.r.t. q(Y ))
Algorithm:
Apply Fenchel duality → saddlepoint problem
Take alternating stochastic gradient steps
6

Information geometry viewpoint
(assume zero measurement noise)
def

P = {pθ (y | x) : θ ∈ Rd}

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

def

P = {pθ (y | x) : θ ∈ Rd}

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

def

P = {pθ (y | x) : θ ∈ Rd}

KL (q || p)

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

Interpretation:
Measurements shape Q

def

P = {pθ (y | x) : θ ∈ Rd}

KL (q || p)

Find model in P with best ﬁt

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

Interpretation:
Measurements shape Q

def

P = {pθ (y | x) : θ ∈ Rd}

KL (q || p)

Find model in P with best ﬁt

Two ways to recover supervised learning:
1. Measure σ = φ: P ∩ Q is the unique solution

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

Interpretation:
Measurements shape Q

def

P = {pθ (y | x) : θ ∈ Rd}

KL (q || p)

Find model in P with best ﬁt

Two ways to recover supervised learning:
1. Measure σ = φ: P ∩ Q is the unique solution
2. Measure σ = {I[x = a, y = b]}:
Q = {empirical distribution}, project onto P
7

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]
If f is a measurement feature (direct):
“inputs in A should be labeled according to τ ”

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]
If f is a measurement feature (direct):
“inputs in A should be labeled according to τ ”
If f is a model feature (indirect):
“inputs in A should be labeled similarly”
8

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g., i I[xi = View , yi = feat])

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g., i I[xi = View , yi = feat])
Per-position test accuracy (on 100 examples):
# labeled examples
General Expectation Criteria
Constraint-Driven Learning
Measurements

10
74.6
74.7
71.4

25
77.2
78.5
76.5

100
80.5
81.7
82.5

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g., i I[xi = View , yi = feat])
Per-position test accuracy (on 100 examples):
# labeled examples
General Expectation Criteria
Constraint-Driven Learning
Measurements

10
74.6
74.7
71.4

25
77.2
78.5
76.5

100
80.5
81.7
82.5

Able to integrate labeled examples and predicates gracefully
9

So far: given measurements, how to learn

Next: how to choose measurements?

10

Bayesian decision theory
Xi
τ

θ
Yi
n

What do we do with an (approximate) posterior p(θ, Y | X, τ )?

11

Bayesian decision theory
reward

Xi

X

τ

θ
ˆ
Y

Y

Yi
n

What do we do with an (approximate) posterior p(θ, Y | X, τ )?
Bayes-optimal predictor:
ˆ
average over X , max over Y , average over Y of reward

11

Bayesian decision theory
reward

Xi

X

τ

θ
ˆ
Y

Y

Yi
n

What do we do with an (approximate) posterior p(θ, Y | X, τ )?
Bayes-optimal predictor:
ˆ
average over X , max over Y , average over Y of reward
R(σ, τ ) = expected reward of Bayes-optimal predictor
(i.e., how happy we are with the given situation)

11

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X)[U (σ, τ )]

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X)[U (σ, τ )]

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X)[U (σ, τ )]
Choose best measurement feature σ:
σ ∗ = argmaxσ U (σ)
12

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
test accuracy

0.9
0.8
0.7
0.6
random
entropy

0.6
20

40

60

80

100

# measurements k

(a) Labeling examples
13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
0.8

0.8

0.7

test accuracy

test accuracy

0.9

0.7
0.6
random
entropy

0.6
20

40

60

80

100

# measurements k

(a) Labeling examples

0.7
frequency
random
entropy

0.6
0.5
20

40

60

80

100

# measurements k

(b) Labeling word types
13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
0.8

0.8

0.7

test accuracy

test accuracy

0.9

0.7
0.6
random
entropy

0.6
20

40

60

80

100

# measurements k

(a) Labeling examples

0.7
frequency
random
entropy

0.6
0.5
20

40

60

80

100

# measurements k

(b) Labeling word types
13

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

14

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

Bayesian model

14

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

14

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

information
geometry
14

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

decision theory

information
geometry
14

Summary
target
human
predictor p∗

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

information
geometry

Bayesian model

decision theory

active
learning
14

