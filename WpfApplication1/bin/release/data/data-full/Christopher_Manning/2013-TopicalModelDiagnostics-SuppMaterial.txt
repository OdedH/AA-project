Topic Model Diagnostics:
Assessing Domain Relevance via Topical Alignment
(Supplementary Materials)

Jason Chuang
Stanford University, 353 Serra Mall, Stanford, CA 94305 USA

jcchuang@cs.stanford.edu

Sonal Gupta
Stanford University, 353 Serra Mall, Stanford, CA 94305 USA

sonal@cs.stanford.edu

Christopher D. Manning
Stanford University, 353 Serra Mall, Stanford, CA 94305 USA

manning@cs.stanford.edu

Jeﬀrey Heer
Stanford University, 353 Serra Mall, Stanford, CA 94305 USA

jheer@cs.stanford.edu

1. Graphs
Supplementary Figure 2 shows an enlarged version of
Figure 1 in the main paper with additional details in
the caption.
Supplementary Figure 3 shows additional data points
for Figure 7 in the main paper.

2. Expert-Authored Concepts in
Information Visualization
We conducted a survey asking ten experienced information visualization (InfoVis) researchers to identify
what they consider to be signiﬁcant and coherent areas
of research in their ﬁeld. Participants were asked to
label each area, and describe it with lists of exemplary
terms and documents.
We focused on InfoVis research due to relevance, scope
and familiarity. Analysis of academic publications is
one of the common real-world uses of topic modeling
(Griﬃths & Steyvers, 2004). Our familiarity with the
InfoVis community allowed us to contact experts capable of exhaustively enumerating its research areas.
InfoVis has a single primary conference, simplifying
the construction and analysis of its publications.
Survey recruitment was by invitation only. We contacted 23 researchers (12 past chairs of the IEEE Information Visualization Conference, six faculty members, two senior industry researchers, and three PhD
students within a year of graduation) on a rolling ba-

sis over four months from March to June 2012. We
sent out 14 surveys, and received ten completed results from four past chairs, two faculty members, one
industry researcher, and three PhD students. We initially limited our survey to only past conference chairs,
and expanded our criteria to established researchers to
enable greater participation.
2.1. Survey Design
We asked participants to describe topics using labels,
terms, and documents that they would use as if they
were communicating with a peer. Representative terms
should exemplify a topic and diﬀerentiate the topic
from other areas of research. Terms could be any notable techniques, methods, systems, or people; multiword phrases were allowed. Representative documents
exemplify the core contributions of a topic. Pilot studies suggested that citing a paper using freeform text is
time consuming, disruptive to the recall process, and
prone to errors. In response, we limited the representative papers to those published at IEEE Information Visualization Conference, and provided a drag-and-drop
interface for associating a paper with a topic. We requested that participants enter ten or more terms and
three or more papers per topic, though fewer responses
were permissible. We asked participants to complete
the survey in a single session if possible.
Conducted using a single webpage (Supplementary
Figure 1), we designed the survey to (1) elicit expert
responses with minimal bias, (2) support recall, (3)

Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment

Supplementary Figure 1: Survey user interface: Participants were provided with blank boxes in a single webpage, and
asked to identify all coherent and signiﬁcant areas of research in information visualization, in a manner as if communicating
with a peer. An optional panel on the right shows 17 years of IEEE Information Visualization Conference proceedings.

enable accurate data collection, and (4) balance between maximizing the value of available expert time
and preventing participant exhaustion.
To avoid artiﬁcially limiting what they consider to be
the scope of InfoVis, the participants were instructed
to consider work published anywhere when creating
the research topics. Participants were provided with
multiple blank boxes, and asked to enumerate all areas they consider to be signiﬁcant. The webpage contained twenty boxes by default, but subjects could add
additional boxes if desired.
In pilot studies, the single most prominent issue was recall. Exhaustively identifying all concepts in a domain
purely from memory can be diﬃcult. In response, we
added a panel on the right that contains a list of all 442
papers published at the IEEE Information Visualization Conference (1995 to 2011), grouped by year. As
InfoVis is a single track conference, we group papers
within each year by session, so the ordering of sessions
and papers are consistent with the actual conference
program. Participants could browse through the proceedings or search for speciﬁc papers by title, author,
or abstract.
The most scarce resource in conducting the survey was
acquiring available expert time. To maximize the value
of their responses, we chose exemplary words and documents as the means to express a concept. Labels
are widely used in cognitive psychology (Rosch et al.,
1976) for identifying topics. Based on pilot studies,
the two chosen properties — freeform typing of a list

of terms, and drag-and-drop speciﬁcation of papers —
minimize input complexity and allow experts to focus
on the construction of topics. We omitted other descriptive attributes, such as summary sentences, which
took pilot participants much longer to enter. We displayed twenty default boxes to provide reasonably exhaustive coverage of the domain while bounding the
length of the survey. In a preliminary study, two of
the authors exhaustively annotated every document
in the corpus with multiple tags. The overlap between
the two sets of annotations indicated that the domain
was covered by approximately twenty shared topics.
2.2. Survey Data
We received a total of 202 topical responses (maximum of 22 and minimum of 18 per subject). The participants speciﬁed an average of 5.71 terms (max 19,
min 1, median 8) and 5.15 documents (max 25, min
1, median 7) per topic. Subjects provided 171 distinct
topic labels and 769 distinct terms. Together, the experts cited a total of 342 distinct documents (77% of
all papers published at IEEE Information Visualization Conference) which we consider to be a reasonable
coverage of the ﬁeld.
We analyzed timing information for seven participants
who had active internet connections for the full duration of their survey. The survey webpage automatically saved responses every minute, allowing us to
track changes at that granularity. On average, the
experts spent 91.7 minutes (max 162, min 42) edit-

Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment

ing their responses within a maximum of ﬁve sessions.
The amount of editing time suggests that the survey
taxed the experts attention and available contiguous
time.

We prove by induction, that P k+1 = P k ∗ X k+1 .
As the base case:
P 0 = [1]T
P 1 = X1 = 1 ∗ X1 = P 0 ∗ X1

3. Mathematical Derivation:
Convolution Operator

For the inductive step:

{xi }∞
i=1,deﬁnitive

i

Given a Bernoulli process
where x is
the probability of observe a positive outcome for the
k
i-th event, let Pdeﬁnitive (n) represent the probability
that we observe exactly n positive outcomes among
the following k events {xi }k
i=1,deﬁnitive .
Similarly, given a Bernoulli process {xi }∞
i=1,noise where
xi is the probability of observe a positive outcome for
k
the i-th event, let Pnoise (n) be the probability that we
observe exactly n positive outcomes among the following k events {xi }k
i=1,noise .
Suppose we construct a new series of Bernoulli process {xi }m
i=1,combined consisted of m events, by randomly drawing from the two processes {xi }deﬁnitive and
{xi }noise . Suppose we draw k events from {xi }deﬁnitive
and m − k events from {xi }noise .
Let Pcombined (n) be the probability that we observe
exactly n positive outcomes among its m events. I
m−k
k
claim that: Pcombined = Pdeﬁnitive ∗ Pnoise

k
Pik+1 = Pi−1 · xk+1 + Pik · (1 − xk+1 )
k+1
k+1
k
= Pi−1 · X1 + Pik · X0
1
k+1
k
Pi−t · Xt

=
P

k+1

t=0
k

= P ∗ X k+1

3.4. Associativity
Let P j,k represent the observed cumulative outcome
for events j to k (inclusive). Since convolution is associative:
P 0,m = P 0,k ∗ X k+1 ∗ X k+2 ∗ · · · ∗ X n
= P 0,k ∗ P k+1,m
It follows that the expected topical-concept matches
for the combined chart is:
Pcombined = Pdeﬁnitive ∗ Pnoise

3.1. Sampling from Two Bernoulli Processes
Since events in a Bernoulli process are considered independent, we can re-arrange the order of events without
aﬀecting the expected number of positive outcomes.
3.2. Sampling from Deﬁnitive vs. Noise Charts
When computing the expected number of positive outcomes for Pcombined , the combined deﬁnitive and noise
charts, we re-arrange the series {xi }combined so that
the k deﬁnitive events occur ﬁrst and the m − k noise
events later.
3.3. Convolution
i

i

Let {x } be a Bernoulli event where x is the probability of observing a positive outcome for event i. We
construct a 2-vector X i = [1 − xi , xi ]T .
Let P k be the multinomial distribution representing the observed cumulative outcome of the ﬁrst k
events where P k (n) is the probability that we observed
exactly n positive outcomes for the ﬁrst k events.
We represent P k as an (k + 1)-vector with entries
[P k (0), P k (1), · · · , P k (k)]T .

4. Noise Estimation
4.1. Setting k
By construction, the distributions P and Pnoise have
the same mean. We arbitrarily choose k so that
Pdeﬁnitive has the same mean as P .
For non-integer values of k, Pdeﬁnitive is zero everywhere except for two values, Pdeﬁnitive ( k ) = k − k
and Pdeﬁnitive ( k ) = k − k .
4.2. Solving for γ
Discrete convolution can be convert to matrix multiplication. We convert the “convolute by Pnoise ” operation
k(1−γ)
into a Toeplitz matrix A = Anoise . Let P = Pdeﬁnitive .
γ
argmin KL(P ∗ Pnoise ||P )
γ

argmin KL(AP ||P )
γ

argmin P T AT log(AP ) − P T AT log(P )
γ

We apply gradient descent to determine the optimal
value γ that minimizes the (convex) objective function.

Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment

5. Denoise Computation

References

5.1. Solving for Pdenoised

Griﬃths, Thomas L. and Steyvers, Mark. Finding scientiﬁc
topics. Proceedings of the National Academy of Sciences,
101(1):5228–5235, 2004.

Let P = Pdenoised .

Rosch, Eleanor, Mervis, Carolyn B, Gray, Wayne D, Johnson, David M, and Boyes-Braem, Penny. Basic objects in
natural categories. Cognitive Psychology, 8(3):382–439,
1976.

argmin KL(P ∗ Pnoise ||P )
P

argmin KL(AP ||P )
P

argmin P

T

AT log(AP ) − P

T

AT log(P )

P

subject to
Pi = 1
i

0 ≤ Pi ≤ 1

for all i

The above is an optimization involving both equality and inequality constraints. We apply sequential
quadratic programming to solve to P using three
mathematical components: barrier method to remove
inequality constraints, ﬁrst-order trust region to solve
for equality-constrained minimizations, and heuristics
to obtain a good initial solution.
5.2. Outer Iteration: Barrier Method
We apply barrier method to remove the inequality constraints, in order to reduce complexity and speed up
computation. We modify the objective function as the
following.
P

T

AT log(AP ) − P

T

AT log(P ) + e−αP + eα(1+P

We perform 50 iterations and gradually increase α
from 500 to 50000.
5.3. Inner Iteration: Trust Region
Within each iteration of the barrier method, we applied ﬁrst-order trust region solve for an optimal solution P .
5.4. Initial Solution
To ensure better convergence, we solve the linear system of equations AP = P , to obtain an initial solution P (0) . We clamp the values of P (0) to within
[0, 1] and L1 normalize the vector to ensure it’s a valid
probability distribution. We use the resulting vector
as the initial solution for the aforementioned barrier
method/trust region solver.

)

Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment

Supplementary Figure 2: Correspondence chart between latent topics and reference concepts. The set of 25 latent
topics are generated by a LDA model (N = 25, α = 0.01, β = 0.01) and displayed along the columns. The set of 18
reference concepts are given by one of the InfoVis experts and displayed along the rows. Area of circles represents
the matching likelihood between topic-concept pairs; likelihoods exceeding random chance are marked with a
bold border. Bars on the right show the probability that a concept is missing (grey), resolved (blue), or repeated
(light blue). Bars on the bottom show the probability that a topic is junk (grey), resolved (orange), or fused
(light orange). This visual analysis tool is available online at: http://vis.stanford.edu/topic-diagnostics

Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment

Supplementary Figure 3: Exhaustive grid search. Topical alignment for LDA models over a grid of parameter/hyperparameter settings: N ∈ [1, 80] (horizontal axis across subgraphs), 13 values of α ∈ [0.5/N, 5000/N ]
(vertical axis), and 13 values of β ∈ [0.0001, 1] (horizontal axis). We observe a qualitative shift in topical composition around β=0.25. For β > 0.25, the models generate fused topics that uncover but do not fully resolve
a majority of the reference concepts as N increases. For β < 0.25, the proportion of resolved and fused topics
remain stable regardless of N . Overall, decreasing β or increasing α leads to a decrease in coverage.

