The Inﬁnite Tree
Jenny Rose Finkel, Trond Grenager, and Christopher D. Manning
Computer Science Department, Stanford University
Stanford, CA 94305
{jrfinkel, grenager, manning}@cs.stanford.edu

Abstract
Historically, unsupervised learning techniques have lacked a principled technique
for selecting the number of unseen components. Research into non-parametric priors,
such as the Dirichlet process, has enabled instead the use of inﬁnite models, in which the
number of hidden categories is not ﬁxed, but
can grow with the amount of training data.
Here we develop the inﬁnite tree, a new inﬁnite model capable of representing recursive
branching structure over an arbitrarily large
set of hidden categories. Speciﬁcally, we
develop three inﬁnite tree models, each of
which enforces different independence assumptions, and for each model we deﬁne a
simple direct assignment sampling inference
procedure. We demonstrate the utility of
our models by doing unsupervised learning
of part-of-speech tags from treebank dependency skeleton structure, achieving an accuracy of 75.34%, and by doing unsupervised
splitting of part-of-speech tags, which increases the accuracy of a generative dependency parser from 85.11% to 87.35%.

1 Introduction
Model-based unsupervised learning techniques have
historically lacked good methods for choosing the
number of unseen components. For example, kmeans or EM clustering require advance speciﬁcation of the number of mixture components. But
the introduction of nonparametric priors such as the
Dirichlet process (Ferguson, 1973) enabled development of inﬁnite mixture models, in which the number of hidden components is not ﬁxed, but emerges
naturally from the training data (Antoniak, 1974).

Teh et al. (2006) proposed the hierarchical Dirichlet process (HDP) as a way of applying the Dirichlet
process (DP) to more complex model forms, so as to
allow multiple, group-speciﬁc, inﬁnite mixture models to share their mixture components. The closely
related inﬁnite hidden Markov model is an HMM
in which the transitions are modeled using an HDP,
enabling unsupervised learning of sequence models
when the number of hidden states is unknown (Beal
et al., 2002; Teh et al., 2006).
We extend this work by introducing the inﬁnite
tree model, which represents recursive branching
structure over a potentially inﬁnite set of hidden
states. Such models are appropriate for the syntactic
dependency structure of natural language. The hidden states represent word categories (“tags”), the observations they generate represent the words themselves, and the tree structure represents syntactic dependencies between pairs of tags.
To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree
structure. This is useful, because coarse-grained
syntactic categories, such as those used in the Penn
Treebank (PTB), make insufﬁcient distinctions to be
the basis of accurate syntactic parsing (Charniak,
1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical
forms themselves (Collins, 2003; Charniak, 2000),
manually split the tagset into a ﬁner-grained one
(Klein and Manning, 2003a), or learn ﬁner grained
tag distinctions using a heuristic learning procedure
(Petrov et al., 2006). We demonstrate that the tags
learned with our model are correlated with the PTB
POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training.

2 Finite Trees
We begin by presenting three ﬁnite tree models, each
with different independence assumptions.

ρ

πk

Each multinomial over children πk is distributed according to a Dirichlet distribution with parameter ρ:

z1

πk |ρ ∼ Dirichlet(ρ, . . . , ρ)
H

z2

z3

x2

φk

x3

This model is presented graphically in Figure 1.

C
x1

Figure 1: A graphical representation of the ﬁnite
Bayesian tree model with independent children. The
plate (rectangle) indicates that there is one copy of
the model parameter variables for each state k ≤ C.
2.1

Independent Children

In the ﬁrst model, children are generated independently of each other, conditioned on the parent. Let
t denote both the tree and its root node, c(t) the list
of children of t, ci (t) the ith child of t, and p(t) the
parent of t. Each tree t has a hidden state zt (in a syntax tree, the tag) and an observation xt (the word).1
The probability of a tree is given by the recursive
deﬁnition:2
Ptr (t) = P(xt |zt )
P(zt′ |zt )Ptr (t′ )
′
t ∈c(t)

To make the model Bayesian, we must deﬁne random variables to represent each of the model’s parameters, and specify prior distributions for them.
Let each of the hidden state variables have C possible values which we will index with k. Each state k
has a distinct distribution over observations, parameterized by φk , which is distributed according to a
prior distribution over the parameters H:
φk |H ∼ H
We generate each observation xt from some distribution F (φzt ) parameterized by φzt speciﬁc to its
corresponding hidden state zt . If F (φk )s are multinomials, then a natural choice for H would be a
Dirichlet distribution.3
The hidden state zt′ of each child is distributed
according to a multinomial distribution πzt speciﬁc
to the hidden state zt of the parent:
xt |zt ∼ F (φzt )
zt′ |zt ∼ Multinomial(πzt )
1

To model length, every child list ends with a distinguished
stop node, which has as its state a distinguished stop state.
2
We also deﬁne a distinguished node t0 , which generates the
root of the entire tree, and P (xt0 |zt0 ) = 1.
3
A Dirichlet distribution is a distribution over the possible
parameters of a multinomial distributions, and is distinct from
the Dirichlet process.

2.2

Simultaneous Children

The independent child model adopts strong independence assumptions, and we may instead want models in which the children are conditioned on more
than just the parent’s state. Our second model thus
generates the states of all of the children c(t) simultaneously:
Ptr (t) = P(xt |zt )P((zt′ )t′ ∈c(t) |zt )

t′ ∈c(t)

Ptr (t′ )

where (zt′ )t′ ∈c(t) indicates the list of tags of the children of t. To parameterize this model, we replace the
multinomial distribution πk over states with a multinomial distribution λk over lists of states.4
2.3

Markov Children

The very large domain size of the child lists in the
simultaneous child model may cause problems of
sparse estimation. Another alternative is to use a
ﬁrst-order Markov process to generate children, in
which each child’s state is conditioned on the previous child’s state:
Ptr (t) = P(xt |zt )

|c(t)|
i=1

P(zci (t) |zci−1 (t) , zt )Ptr (t′ )

For this model, we augment all child lists with a distinguished start node, c0 (t), which has as its state
a distinguished start state, allowing us to capture
the unique behavior of the ﬁrst (observed) child. To
parameterize this model, note that we will need to
deﬁne C(C + 1) multinomials, one for each parent
state and preceding child state (or a distinguished
start state).

3 To Inﬁnity, and Beyond . . .
This section reviews needed background material
for our approach to making our tree models inﬁnite.
3.1

The Dirichlet Process

Suppose we model a document as a bag of words
produced by a mixture model, where the mixture
components might be topics such as business, politics, sports, etc. Using this model we can generate a
4

This requires stipulating a maximum list length.

γ

α0

α0

0.8

H

φk

πj

φk

∞

1
0.6

0.8
0.6

0.4
0.4

0.2
P(x = "profit")
i

β

π

1

H

zi

0.2
0

0

P(xi = "game")

Figure 2: Plot of the density function of a Dirichlet distribution H (the surface) as well as a draw
G (the vertical lines, or sticks) from a Dirichlet
process DP(α0 , H) which has H as a base measure. Both distributions are deﬁned over a simplex in which each point corresponds to a particular
multinomial distribution over three possible words:
“proﬁt”, “game”, and “election”. The placement of
the sticks is drawn from the distribution H, and is
independent of their lengths, which is drawn from a
stick-breaking process with parameter α0 .
document by ﬁrst generating a distribution over topics π, and then for each position i in the document,
generating a topic zi from π, and then a word xi
from the topic speciﬁc distribution φzi . The word
distributions φk for each topic k are drawn from a
base distribution H. In Section 2, we sample C
multinomials φk from H. In the inﬁnite mixture
model we sample an inﬁnite number of multinomials from H, using the Dirichlet process.
Formally, given a base distribution H and a concentration parameter α0 (loosely speaking, this controls the relative sizes of the topics), a Dirichlet process DP(α0 , H) is the distribution of a discrete random probability measure G over the same (possibly
continuous) space that H is deﬁned over; thus it is a
measure over measures. In Figure 2, the sticks (vertical lines) show a draw G from a Dirichlet process
where the base measure H is a Dirichlet distribution
over 3 words. A draw comprises of an inﬁnite number of sticks, and each corresponding topic.
We factor G into two coindexed distributions: π,
a distribution over the integers, where the integer
represents the index of a particular topic (i.e., the
height of the sticks in the ﬁgure represent the probability of the topic indexed by that stick) and φ, representing the word distribution of each of the top-

∞
zji

xi
N

π|α0
φk |H
zi |π
xi |zi , φ

∼ GEM(α0 )
∼H
∼π
∼ F (φzi )

xji
N

(a)
(b)
Figure 3: A graphical representation of a simple
Dirichlet process mixture model (left) and a hierarchical Dirichlet process model (right). Note that we
show the stick-breaking representations of the models, in which we have factored G ∼ DP(α0 , H) into
two sets of variables: π and φ.
ics (i.e., the location of the sticks in the ﬁgure). To
generate π we ﬁrst generate an inﬁnite sequence of
′
variables π ′ = (πk )∞ , each of which is distributed
k=1
according to the Beta distribution:
′
πk |α0 ∼ Beta(1, α0 )

Then π = (πk )∞ is deﬁned as:
k=1
′
πk = πk

k−1
i=1

′
(1 − πi )

Following Pitman (2002) we refer to this process as
π ∼ GEM(α0 ). It should be noted that ∞ πk =
k=1
1,5 and P (i) = πi . Then, according to the DP,
P (φi ) = πi . The complete model, is shown graphically in Figure 3(a).
To build intuition, we walk through the process of
generating from the inﬁnite mixture model for the
document example, where xi is the word at position i, and zi is its topic. F is a multinomial distribution parameterized by φ, and H is a Dirichlet
distribution. Instead of generating all of the inﬁnite
mixture components (πk )∞ at once, we can build
k=1
them up incrementally. If there are K known topics, we represent only the known elements (πk )K
k=1
and represent the remaining probability mass πu =
5
This is called the stick-breaking construction: we start with
a stick of unit length, representing the entire probability mass,
and successively break bits off the end of the stick, where the
′
proportional amount broken off is represented by πk and the
absolute amount is represented by πk .

φ1

φ2 φ3

φ4 φ5 φ6 φ7

...

β:
...
πj :
Figure 4: A graphical representation of πj , a broken
stick, which is distributed according to a DP with a
broken stick β as a base measure. Each βk corresponds to a φk .
1 − ( K πk ). Initially we have πu = 1 and
k=1
φ = ().
For the ith position in the document, we ﬁrst draw
a topic zi ∼ π. If zi = u, then we ﬁnd the coindexed topic φzi . If zi = u, the unseen topic, we
make a draw b ∼ Beta(1, α0 ) and set πK+1 = bπu
new
and πu = (1 − b)πu . Then we draw a parameter φK+1 ∼ H for the new topic, resulting in π =
new
(π1 , . . . , πK+1 , πu ) and φ = (φ1 , . . . , φK+1 ). A
word is then drawn from this topic and emitted by
the document.
3.2

The Hierarchical Dirichlet Process

Let’s generalize our previous example to a corpus
of documents. As before, we have a set of shared
topics, but now each document has its own characteristic distribution over these topics. We represent
topic distributions both locally (for each document)
and globally (across all documents) by use of a hierarchical Dirichlet process (HDP), which has a local
DP for each document, in which the base measure is
itself a draw from another, global, DP.
The complete HDP model is represented graphically in Figure 3(b). Like the DP, it has global broken stick β = (βk )∞ and topic speciﬁc word disk=1
tribution parameters φ = (φk )∞ , which are coink=1
dexed. It differs from the DP in that it also has local broken sticks πj for each group j (in our case
documents). While the global stick β ∼ GEM(γ)
is generated as before, the local sticks πj are distributed according to a DP with base measure β:
πj ∼ DP(α0 , β).
We illustrate this generation process in Figure 4.
The upper unit line represents β, where the size of
segment k represents the value of element βk , and
the lower unit line represents πj ∼ DP(α0 , β) for a
particular group j. Each element of the lower stick
was sampled from a particular element of the upper

stick, and elements of the upper stick may be sampled multiple times or not at all; on average, larger
elements will be sampled more often. Each element
βk , as well as all elements of πj that were sampled
from it, corresponds to a particular φk . Critically,
several distinct πj can be sampled from the same
βk and hence share φk ; this is how components are
shared among groups.
For concreteness, we show how to generate a corpus of documents from the HDP, generating one
document at a time, and incrementally constructing our inﬁnite objects. Initially we have βu = 1,
φ = (), and πju = 1 for all j. We start with the
ﬁrst position of the ﬁrst document and draw a local
topic y11 ∼ π1 , which will return u with probability 1. Because y11 = u we must make a draw from
the base measure, β, which, because this is the ﬁrst
document, will also return u with probability 1. We
new
must now break βu into β1 and βu , and break π1u
new in the same manner presented for
into π11 and π1u
the DP. Since π11 now corresponds to global topic
1, we sample the word x11 ∼ Multinomial(φ1 ). To
sample each subsequent word i, we ﬁrst sample the
local topic y1i ∼ π1 . If y1i = u, and π1y1i corresponds to βk in the global stick, then we sample the
word x1i ∼ Multinomial(φk ). Once the ﬁrst document has been sampled, subsequent documents are
sampled in a similar manner; initially πju = 1 for
document j, while β continues to grow as more documents are sampled.

4 Inﬁnite Trees
We now use the techniques from Section 3 to create
inﬁnite versions of each tree model from Section 2.
4.1

Independent Children

The changes required to make the Bayesian independent children model inﬁnite don’t affect its basic structure, as can be witnessed by comparing the
graphical depiction of the inﬁnite model in Figure 5
with that of the ﬁnite model in Figure 1. The instance variables zt and xt are parameterized as before. The primary change is that the number of
copies of the state plate is inﬁnite, as are the number
of variables πk and φk .
Note also that each distribution over possible
child states πk must also be inﬁnite, since the number of possible child states is potentially inﬁnite. We
achieve this by representing each of the πk variables
as a broken stick, and adopt the same approach of

γ
α0

πk

H

β|γ ∼ GEM(γ)
πk |α0 , β ∼ DP(α0 , β)
φk |H ∼ H

β

φk
∞

z1
z2
x1

z3

x2

x3

Figure 5: A graphical representation of the inﬁnite
independent child model.
sampling each πk from a DP with base measure β.
For the dependency tree application, φk is a vector
representing the parameters of a multinomial over
words, and H is a Dirichlet distribution.
The inﬁnite hidden Markov model (iHMM) or
HDP-HMM (Beal et al., 2002; Teh et al., 2006) is
a model of sequence data with transitions modeled
by an HDP.6 The iHMM can be viewed as a special
case of this model, where each state (except the stop
state) produces exactly one child.
4.2

Simultaneous Children

The key problem in the deﬁnition of the simultaneous children model is that of deﬁning a distribution over the lists of children produced by each state,
since each child in the list has as its domain the positive integers, representing the inﬁnite set of possible
states. Our solution is to construct a distribution Lk
over lists of states from the distribution over individual states πk . The obvious approach is to sample the
states at each position i.i.d.:
P(zt′ |π) =

P((zt′ )t′ ∈c(t) |π) =
t′ ∈c(t)

πzt ′
t′ ∈c(t)

However, we want our model to be able to represent the fact that some child lists, ct , are more
or less probable than the product of the individual
child probabilities would indicate. To address this,
we can sample a state-conditional distribution over
child lists λk from a DP with Lk as a base measure.
6
The original iHMM paper (Beal et al., 2002) predates, and
was the motivation for, the work presented in Teh et al. (2006),
and is the origin of the term hierarchical Dirichlet process.
However, they used the term to mean something slightly different than the HDP presented in Teh et al. (2006), and presented a
sampling scheme for inference that was a heuristic approximation of a Gibbs sampler.

Thus, we augment the basic model given in the previous section with the variables ζ, Lk , and λk :
Lk |πk ∼ Deterministic, as described above
λk |ζ, Lk ∼ DP(ζ, Lk )
ct |λk ∼ λk
An important consequence of deﬁning Lk locally
(instead of globally, using β instead of the πk s) is
that the model captures not only what sequences of
children a state prefers, but also the individual children that state prefers; if a state gives high probability to some particular sequence of children, then
it is likely to also give high probability to other sequences containing those same states, or a subset
thereof.
4.3

Markov Children

In the Markov children model, more copies of the
variable π are needed, because each child state must
be conditioned both on the parent state and on the
state of the preceding child. We use a new set of
variables πki , where π is determined by the parent state k and the state of the preceding sibling i.
Each of the πki is distributed as πk was in the basic
model: πki ∼ DP(α0 , β).

5 Inference
Our goal in inference is to draw a sample from the
posterior over assignments of states to observations.
We present an inference procedure for the inﬁnite
tree that is based on Gibbs sampling in the direct
assignment representation, so named because we directly assign global state indices to observations.7
Before we present the procedure, we deﬁne a few
count variables. Recall from Figure 4 that each state
k has a local stick πk , each element of which corresponds to an element of β. In our sampling procedure, we only keep elements of πk and β which
correspond to states observed in the data. We deﬁne
the variable mjk to be the number of elements of the
ﬁnite observed portion of πk which correspond to βj
and njk to be the number of observations with state
k whose parent’s state is j.
We also need a few model-speciﬁc counts. For the
simultaneous children model we need njz , which is
7

We adapt one of the sampling schemes mentioned by Teh
et al. (2006) for use in the iHMM. This paper suggests two
sampling schemes for inference, but does not explicitly present
them. Upon discussion with one of the authors (Y. W. Teh,
2006, p.c.), it became clear that inference using the augmented
representation is much more complicated than initially thought.

the number of times the state sequence z occurred
as the children of state j. For the Markov children model we need the count variable njik which
ˆ
is the number of observations for a node with state
k whose parent’s state is j and whose previous sibling’s state is i. In all cases we represent marginal
counts using dot-notation, e.g., n·k is the total number of nodes with state k, regardless of parent.
Our procedure alternates between three distinct
sampling stages: (1) sampling the state assignments
z, (2) sampling the counts mjk , and (3) sampling
the global stick β. The only modiﬁcation of the procedure that is required for the different tree models is the method for computing the probability
of the child state sequence given the parent state
P((zt′ )t′ ∈c(t) |zt ), deﬁned separately for each model.
Sampling z. In this stage we sample a state for
each tree node. The probability of node t being assigned state k is given by:
P(zt = k|z −t , β) ∝ P(zt = k, (zt′ )t′ ∈s(t) |zp(t) )
−x
· P((zt′ )t′ ∈c(t) |zt = k) · fk t (xt )
−x
where s(t) denotes the set of siblings of t, fk t (xt )
denotes the posterior probability of observation xt

given all other observations assigned to state k, and
z −t denotes all state assignments except zt . In other
words, the probability is proportional to the product
of three terms: the probability of the states of t and
its siblings given its parent zp(t) , the probability of
the states of the children c(t) given zt , and the posterior probability of observation xt given zt . Note
that if we sample zt to be a previously unseen state,
we will need to extend β as discussed in Section 3.2.
Now we give the equations for P((zt′ )t′ ∈c(t) |zt )
for each of the models. In the independent child
model the probability of generating each child is:
Pind (zci (t)

njk + α0 βk
= k|zt = j) =
nj· + α0

DT NN
The man

IN DT
NN VBD PRP$
NN
TO VB NN EOS
in the corner taught his dachshund to play golf EOS

Figure 6: An example of a syntactic dependency tree
where the dependencies are between tags (hidden
states), and each tag generates a word (observation).
Markov child model:
Pm (zci (t) = k|zci−1 (t) = i, zt = j) =
Pm ((zt′ )t′ ∈c(t) |zt ) =

|c(t)|
i=1

njik + α0 βk
ˆ
nji· + α0
ˆ

Pm (zci (t) |zci−1 (t) , zt )

Finally, we give the posterior probability of an observation, given that F (φk ) is Multinomial(φk ), and
that H is Dirichlet(ρ, . . . , ρ). Let N be the vocabulary size and nk be the number of observations x
˙
with state k. Then:
n xt k + ρ
˙
−x
fk t (xt ) =
n·k + N ρ
˙
Sampling m. We use the following procedure,
which slightly modiﬁes one from (Y. W. Teh, 2006,
p.c.), to sample each mjk :
SAMPLE M(j, k)

1 if njk = 0
2
then mjk = 0
3
else mjk = 1
4
for i ← 2 to njk
α0
5
do if rand() < α0 +i−1
6
then mjk = mjk + 1
7 return mjk
Sampling β. Lastly, we sample β using the Dirichlet distribution:
(β1 , . . . , βK , βu ) ∼ Dirichlet(m·1 , . . . , m·K , α0 )

6 Experiments

We demonstrate inﬁnite tree models on two distinct syntax learning tasks: unsupervised POS learnFor the simultaneous child model, the probability of ing conditioned on untagged dependency trees and
generating a sequence of children, z, takes into ac- learning a split of an existing tagset, which improves
count how many times that sequence has been gen- the accuracy of an automatic syntactic parser.
For both tasks, we use a simple modiﬁcation of
erated, along with the likelihood of regenerating it:
the basic model structure, to allow the trees to gennjz + ζPind (z|zt = j)
erate dependents on the left and the right with difPsim ((zt′ )t′ ∈c(t) = z|zt = j) =
nj· + ζ
ferent distributions – as is useful in modeling natuRecall that ζ denotes the concentration parameter ral language. The modiﬁcation of the independent
for the sequence generating DP. Lastly, we have the child tree is trivial: we have two copies of each of
Pind ((zt′ )t′ ∈c(t) |zt = j) =

t′ ∈c(t)

Pind (zt′ |zt = j)

the variables πk , one each for the left and the right.
Generation of dependents on the right is completely
independent of that for the left. The modiﬁcations of
the other models are similar, but now there are separate sets of πk variables for the Markov child model,
and separate Lk and λk variables for the simultaneous child model, for each of the left and right.
For both experiments, we used dependency trees
extracted from the Penn Treebank (Marcus et al.,
1993) using the head rules and dependency extractor from Yamada and Matsumoto (2003). As is standard, we used WSJ sections 2–21 for training, section 22 for development, and section 23 for testing.
6.1

Unsupervised POS Learning

In the ﬁrst experiment, we do unsupervised part-ofspeech learning conditioned on dependency trees.
To be clear, the input to our algorithm is the dependency structure skeleton of the corpus, but not
the POS tags, and the output is a labeling of each
of the words in the tree for word class. Since the
model knows nothing about the POS annotation, the
new classes have arbitrary integer names, and are
not guaranteed to correlate with the POS tag definitions. We found that the choice of α0 and β
(the concentration parameters) did not affect the output much, while the value of ρ (the parameter for
the base Dirichlet distribution) made a much larger
difference. For all reported experiments, we set
α0 = β = 10 and varied ρ.
We use several metrics to evaluate the word
classes. First, we use the standard approach of
greedily assigning each of the learned classes to the
POS tag with which it has the greatest overlap, and
then computing tagging accuracy (Smith and Eisner,
2005; Haghighi and Klein, 2006).8 Additionally, we
compute the mutual information of the learned clusters with the gold tags, and we compute the cluster
F-score (Ghosh, 2003). See Table 1 for results of
the different models, parameter settings, and metrics. Given the variance in the number of classes
learned it is a little difﬁcult to interpret these results,
but it is clear that the Markov child model is the
best; it achieves superior performance to the independent child model on all metrics, while learning
fewer word classes. The poor performance of the
simultaneous model warrants further investigation,
but we observed that the distributions learned by that
8

The advantage of this metric is that it’s comprehensible.
The disadvantage is that it’s easy to inﬂate by adding classes.

Model
Indep.
Simul.
Markov

ρ
0.01
0.001
0.0001
0.01
0.001
0.0001
0.01
0.001

# Classes
943
1744
2437
183
430
549
613
894

Acc.
67.89
73.61
74.64
21.36
15.77
16.68
68.53
75.34

MI
2.00
2.23
2.27
0.31
0.09
0.12
2.12
2.31

F1
48.29
40.80
39.47
21.57
13.80
14.29
49.82
48.73

Table 1: Results of part unsupervised POS tagging
on the different models, using a greedy accuracy
measure.
model are far more spiked, potentially due to double
counting of tags, since the sequence probabilities are
already based on the local probabilities.
For comparison, Haghighi and Klein (2006) report an unsupervised baseline of 41.3%, and a best
result of 80.5% from using hand-labeled prototypes
and distributional similarity. However, they train on
less data, and learn fewer word classes.
6.2

Unsupervised POS Splitting

In the second experiment we use the inﬁnite tree
models to learn a reﬁnement of the PTB tags. We
initialize the set of hidden states to the set of PTB
tags, and then, during inference, constrain the sampling distribution over hidden state zt at each node t
to include only states that are a reﬁnement of the annotated PTB tag at that position. The output of this
training procedure is a new annotation of the words
in the PTB with the learned tags. We then compare
the performance of a generative dependency parser
trained on the new reﬁned tags with one trained on
the base PTB tag set. We use the generative dependency parser distributed with the Stanford factored parser (Klein and Manning, 2003b) for the
comparison, since it performs simultaneous tagging
and parsing during testing. In this experiment, unlabeled, directed, dependency parsing accuracy for
the best model increased from 85.11% to 87.35%, a
15% error reduction. See Table 2 for the full results
over all models and parameter settings.

7 Related Work
The HDP-PCFG (Liang et al., 2007), developed at
the same time as this work, aims to learn state splits
for a binary-branching PCFG. It is similar to our
simultaneous child model, but with several important distinctions. As discussed in Section 4.2, in our
model each state has a DP over sequences, with a
base distribution that is deﬁned over the local child

Model
Baseline
Independent
Markov

ρ
–
0.01
0.001
0.01
0.001

Accuracy
85.11
86.18
85.88
87.15
87.35

Table 2: Results of untyped, directed dependency
parsing, where the POS tags in the training data have
been split according to the various models. At test
time, the POS tagging and parsing are done simultaneously by the parser.
state probabilities. In contrast, Liang et al. (2007)
deﬁne a global DP over sequences, with the base
measure deﬁned over the global state probabilities,
β; locally, each state has an HDP, with this global
DP as the base measure. We believe our choice to
be more linguistically sensible: in our model, for a
particular state, dependent sequences which are similar to one another increase one another’s likelihood.
Additionally, their modeling decision made it difﬁcult to deﬁne a Gibbs sampler, and instead they use
variational inference. Earlier, Johnson et al. (2007)
presented adaptor grammars, which is a very similar model to the HDP-PCFG. However they did not
conﬁne themselves to a binary branching structure
and presented a more general framework for deﬁning the process for splitting the states.

8 Discussion and Future Work
We have presented a set of novel inﬁnite tree models
and associated inference algorithms, which are suitable for representing syntactic dependency structure.
Because the models represent a potentially inﬁnite
number of hidden states, they permit unsupervised
learning algorithms which naturally select a number of word classes, or tags, based on qualities of
the data. Although they require substantial technical background to develop, the learning algorithms
based on the models are actually simple in form, requiring only the maintenance of counts, and the construction of sampling distributions based on these
counts. Our experimental results are preliminary but
promising: they demonstrate that the model is capable of capturing important syntactic structure.
Much remains to be done in applying inﬁnite
models to language structure, and an interesting extension would be to develop inference algorithms
that permit completely unsupervised learning of dependency structure.

Acknowledgments
Many thanks to Yeh Whye Teh for several enlightening conversations, and to the following members (and honorary member) of the Stanford NLP
group for comments on an earlier draft: Thad
Hughes, David Hall, Surabhi Gupta, Ani Nenkova,
Sebastian Riedel. This work was supported by a
Scottish Enterprise Edinburgh-Stanford Link grant
(R37588), as part of the EASIE project, and by
the Advanced Research and Development Activity
(ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Phase II Program.

References
C. E. Antoniak. 1974. Mixtures of Dirichlet processes with applications to Bayesian nonparametrics. Annals of Statistics,
2:1152–1174.
M.J. Beal, Z. Ghahramani, and C.E. Rasmussen. 2002. The
inﬁnite hidden Markov model. In Advances in Neural Information Processing Systems, pages 577–584.
E. Charniak. 1996. Tree-bank grammars. In AAAI 1996, pages
1031–1036.
E. Charniak. 2000. A maximum-entropy-inspired parser. In
HLT-NAACL 2000, pages 132–139.
M. Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.
T. S. Ferguson. 1973. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1:209–230.
J. Ghosh. 2003. Scalable clustering methods for data mining. In
N. Ye, editor, Handbook of Data Mining, chapter 10, pages
247–277. Lawrence Erlbaum Assoc.
A. Haghighi and D. Klein. 2006. Prototype-driven learning for
sequence models. In HLT-NAACL 2006.
M. Johnson, T. Grifﬁths, and S. Goldwater. 2007. Adaptor
grammars: A framework for specifying compositional nonparametric Bayesian models. In NIPS 2007.
D. Klein and C. D. Manning. 2003a. Accurate unlexicalized
parsing. In ACL 2003.
D. Klein and C. D. Manning. 2003b. Factored A* search for
models over sequences and trees. In IJCAI 2003.
P. Liang, S. Petrov, D. Klein, and M. Jordan. 2007. Nonparametric PCFGs using Dirichlet processes. In EMNLP 2007.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The Penn
Treebank. Computational Linguistics, 19(2):313–330.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006. Learning
accurate, compact, and interpretable tree annotation. In ACL
44/COLING 21, pages 433–440.
J. Pitman. 2002. Poisson-Dirichlet and GEM invariant distributions for split-and-merge transformations of an interval partition. Combinatorics, Probability and Computing, 11:501–
514.
N. A. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In ACL 2005.
Y. W. Teh, M.I. Jordan, M. J. Beal, and D.M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101:1566–1581.
H. Yamada and Y. Matsumoto. 2003. Statistical dependency
analysis with support vector machines. In Proceedings of
IWPT, pages 195–206.

