Appeared in Proceedings of the Joint Meeting of the Human Language Technology
Conference and the North American Chapter of the Association for Computational
Linguistics (HLT-NAACL 2003), pp. 64-71, 2003.

Simpler and More General Minimization
for Weighted Finite-State Automata
Jason Eisner
Department of Computer Science
Johns Hopkins University
Baltimore, MD, USA 21218-2691
jason@cs.jhu.edu
Abstract
Previous work on minimizing weighted ﬁnite-state automata
(including transducers) is limited to particular types of weights.
We present efﬁcient new minimization algorithms that apply
much more generally, while being simpler and about as fast.
We also point out theoretical limits on minimization algorithms. We characterize the kind of “well-behaved” weight
semirings where our methods work. Outside these semirings,
minimization is not well-deﬁned (in the sense of producing a
unique minimal automaton), and even ﬁnding the minimum
number of states is in general NP-complete and inapproximable.

1

Introduction

It is well known how to efﬁciently minimize a deterministic ﬁnite-state automaton (DFA), in the sense of constructing another DFA that recognizes the same language
as the original but with as few states as possible (Aho et
al., 1974). This DFA also has as few arcs as possible.
Minimization is useful for saving memory, as when
building very large automata or deploying NLP systems
on small hand-held devices. When automata are built up
through complex regular expressions, the savings from
minimization can be considerable, especially when applied at intermediate stages of the construction, since (for
example) smaller automata can be intersected faster.
Recently the computational linguistics community has
turned its attention to weighted automata that compute
interesting functions of their input strings. A traditional
automaton only returns an boolean from the set K =
{true, f alse}, which indicates whether it has accepted
the input. But a probabilistic automaton returns a probability in K = [0, 1], or equivalently, a negated logprobability in K = [0, ∞]. A transducer returns an output
string from K = ∆∗ (for some alphabet ∆).
Celebrated algorithms by Mohri (1997; 2000) have
recently made it possible to minimize deterministic automata whose weights (outputs) are log-probabilities or
strings. These cases are of central interest in language
and speech processing.
However, automata with other kinds of weights can
also be deﬁned. The general formulation of weighted
automata (Berstel and Reutenauer, 1988) permits any
weight set K, if appropriate operations ⊕ and ⊗ are provided for combining weights from the different arcs of
the automaton. The triple (K, ⊕, ⊗) is called a weight

semiring and will be explained below. K-valued functions that can be computed by ﬁnite-state automata are
called rational functions.
How does minimization generalize to arbitrary weight
semirings? The question is of practical as well as theoretical interest. Some NLP automata use the real semiring
(R, +, ×), or its log equivalent, to compute unnormalized
probabilities or other scores outside the range [0, 1] (Lafferty et al., 2001; Cortes et al., 2002). Expectation semirings (Eisner, 2002) are used to handle bookkeeping when
training the parameters of a probabilistic transducer. A
byproduct of this paper is a minimization algorithm that
works fully with those semirings, a new result permitting
more efﬁcient automaton processing in those situations.
Surprisingly, we will see that minimization is not
even well-deﬁned for all weight semirings! We will
then (nearly) characterize the semirings where it is welldeﬁned, and give a recipe for constructing minimization
algorithms similar to Mohri’s in such semirings.
Finally, we follow this recipe to obtain a speciﬁc, simple and practical algorithm that works for all division
semirings. All the cases above either fall within this
framework or can be forced into it by adding multiplicative inverses to the semiring. The new algorithm provides
arguably simpler minimization for the cases that Mohri
has already treated, and also handles additional cases.

2

Weights and Minimization

We introduce weighted automata by example. The transducer below describes a partial function from strings to
strings. It maps aab → xyz and bab → wwyz. Why?
Since the transducer is deterministic, each input (such as
aab) is accepted along at most one path; the corresponding output (such as xyz) is found by concatenating the
output strings found along a:y path. ε denotes the empty
the
string.
a:x
0

1

b:zz

a:wwy

b:ε
3

2

b:z
b:ε

b:wwzzz

5

4

δ and σ standardly denote the automaton’s transition and
output functions: δ(3, a) = 2 is the state reached by the
a arc from state 3, and σ(3, a) = wwy is that arc’s output.

In an automaton whose outputs (weights) were numbers rather than strings like wwy, concatenating them
would not be sensible; instead we would want to add or
multiply the weights along the path. In general ⊗ denotes
the chosen operation for combining weights along a path.
The ⊗ operation need not be commutative—indeed
concatenation is not—but it must be associative. K must
contain (necessarily unique) weights, denoted 1 and 0,
such that 1 ⊗ k = k ⊗ 1 = k and 0 ⊗ k = k ⊗ 0 = 0 for
all k ∈ K. An unaccepted input (e.g., aba) is assigned
the output 0. When ⊗ is string concatenation, 1 = ε, and
0 is a special object ∅ deﬁned to satisfy the axioms.
If an input such as aa were accepted along multiple
paths, we would have to use another operation ⊕ to combine those paths’ weights into a single output for aa.
But that cannot happen with the deterministic automata
treated by this paper. So we omit discussion of the properties that ⊕ should have, and do not trouble to spell out
its deﬁnition for the semirings (K, ⊕, ⊗) discussed in this
paper.1 We are only concerned with the monoid (K, ⊗).
The following automaton is equivalent to the previous
one since it computes the same function:
a:yz
a:x
0

1

b:zzz
a:yz

b:ww
3

2

b:ε
b:ε

b:zzz

5

4

However, it distributes weights differently along the arcs,
and states 1 and 3 can now obviously be merged (as can 2
and 4, yielding the minimal equivalent automaton). Formally we know that states 1 and 3 are equivalent because
F1 = F3 , where Fq denotes the sufﬁx function of state
q—the function deﬁned by the automaton if the start state
is taken to be q rather than 0. (Thus, F3 (ab) = yz.)
Equivalent states can safely be merged, by deleting one
and rerouting its incoming arcs to the other.
We will follow Mohri’s minimization strategy:
1. Turn the ﬁrst automaton above into the second. This
operation is called pushing (or quasi-determinization).
Here, for instance, it “pushed ww back” through state 3.
2. Merge equivalent states of the second automaton, by
applying ordinary unweighted DFA minimization (Aho et
al., 1974, section 4.13) as if each weighted arc label such
as a:yz were simply a letter in a large alphabet.
3. Trim the result, removing useless states and arcs that
are not on any accepting path (deﬁned as a path whose
weight is non-0 because it has no missing arcs and its last
state is ﬁnal).
1
Though appropriate deﬁnitions do exist for our examples.
For example, take the ⊕ of two strings to be the shorter of the
two, breaking ties by a lexicographic ordering.

Mohri (2000) proves that this technique ﬁnds the minimal
automaton, which he shows to be unique up to placement
of weights along paths.2
We will only have to modify step 1, generalizing pushing to other semirings. Pushing makes heavy use of left
quotients: we adopt the notation k\m for an element of
K such that k ⊗ (k\m) = m. This differs from the notation k −1 ⊗ m (in which k −1 denotes an actual element of
K) because k\m need not exist nor be unique. For example, ww\wwzzz = zzz (a fact used above) but wwy\wwzzz
does not exist since wwzzz does not begin with wwy.
If F is a function, α is a string, and k is a weight, we
use some natural notation for functions related to F :
def
k ⊗ F : (k ⊗ F )(γ) = k ⊗ (F (γ))
k\F : a function (if one exists) with k ⊗ (k\F ) = F
α−1 F :

def

(α−1 F )(γ) = F (αγ)

(standard notation)

In effect, k\F and α−1 F drop output and input preﬁxes.

3

Pushing and Its Limitations

The intuition behind pushing is to canonicalize states’
sufﬁx functions. This increases the chance that two states
will have the same sufﬁx function. In the example of the
previous section, we were able to replace F3 with ww\F3
(pushing the ww backwards onto state 3’s incoming arc),
making it equal to F1 so {1, 3} could merge.
Since canonicalization was also performed at states 2
and 4, F1 and F3 ended up with identical representations: arc weights were distributed identically along corresponding paths from 1 and 3. Hence unweighted minimization could discover that F1 = F3 and merge {1, 3}.
Mohri’s pushing strategy—we will see others—is always to extract some sort of “maximum left factor” from
each sufﬁx function Fq and push it backwards. That is,
he expresses Fq = k ⊗ G for as “large” a k ∈ K as
possible—a maximal common preﬁx—then pushes factor k back out of the sufﬁx function so that it is counted
earlier on paths through q (i.e., before reaching q). q’s
sufﬁx function now has canonical form G (i.e., k\Fq ).
How does Mohri’s strategy reduce to practice? For
transducers, where (K, ⊗) = (∆∗ , concat), the maximum left factor of Fq is the longest common preﬁx of
the strings in range(Fq ).3 Thus we had range(F3 ) =
{wwyz, wwzzz} above with longest common preﬁx ww.
For the tropical semiring (R≥0 ∪ {∞}, min, +), where
k\m = m − k is deﬁned only if k ≤ m, the maximum
left factor k is the minimum of range(Fq ).
But “maximum left factor” is not an obvious notion
for all semirings. If we extended the tropical semir2

That is, any other solution is isomorphic to the one found
here if output weights are ignored.
3
In general we treat Fq as a partial function, so that
range(Fq ) excludes 0 (the weight of unaccepted strings). Left
factors are unaffected, as anything can divide 0.

ing with negative numbers, or substituted the semiring
(R≥0 , +, ×), keeping the usual deﬁnition of “maximum,”
then any function would have arbitrarily large left factors.
A more √
fundamentally problematic example is the
√
semiring Z[ −5]. It is deﬁned as ({m + n −5 : m, n ∈
Z}, +, ×) where Z denotes the integers. It is a standard example of a commutative algebra in which factorization is not unique. For example, 6 = 2 ⊗ 3 =
√
√
(1 + −5) ⊗ (1 − −5) and these 4 factors cannot be
factored further. This makes it impossible to canonicalize
F2 below:
a:3
1

b:(1+sqrt(-5))

a:1

0

b:1
c:1

a:6
2

4

b:(2+2*sqrt(-5))
a:(1-sqrt(-5))

3

b:2

What is the best left factor to extract from F2 ? We could
√
left-divide F2 by either 2 or 1 + −5. The former action
allows us to merge {1, 2} and the latter to merge {2, 3};
but we cannot have it both ways. So this automaton has
no unique minimization! The minimum of 4 states is
achieved by two distinct answers (contrast footnote 2).
It follows that known minimization techniques will not
work in general semirings, as they assume state mergeability to be transitive.4 In general the result of minimization is not even well-deﬁned (i.e., unique).
Of course, given a deterministic automaton M , one
¯
may still seek an equivalent M with as few states as possible. But we will now see that even ﬁnding the minimum
number of states is NP-complete, and inapproximable.
The NP-hardness proof [which may be skipped on a
ﬁrst reading] is by reduction from Minimum Clique Partition. Given a graph with vertex set V = {1, 2, . . . n}
and edge set E, we wish to partition V into as few cliques
as possible. (S ⊆ V is a clique of the graph iff ij ∈ E
for all pairs i, j ∈ S.) Determining the minimum number of cliques is NP-complete and inapproximable: that
is, unless P=NP, we cannot even ﬁnd it within a factor of
2 or 3 or any other constant factor in polynomial time.5
Given such a graph, we reduce the clique problem to
our problem. Consider the “bitwise boolean” semiring
({0, 1}n , OR, AND). Each weight k is a string of n bits,
4
A further wrinkle lies in deciding what and how to push; in
general semirings, it can be necessary to shift weights forward
as well as backward along paths. Modify the example above by
pushing a factor of 2 backwards through state 2. Making F2 =
F3 in this modiﬁed example now requires pushing 2 forward
√
and then 1 + −5 backward through state 2.
5
This problem is just the dual of Graph Coloring. For detailed approximability results see (Crescenzi and Kann, 1998).

denoted k1 , . . . kn . For each i ∈ V , deﬁne f i , k i , mi ∈
i
i
K as follows: fj = 0 iff ij ∈ E; kj = 1 iff i = j; mi =
j
0 iff either ij ∈ E or i = j. Now consider the following
automaton M over the alphabet Σ = {a, b, c1 , . . . cn }.
The states are {0, 1, . . . n, n + 1}; 0 is the initial state and
n + 1 is the only ﬁnal state. For each i ∈ V , there is an
n

i

i

ci :1
a:k
b:m
arc 0−−→i and arcs i−−→(n + 1) and i−−→(n + 1).
A minimum-state automaton equivalent to M must
have a topology obtained by merging some states of V .
Other topologies that could accept the same language
(c1 |c2 | · · · |cn )(a|b) are clearly not minimal (they can be
improved by merging ﬁnal states or by trimming).
We claim that for S ⊆ {1, 2, . . . n}, it is possible to
merge all states in S into a single state (in the automaton)
if and only if S is a clique (in the graph):

• If S is a clique, then deﬁne k, m ∈ K by ki = 1 iff
i ∈ S, and mi = 1 iff i ∈ S. Observe that for every
i ∈ S, we have k i = f i ⊗ k, mi = f i ⊗ m. So by
pushing back a factor of f i at each i ∈ S, one can make
all i ∈ S share a sufﬁx function and then merge them.
• If S is not a clique, then choose i, j ∈ S so that
ij ∈ E. Considering only bit i, there exists no bit
i
pair (ki , mi ) ∈ {0, 1}2 of which (ki , mi ) = (1, 0)
i
j
j
and (ki , mi ) = (0, 1) are both left-multiples. So there
can exist no weight pair (k, m) of which (k i , mi ) and
(k j , mj ) are both left-multiples. It is therefore not possible to equalize the sufﬁx functions Fi and Fj by leftdividing each of them.6 i and j cannot be merged.
Thus, the partitions of V into cliques are identical to
the partitions of V into sets of mergeable states, which are
in 1-1 correspondence with the topologies of automata
equivalent to M and derived from it by merging. There is
an N -clique partition of V iff there is an (N +2)-state automaton. It follows that ﬁnding the minimum number of
states is as hard, and as hard to approximate within a constant factor, as ﬁnding the minimum number of cliques.

4

When Is Minimization Unique?

The previous section demonstrated the existence of
pathological weight semirings. We now partially characterize the “well-behaved” semirings (K, ⊕, ⊗) in which
all automata do have unique minimizations. Except when
otherwise stated, lowercase variables are weights ∈ K
and uppercase ones are K-valued rational functions.
[This section may be skipped, except the last paragraph.]
A crucial necessary condition is that (K, ⊗) allow
what we will call greedy factorization, meaning that
given f ⊗F = g ⊗G = 0, it is always possible to express
6

This argument only shows that pushing backward cannot
give them the same sufﬁx function. But pushing forward cannot
help either, despite footnote 4, since 1n on the arc to i has no
right factors other than itself (the identity) to push forward.

F = f ⊗ H and G = g ⊗ H. This condition holds for
many practically useful semirings, commutative or otherwise. It says, roughly, that the order in which left factors
are removed from a sufﬁx function does not matter. We
can reach the same canonical H regardless of whether we
left-divide ﬁrst by f or g.
Given a counterexample to this condition, one can construct an automaton with no unique minimization. Sim√
ply follow the plan of the Z[ −5] example, putting
F1 = F , F2 = f ⊗ F = g ⊗ G, F3 = G.7 For example, in semiring (K, ⊗) = ({xn : n = 1}, concat), put
F2 = x2 ⊗ {(a, x3 ), (b, x4 )} = x3 ⊗ {(a, x2 ), (b, x3 )}.
Some useful semirings do fail the condition. One
is the “bitwise boolean” semiring that checks a string’s
membership in two languages at once: (K, ⊕, ⊗) =
({00, 01, 10, 11}, OR, AND).
(Let F2 = 01 ⊗
{(a, 11), (b, 00)} = 01 ⊗ {(a, 01), (b, 10)}.) R2 under
pointwise × (which computes a string’s probability under
two models) fails similarly. So does (sets, ∩, ∪) (which
collects features found along the accepting path).
We call H a residue of F iff F = f ⊗ H for some
f . Write F
G iff F , G have a common residue. In
these terms, (K, ⊗) allows greedy factorization iff F
G when F , G are residues of the same nonzero function.
More perspicuously, one can show that this holds iff is
an equivalence relation on nonzero, K-valued functions.
So in semirings where minimization is uniquely deﬁned, is necessarily an equivalence relation. Given an
automaton M for function F , we may regard
as an
equivalence relation on the states of a trimmed version
of M :8 q
r iff Fq
Fr . Let [r] = {r1 , . . . , rm }
be the (ﬁnite) equivalence class of r: we can inductively
ﬁnd at least one function F[r] that is a common residue of
Fr1 , . . . , Frm . The idea behind minimization is to con¯
struct an automaton M whose states correspond to these
equivalence classes, and where each [r] has sufﬁx func¯
tion F[r] . The Appendix shows that M is then minimal.
a:k
¯
Under this idea, if M has an arc q −→r, M needs an arc
a:k
[q]−→[r], where k is such that a−1 F[q] = k ⊗ F[r] .
The main difﬁculty in completing the construction of
¯
M is to ensure each weight k exists. That is, F[r] must be
carefully chosen to be a residue not only of Fr1 , . . . , Frm
(which ultimately does not matter, as long as F[0] is a
residue of F0 , where 0 is the start state) but also of
a−1 F[q] . If M is cyclic, this imposes cyclic dependencies on the choices of the various F[q] and F[r] functions.
We have found no simple necessary and sufﬁcient condition on (K, ⊗) that guarantees a globally consistent set
of choices to exist. However, we have given a useful nec7
Then factoring F2 allows state 2 to merge with either 1 or
3; but all three states cannot merge, since any sufﬁx function
that could be shared by 1 and 3 could serve as H.
8
Trimming ensures that sufﬁx functions are nonzero.

essary condition (greedy factorization), and we now give
a useful sufﬁcient condition. Say that H is a minimum
residue of G = 0 if it is a residue of every residue of G.
(If G has several minimum residues, they are all residues
of one another.) If (K, ⊗) is such that every G has a minimum residue—a strictly stronger condition than greedy
factorization—then it can be shown that G has the same
minimum residues as any H
G. In such a (K, ⊗),
¯
M can be constructed by choosing the sufﬁx functions
F[r] independently. Just let F[r] = F{r1 ,...,rm } be a minia:k
mum residue of Fr1 . Now consider again M ’s arc q −→r:
since a−1 F[q]
a−1 Fq
Fr
Fr1 , we see F[r] is a
(minimum) residue of a−1 F[q] , so that a weight k can be
a:k
chosen for [q]−→[r].
¯
A ﬁnal step ensures that M deﬁnes the function F . To
describe it, we must augment the formalism to allow an
initial weight ι(0) ∈ K, and a ﬁnal weight φ(r) ∈ K
for each ﬁnal state r. The weight of an accepting path
from the start state 0 to a ﬁnal state r is now deﬁned to
¯
be ι(0) ⊗ (weights of arcs along the path) ⊗ φ(r). In M ,
we set ι([0]) to some k such that F0 = k ⊗ F[0] , and set
φ([r]) = F[r] (ε). The mathematical construction is done.

5

A Simple Minimization Recipe

We now give an effective algorithm for minimization in
the semiring (K, ⊗). The algorithmic recipe has one ingredient: along with (K, ⊗), the user must give us a leftfactor functional λ that can choose a left factor λ(F ) of
any function F . Formally, if Σ is the input alphabet, then
we require λ : (Σ∗ → K) → K to have the following
properties for any rational F : Σ∗ → K and any k ∈ K:
• Shifting: λ(k ⊗ F ) = k ⊗ λ(F ).
• Quotient: λ(F )\λ(a−1 F ) exists in K for any a ∈ Σ.
• Final-quotient: λ(F )\F (ε) exists in K.9
The algorithm generalizes Mohri’s strategy as outlined
in section 2. We just use λ to pick the left factors during
pushing. The λ’s used by Mohri for two semirings were
mentioned in section 3. We will deﬁne another λ in section 6. Naturally, it can be shown that no λ can exist in a
√
semiring that lacks greedy factorization, such as Z[ −5].
The 3 properties above are needed for the strategy to
work. The strategy also requires (K, ⊗) to be left cancellative, i.e., k ⊗ m = k ⊗ m implies m = m (if
k = 0). In other words, left quotients by k are unique
when they exist (except for 0\0). This relieves us from
having to make arbitrary choices of weight during pushing. Incompatible choices might prevent arc labels from
matching as desired during the merging step of section 2.
9
To show the ﬁnal-quotient property given the other two, it
sufﬁces to show that λ(G) ∈ K has a right inverse in K, where
G is the function mapping ε to 1 and everything else to 0.

Given an input DFA. At each state q, simultaneously,
we will push back λ(Fq ). This pushing construction
is trivial once the λ(Fq ) values are computed. An
a:k
arc q −→r should have its weight changed from k to
λ(Fq )\λ(a−1 Fq ) = λ(Fq )\λ(k ⊗ Fr ), which is welldeﬁned (by the quotient property and left cancellativity)10
and can be computed as λ(Fq )\(k ⊗ λ(Fr )) (by the shifta:k
b:
ing property). Thus a subpath q −→r−→s, with weight
a:k
b:
k ⊗ , will become q −→r−→s, with weight k ⊗ =
(λ(Fq )\(k ⊗ λ(Fr ))) ⊗ (λ(Fr )\( ⊗ λ(Fs ))). In this
way the factor λ(Fr ) is removed from the start of all paths
from r, and is pushed backwards through r onto the end
of all paths to r. It is possible for this factor (or part of
it) to travel back through multiple arcs and around cycles,
since k is found by removing a λ(Fq ) factor from all of
k ⊗ λ(Fr ) and not merely from k.
As it replaces the arc weights, pushing also replaces
the initial weight ι(0) with ι(0) ⊗ λ(F0 ), and replaces
each ﬁnal weight φ(r) with λ(Fr )\φ(r) (which is welldeﬁned, by the ﬁnal-quotient property). Altogether, pushing leaves path weights unchanged (by easy induction).11
After pushing, we ﬁnish with merging and trimming as
in section 2. While merging via unweighted DFA minimization treats arc weights as part of the input symbols,
what should it do with any initial and ﬁnal weights? The
start state’s initial weight should be preserved. The merging algorithm can and should be initialized with a multiway partition of states by ﬁnal weight, instead of just a
2-way partition into ﬁnal vs. non-ﬁnal.12
The Appendix shows that this strategy indeed ﬁnds the
unique minimal automaton.
It is worth clarifying how this section’s effective algorithm implements the mathematical construction from
the end of section 4. At each state q, pushing replaces the
sufﬁx function Fq with λ(Fq )\Fq . The quotient properties of λ are designed to guarantee that this quotient is
deﬁned,13 and the shifting property is designed to ensure
10
Except in the case 0\0, which is not uniquely deﬁned. This
arises only if Fq = 0, i.e., q is a dead state that will be trimmed
later, so any value will do for 0\0: arcs from q are irrelevant.
11
One may prefer a formalism without initial or ﬁnal weights.
If the original automaton is free of ﬁnal weights (other than 1),
so is the pushed automaton—provided that λ(F ) = 1 whenever
F (ε) = 1, as is true for all λ’s in this paper. Initial weights can
be eliminated at the cost of duplicating state 0 (details omitted).
12
Alternatively, Mohri (2000, §4.5) explains how to temporarily eliminate ﬁnal weights before the merging step.
13
That is, λ(Fq )\Fq (γ) exists for each γ ∈ Σ∗ . One may
show by induction on |γ| that the left quotients λ(F )\F (γ) exist for all F . When |γ| = 0 this is the ﬁnal-quotient property.
For |γ| > 0 we can write γ as aγ , and then λ(F )\F (γ) =
λ(F )\F (aγ ) = λ(F )\(a−1 F )(γ ) = (λ(F )\λ(a−1 F )) ⊗
(λ(a−1 F )\(a−1 F )(γ )), where the ﬁrst factor exists by the
quotient property and the second factor exists by inductive hypothesis.

that it is a minimum residue of Fq .14 In short, if the conditions of this section are satisﬁed, so are the conditions
of section 4, and the construction is the same.
The converse is true as well, at least for right cancellative semirings. If such a semiring satisﬁes the conditions
of section 4 (every function has a minimum residue), then
the requirements of this section can be met to obtain an
effective algorithm: there exists a λ satisfying our three
properties,15 and the semiring is left cancellative.16

6

Minimization in Division Semirings

For the most important idea of this paper, we turn to a
common special case. Suppose the semiring (K, ⊕, ⊗)
deﬁnes k\m for all m, k = 0 ∈ K. Equivalently,17 suppose every k = 0 ∈ K has a unique two-sided inverse
k −1 ∈ K. Useful cases of such division semirings include the real semiring (R, +, ×), the tropical semiring
extended with negative numbers (R ∪ {∞}, min, +), and
expectation semirings (Eisner, 2002). Minimization has
not previously been available in these.
We propose a new left-factor functional that is fast to
compute and works in arbitrary division semirings. We
avoid the temptation to deﬁne λ(F ) as range(F ): this
deﬁnition has the right properties, but in some semirings
including (R≥0 , +, ×) the inﬁnite summation is quite expensive to compute and may even diverge. Instead (unlike Mohri) we will permit our λ(F ) to depend on more
than just range(F ).
Order the space of input strings Σ∗ by length, breaking
ties lexicographically. For example, ε < bb < aab <
aba < abb. Now deﬁne
14
Suppose X is any residue of Fq , i.e., we can write Fq =
x ⊗ X. Then we can rewrite the identity Fq = λ(Fq ) ⊗
(λ(Fq )\Fq ), using the shifting property, as x ⊗ X = x ⊗
λ(X)⊗(λ(Fq )\Fq ). As we have separately required the semiring to be left cancellative, this implies that X = λ(X) ⊗
(λ(Fq )\Fq ). So (λ(Fq )\Fq ) is a residue of any residue X of
Fq , as claimed.
15
Deﬁne λ(0) = 0. From each equivalence class of nonzero
functions under , pick a single minimum residue (axiom of
choice). Given F , let [F ] denote the minimum residue from its
class. Observe that F = f ⊗[F ] for some f ; right cancellativity
implies f is unique. So deﬁne λ(F ) = f . Shifting property:
λ(k ⊗ F ) = λ(k ⊗ f ⊗ [F ]) = k ⊗ f = k ⊗ λ(f ⊗ [F ]) =
k ⊗ λ(F ). Quotient property: λ(a−1 F ) ⊗ [a−1 F ] = a−1 F =
a−1 (λ(F ) ⊗ [F ]) = λ(F ) ⊗ a−1 [F ] = λ(F ) ⊗ λ(a−1 [F ]) ⊗
[a−1 [F ]] = λ(F ) ⊗ λ(a−1 [F ]) ⊗ [a−1 F ] (the last step since
a−1 [F ]
a−1 F ). Applying right cancellativity, λ(a−1 F ) =
λ(F )⊗λ(a−1 [F ]), showing that λ(F )\λ(a−1 F ) exists. Finalquotient property: Quotient exists since F (ε) = λ(F )⊗[F ](ε).
16
Let x, y denote the function mapping a to x, b to y, and
everything else to 0. Given km = km , we have k ⊗ m, 1 =
k⊗ m , 1 . Since the minimum residue property implies greedy
factorization, we can write m, 1 = f ⊗ a, b , m , 1 =
g ⊗ a, b . Then f ⊗ b = g ⊗ b, so by right cancellativity
f = g, whence m = f ⊗ a = g ⊗ a = m .
17
The equivalence is a standard exercise, though not obvious.

def

λ(F ) =

F (min support(F )) ∈ K
0

if F = 0
if F = 0

where support(F ) denotes the set of input strings to
which F assigns a non-0 weight. This λ clearly has the
shifting property needed by section 5. The quotient and
ﬁnal-quotient properties come for free because we are in
a division semiring and because λ(F ) = 0 iff F = 0.
Under this deﬁnition, what is λ(Fq ) for a sufﬁx function Fq ? Consider all paths of nonzero weight18 from
state q to a ﬁnal state. If none exist, λ(Fq ) = 0. Otherwise, min support(Fq ) is the input string on the shortest such path, breaking ties lexicographically.19 λ(Fq ) is
simply the weight of that shortest path.
To push, we must compute λ(Fq ) for each state q. This
is easy because λ(Fq ) is the weight of a single, minimumlength and hence acyclic path from q. (Previous methods combined the weights of all paths from q, even if
inﬁnitely many.) It also helps that the left factors at different states are related: if the minimum path from q begins with a weight-k arc to r, then it continues along the
minimum path from r, so λ(Fq ) = k ⊗ λ(Fr ).
Below is a trivial linear-time algorithm for computing
λ(Fq ) at every q. Each state and arc is considered once
in a breadth-ﬁrst search back from the ﬁnal states. len(q)
and ﬁrst(q) store the string length and ﬁrst letter of a running minimum of support(Fq ) ∈ Σ∗ .
foreach state q
if q is ﬁnal then
len(q) := 0
(* min support(Fq ) is ε for ﬁnal q *)
λ(Fq ) := φ(q) (* Fq (ε) is just the ﬁnal weight, φ(q) *)
enqueue q on a FIFO queue
else
len(q) := ∞
(* not yet discovered *)
λ(Fq ) := 0
(* assume Fq = 0 until we discover q *)
until the FIFO queue is empty
dequeue a state r
a:k
foreach arc q −→r entering r such that k = 0
if len(q) = ∞ then enqueue q (* breadth-ﬁrst search *)
if len(q) = ∞ or (len(q) = len(r) + 1
and a < ﬁrst(q)) then
ﬁrst(q) := a
(* reduce min support(Fq ) *)
len(q) := len(r) + 1
λ(Fq ) := k ⊗ λ(Fr )

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.

The runtime is O(|states|+t·|arcs|) if ⊗ has runtime t.
If ⊗ is slow, this can be reduced to O(t · |states| + |arcs|)
by removing line 16 and waiting until the end, when the
minimum path from each non-ﬁnal state q is fully known,
to compute the weight λ(Fq ) of that path. Simply ﬁnish
up by calling F IND -λ on each state q:
F IND -λ(state q):
if λ(Fq ) = 0 and len(q) < ∞ then
2.
λ(Fq ) := σ(q, ﬁrst(q)) ⊗ F IND -λ(δ(q, ﬁrst(q)))
3.
return λ(Fq )
1.

18

In a division semiring, these are paths free of 0-weight arcs.
The min exists since < is a well-ordering. In a purely lexicographic ordering, a∗ b ⊆ Σ∗ would have no min.
19

After thus computing λ(Fq ), we simply proceed with
pushing, merging, and trimming as in section 5.20 Pushing runs in time O(t · |arcs|) and trimming in O(|states| +
|arcs|). Merging is worse, with time O(|arcs| log |states|).

7

A Bonus: Non-Division Semirings

√
The trouble with Z[ −5] was that it “lacked” needed
quotients. The example on p. 3 can easily be minimized
(down to 3 states) if we regard it instead as deﬁned over
(C, +, ×)—letting us use any weights in C. Simply use
section 6’s algorithm.
This new change-of-semiring trick can be used for
other non-division semirings as well. One can extend the
original weight semiring (K, ⊕, ⊗) to a division semiring
by adding ⊗-inverses.21
In this way, the tropical semiring (R≥0 ∪ {∞},
min, +) can be augmented with the negative reals to obtain (R ∪ {∞}, min, +). And the transducer semiring
(∆∗ ∪ {∅}, min, concat)22 can be augmented by extending the alphabet ∆ = {x, y, . . .} with inverse letters
{x−1 , y−1 , . . .}.
The minimized DFA we obtain may have “weird” arc
weights drawn from the extended semiring. But the arc
weights combine along paths to produce the original automaton’s outputs, which fall in the original semiring.
Let us apply this trick to the example of section 2,
yielding the following pushed automaton in which F1 =
F3 as desired. (x−1 , y−1 , . . . are written as X, Y, . . ., and
a: ε
λ(Fq ) is displayed at each q.)
1
a: ε

:xyz

0
xyz b:ZYXwwyz

yz

b:ZYzzz
a: ε

3
wwyz b:ZYzzz

2
z

b:ε
b:ε

5
ε

4
ε

For example, the z−1 y−1 zzz output on the 3 → 4 arc was
computed as λ(F3 )−1 ⊗ wwzzz ⊗ λ(F4 ) = (wwyz)−1 ⊗
wwzzz ⊗ ε = z−1 y−1 w−1 w−1 wwzzz.
This trick yields new algorithms for the tropical semiring and sequential transducers, which is interesting and
perhaps worthwhile. How do they compare with previous work?
Over the tropical semiring, our linear-time pushing algorithm is simpler than (Mohri, 1997), and faster by a
log factor, because it does not require a priority queue.
20

It is also permissible to trim the input automaton at the start,
or right after computing λ (note that λ(Fq ) = 0 iff we should
trim q). This simpliﬁes pushing and merging. No trimming is
then needed at the end, except to remove the one dead state that
the merging step may have added to complete the automaton.
21
This is often possible but not always; the semiring must be
cancellative, and there are other conditions. Even disregarding
⊕ because we are minimizing a deterministic automaton, it is
not simple to characterize when the monoid (K, ⊗) can be embedded into a group (Clifford and Preston, 1967, chapter 12).
22
Where min can be deﬁned as in section 6 and footnote 1.

(Though this does not help the overall complexity of minimization, which is dominated by the merging step.) We
also have no need to implement faster algorithms for special cases, as Mohri proposes, because our basic algorithm is already linear. Finally, our algorithm generalizes
better, as it can handle negative weight cycles in the input.
These are useful in (e.g.) conditional random ﬁelds.
On the other hand, Mohri’s algorithm guarantees a potentially useful property that we do not: that the weight
of the preﬁx path reading α ∈ Σ∗ is the minimum weight
of all paths with preﬁx α. Commonly this approximates
− log(p(most probable string with preﬁx α)), perhaps a
useful value to look up for pruning.
As for transducers, how does our minimization algorithm (above) compare with previous ones? Following
earlier work by Choffrut and others, Mohri (2000) deﬁnes λ(Fq ) as the longest common preﬁx of range(Fq ).
He constrains these values with a set of simultaneous
equations, and solves them by repeated changes of variable using a complex relaxation algorithm. His implementation uses various techniques (including a trie and
a graph decomposition) to make pushing run in time
O(|states| + |arcs| · maxq |λ(Fq )|).23 Breslauer (1996)
gives a different computation of the same result.
To implement our simpler algorithm, we represent
strings in ∆∗ as pointers into a global trie that extends
upon lookup. The strings are actually stored reversed in
the trie so that it is fast to add and remove short preﬁxes. Over the extended alphabet, we use the pointer
pair (k, m) to represent the string k −1 m where k, m ∈
∆∗ have no common preﬁx. Such pointer pairs can
be equality-tested in O(1) time during merging. For
k, m ∈ ∆∗ , k ⊗ m is computed in time O(|k|), and k\m
in time O(|LCP(k, m)|) or more loosely O(|k|) (where
LCP = longest common preﬁx).
The total time to compute our λ(Fq ) values is therefore
O(|states| + t · |arcs|), where t is the maximum length of
any arc’s weight. For each arc we then compute a new
weight as a left-quotient by a λ value. So our total runtime for pushing is O(|states| + |arcs| · maxq |λ(Fq )|).
This may appear identical to Mohri’s runtime, but in fact
our |λ(Fq )| ≥ Mohri’s, though the two deﬁnitions share
a worst case of t · |states|.24
Inverse letters must be eliminated from the minimized
transducer if one wishes to pass it to any specialized algorithms (composition, inversion) that assume weights
in ∆∗ . Fortunately this is not hard. If state q of the
23

We deﬁne |ε| = 1 to simplify the O(· · ·) expressions.
The |λ(Fq )| term contributed by a given arc from q is a
bound on the length of the LCP of the outputs of certain paths
from q. Mohri uses all paths from q and we use just two, so our
LCP is sometimes longer. However, both LCP s probably tend to
be short in practice, especially if one bypasses LCP(k, k) with
special handling for k\k = ε.
24

result was formed by merging states q1 , . . . qj , deﬁne
ρ(q) = LCS{λ(Fqi ) : i = 1, . . . j} ∈ ∆∗ (where LCS =
longest common sufﬁx). Now push the minimized transducer using ρ(q)−1 in place of λ(Fq ) for all q. This corrects for “overpushing”: any letters ρ(q) that were unnecessarily pushed back before minimization are pushed forward again, cancelling the inverse letters. In our running
example, state 0 will push (xyz)−1 back and the merged
state {1,3} will push (yz)−1 back. This is equivalent to
pushing ρ(0) = xyz forward through state 0 and the yz
part of it forward through {1,3}, canceling the z−1 y−1 at
the start of one of the next arcs.
We must show that the resulting labels really are free
of inverse letters. Their values are as if the original pushing had pushed back not λ(Fqi ) ∈ ∆∗ but only its shorter
def
ˆ
preﬁx λ(qi ) = λ(Fqi )/ρ(qi ) ∈ ∆∗ (note the right quotient). In other words, an arc from qi to ri with weight
ˆ
ˆ
k ∈ ∆∗ was reweighted as λ(qi )\(k ⊗ λ(ri )). Any inverse letters in such new weights clearly fall at the left.
So suppose the new weight on the arc from q to r begins
ˆ
with an inverse letter z −1 . Then λ(qi ) must have ended
with z for each i = 1, . . . j. But then ρ(qi ) was not the
longest common sufﬁx: zρ(qi ) is a longer one, a contradiction (Q.E.D.).
Negative weights can be similarly eliminated after
minimization over the tropical semiring, if desired, by
substituting min for LCS.
The optional elimination of inverse letters or negative weights does not affect the asymptotic runtime. A
caveat here is that the resulting automaton no longer has
a canonical form. Consider a straight-line automaton:
pushing yields a canonical form as always, but inverseˆ
letter elimination completely undoes pushing (λ(qi ) =
ε). This is not an issue in Mohri’s approach.

8

Conclusion and Final Remarks

We have for the most part characterized the semirings
over which weighted deterministic automata can be minimized (section 4), and we have shown how to perform
such minimization in both general and speciﬁc cases (sections 5, 6, 7). Our technique for division semirings and
their subsemirings pushes back, at each state q, the output of a single, easily found, shortest accepting path from
q. This is simpler and more general than previous approaches that aggregate all accepting paths from q.
Our new algorithm (section 6) is most important for
previously unminimizable, practically needed division
semirings: real (e.g., for probabilities), expectation (for
learning (Eisner, 2002)), and additive with negative
weights (for conditional random ﬁelds (Lafferty et al.,
2001)). It can also be used in non-division semirings,
as for transducers. It is unpatented, easy to implement,
comparable or faster in asymptotic runtime, and perhaps

faster in practice (especially for the tropical semiring,
where it seems preferable in most respects).
Our approach applies also to R-weighted sequential
transducers as in (Cortes et al., 2002). Such automata
can be regarded as weighted by the product semiring
(R × ∆∗ , (+, min), (×, concat)). Equivalently, one can
push the numeric and string components independently.
Our new pushing algorithm enables not only minimization but also equivalence-testing in more weight semirings. Equivalence is efﬁciently tested by pushing the (deterministic) automata to canonicalize their arc labels and
then testing unweighted equivalence (Mohri, 1997).

Let M be any automaton that computes F . For α, β ∈ D,
M

we say α ∼ β iff δM (0, α) = δM < (0, β), i.e., the preﬁxes
α and β lead from the start state 0 to the same state q in M .
M

F

If α ∼ β, then α ∼ β, since α−1 F = σ(0, α) ⊗ Fq
σ(0, β) ⊗ Fq = β −1 F .
F

If α ∼ β, then α−1 F

β −1 F , so FδM (0,α)

α−1 F
¯
M

−1

β F
FδM (0,β) , so δM (0, α)
δM (0, β), so α ∼ β by
¯
construction of M .
¯
M
F
M
In short, α ∼ β ⇒ α ∼ β ⇒ α ∼ β. So each of the three
partitions of D into equivalence classes is a reﬁnement of the
next. Hence nM ≥ nF ≥ nM , where these are the respective
¯
numbers of equivalence classes.
M

References
A. V. Aho, J. E. Hopcroft, and J. D. Ullman. 1974. The Design
and Analysis of Computer Algorithms. Addison-Wesley.
Jean Berstel and Christophe Reutenauer. 1988. Rational Series
and their Languages. Springer-Verlag.
Dany Breslauer. 1996. The sufﬁx tree of a tree and minimizing
sequential transducers. Lecture Notes in Computer Science,
1075.
A. H. Clifford and G. B. Preston. 1967. The Algebraic Theory
of Semigroups.
Corinna Cortes, Patrick Haffner, and Mehryar Mohri. 2002.
Rational kernels. In Proceedings of NIPS, December.
Pierluigi Crescenzi and Viggo Kann. 1998. How to ﬁnd the best
approximation results—a follow-up to Garey and Johnson.
ACM SIGACT News, 29(4):90–97, December.
Jason Eisner. 2002. Parameter estimation for probabilistic
ﬁnite-state transducers. In Proc. of ACL, Philadelphia, July.
John Lafferty, Andrew McCallum, and Fernando Pereira. 2001.
Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the
International Conference on Machine Learning.
Mehryar Mohri. 1997. Finite-state transducers in language and
speech processing. Computational Linguistics, 23(2).
Mehryar Mohri. 2000. Minimization algorithms for sequential
transducers. Theoretical Computer Science, 324:177–201.

Appendix: Remaining Proofs
Let M be an automaton to minimize and F : Σ∗ → K be the
function it deﬁnes. We assume (K, ⊗) allows greedy factorization, so is an equivalence relation on nonzero functions. We
¯
ﬁrst prove that M with the properties of section 4 is the minimal
automaton computing F . We will then show, following Mohri,
¯
that the algorithm of section 5 ﬁnds such an M . (Section 6 is a
special case of section 5.)
We chose in advance a desired sufﬁx function F[r] for each
¯
¯
state [r] of M , and used these to determine the weights of M .
˜
To show that the weights were determined correctly, let F[r] be
the actual sufﬁx function of [r]. Claim that for all α and r,
˜
F[r] (α) = F[r] (α). This is easily proved by induction on |α|.
¯
Our choice of initial weight then ensures that M computes F .
F
We must now prove minimality. For α, β ∈ Σ∗ , say α ∼ β
F
iff α−1 F
β −1 F . Note that ∼ is an equivalence relation on
def
25
∗
−1
D = {α ∈ Σ : α F = 0}.
It is not an equivalence relation on all of Σ∗ , since α ∈ D is
F
related by ∼ to every β. This corresponds to the fact that a dead
25

Since ∼ has one equivalence class per useful state of M (as
deﬁned in section 2), nM is the number of states in a trimmed
¯
version of M . Similarly nM is the number of states of M (after
¯
¯
trimming). Since M was arbitrary, M is minimal.
¯
Uniqueness: If M has the same number of states as M , then
the two partitions must be equal. So two preﬁxes reach the same
¯
state in M iff they do so in M . This gives a δ-preserving iso¯
morphism between M and M . It follows that the minimal DFA
is unique, except for the distribution of output labels along paths
(which may depend on arbitrary choices of residues F[r] ).
Now we turn to section 5’s effective construction, using λ,
ˆ
¯
of a pushed automaton M and a merged version M . The proof
of minimality is essentially the same as in (Mohri, 2000). We
¯
know that M computes the same function as M (since pushing,
merging, and trimming preserve this). So it sufﬁces to show
¯
M

F

α ∼ β ⇒ α ∼ β. The above proof of minimality will then go
through as before.
ˆ
M and M have the same states and transition function δ;
denote their emission functions by σ and σ . Fq refers to sufˆ
F
ﬁx functions in M . Given α ∼ β (so α, β ∈ D), use the
F
deﬁnition of ∼ to write α−1 F = kα ⊗ F and β −1 F =
kβ ⊗ F . Let q = δ(0, α), r = δ(0, β), k = σ(0, α).
For any a ∈ Σ, write σ (q, a) = λ(Fq )\λ(a−1 Fq ) = (k ⊗
ˆ
λ(Fq ))\(k ⊗ λ(a−1 Fq )) = λ(k ⊗ Fq )\λ(k ⊗ a−1 Fq ) =
λ(α−1 F )\λ(a−1 (α−1 F )) = λ(kα ⊗F )\λ(a−1 (kα ⊗F )) =
λ(F )\λ(a−1 F ). By symmetry, σ (r, a) = λ(F )\λ(a−1 F )
ˆ
as well. Thanks to left cancellativity, left quotients are unique,
so σ (q, a) = σ (r, a).26
ˆ
ˆ
F
ˆ
So α ∼ β ⇒ corresponding arcs from q and r in M output
F

identical weights. Since αa ∼ βa as well, the same holds at
ˆ
δ(q, a) and δ(r, a). So by induction, regarding M as an unweighted automaton, exactly the same strings in (Σ × K)∗ are
accepted from q and from r. So merging will merge q and r,
¯
M

and α ∼ β as claimed.

state can be made to merge with any state by pushing 0 back
from it, so that the arcs to it have weight 0 and the arcs from
¯
it have arbitrary weights. Our construction of M only creates
states for the equivalence classes of D; δ(0, α) for α ∈ D is
undeﬁned, not a dead state.
26
We must check that we did not divide by 0 and obtain a
false equation. It sufﬁces to show that k = 0 and λ(Fq ) =
0. Fortunately, α ∈ D implies both. (It implies Fq = 0, so
(γ −1 Fq )(ε) = Fq (γ) = 0 for some γ. Hence λ(Fq ) = 0
since otherwise λ(γ −1 Fq ) = 0 and λ(γ −1 Fq )\(γ −1 Fq )(ε) is
undeﬁned, contradicting the ﬁnal-quotient property.)

