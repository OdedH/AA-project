EMNLP’12

Joint Inference for Event Timeline Construction

Quang Xuan Do
Wei Lu
Dan Roth
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA
{quangdo2,luwei,danr}@illinois.edu

Abstract

Time
−→

e4

This paper addresses the task of constructing a timeline of events mentioned in a given
text. To accomplish that, we present a novel
representation of the temporal structure of a
news article based on time intervals. We then
present an algorithmic approach that jointly
optimizes the temporal structure by coupling
local classiﬁers that predict associations and
temporal relations between pairs of temporal entities with global constraints. Moreover,
we present ways to leverage knowledge provided by event coreference to further improve
the system performance. Overall, our experiments show that the joint inference model signiﬁcantly outperformed the local classiﬁers by
9.2% of relative improvement in F1 . The experiments also suggest that good event coreference could make remarkable contribution to
a robust event timeline construction system.

1

Introduction

Inferring temporal relations amongst a collection of
events in a text is a signiﬁcant step towards various important tasks such as automatic information
extraction and document comprehension. Over the
past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have
been several works on building automatic systems
for such a task (Mani et al., 2006; Chambers and
Jurafsky, 2008; Yoshikawa et al., 2009; Denis and
Muller, 2011).
Most previous works devoted much efforts to the
task of identifying relative temporal relations (such
as before, or overlap) amongst events (Chambers

e3 /e5

|

e1

|

•
−∞

t1
•

I1

e2

t2
•

t3
•

|

|

I2

t4
•
e7 − e6
I3

•
+∞
|

|

Figure 1: A graphical illustration of our timeline representation.
The e’s, t’s and I’s are events, time points and time intervals,
respectively.

and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of
occurrence. Even if this issue is addressed, certain
restrictions are often imposed for efﬁciency reasons
(Yoshikawa et al., 2009; Verhagen et al., 2010). In
practice, however, being able to automatically infer
the correct time of occurrence associated with each
event is crucial. Such information not only leads to
better text comprehension, but also enables fusion
of event structures extracted from multiple articles
or domains.
In this work, we are speciﬁcally interested in mapping events into an universal timeline representation. Besides inferring the relative temporal relations amongst the events, we would also like to automatically infer a speciﬁc absolute time of occurrence for each event mentioned in the text. Unlike
previous work, we associate each event with a speciﬁc absolute time interval inferred from the text. An
example timeline representation is illustrated in Fig.

1. Further details of our timeline representation are
given in Sec. 2.3.
We perform global inference by combining a collection of local pairwise classiﬁers through the use
of an Integer Linear Programming (ILP) formulation that promotes global coherence among local decisions. The formulation allows our model to predict both event-event relations and event-time interval associations simultaneously. We show that, with
the use of time intervals instead of time points, our
approach leads to a more concise ILP formulation
with reduced number of variables and constraints.
Moreover, we observed that event coreference can
reveal important information for such a task. We
propose that different event mentions that refer to
the same event can be grouped together before classiﬁcation and performing global inference. This can
reduce the amount of efforts in both classiﬁcation
and inference stages and can potentially eliminate
mistakes that would be made otherwise without such
coreference information. To the best of our knowledge, our proposal of leveraging event coreference
to support event timeline construction is novel.
Our experiments on a collection of annotated
news articles from the standard ACE dataset demonstrate that our approach produces robust timelines of
events. We show that our algorithmic approach is
able to combine various local evidences to produce
a global coherent temporal structure, with improved
overall performance. Furthermore, the experiments
show that the overall performance can be further improved by exploiting knowledge from event coreference.

2

Background

We focus on the task of mapping event mentions in
a news article to a timeline. We ﬁrst brieﬂy describe
and deﬁne several basic concepts.
2.1

Events

Following the annotation guidelines of the ACE
project, we deﬁne an event as an action or occurrence that happens with associated participants or
arguments. We also distinguish between events and
event mentions, where a unique event can be coreferred to by a set of explicit event mentions in an
article. Formally, an event E i is co-referred to by

a set of event mentions (ei , ei , . . . , ei ). Each event
1 2
k
mention e can be written as p(a1 , a2 , . . . , al ), where
the predicate p is the word that triggers the presence
of e in text, and a1 , a2 , . . . al are the arguments associated with e. In this work we focus on four temporal relations between two event mentions including
before, after, overlap and no relation.
2.2

Time Intervals

Similar to Denis and Muller (2011), we deﬁne time
intervals as pairs of time endpoints. Each time interval I is denoted by [t− , t+ ], where t− and t+ are
two time endpoints representing the lower and upper
bound of the interval I, respectively, with t− ≤ t+ .
The general form of a time endpoint is written as
“YYYY-MM-DD hh:mm:ss”. An endpoint can be undeﬁned, in which case it is set to an inﬁnity value:
−∞, or +∞. There are two types of time intervals:
Explicit intervals are time intervals that can be
extracted directly from a given text. For example,
consider the following snippet of an article in our
data set: The litigation covers buyers in auctions
outside the United States between January 1, 1993
and February 7, 2000. In this example, we can extract and normalize two time intervals which are explicitly written, including January 1, 1993 → [199301-01 00:00:00, 1993-01-01 23:59:59] and February 7, 2000 → [2000-02-07 00:00:00, 2000-02-07
23:59:59]. Moreover, an explicit interval can also
be formed by one or more separate explicit temporal
expressions. In the example above, the connective
term between relates the two expressions to form a
single time interval: between January 1, 1993 and
February 7, 2000 → [1993-01-01 00:00:00, 200002-07 23:59:59]. To extract explicit time intervals
from text, we use the time interval extractor described in Zhao et al. (2012).
Implicit intervals are time intervals that are not
explicitly mentioned in the text. We observed that
there are events that cannot be assigned to any precise time interval but are roughly known to occur
in the past or in the future relative to the Document Creation Time (DCT) of the article. We
introduce two implicit time intervals to represent
the past and the future events as (−∞, t− ] and
DCT
[t+ , +∞), respectively. In addition, we also alDCT
low an event mention to be assigned into the entire
timeline, which is denoted by (−∞, +∞) if we can-

not identify its time of occurrence. We also consider
DCT as an implicit interval.
We say that the time interval Ii precedes the time
interval Ij on a timeline if and only if t+ ≤ t− ,
i
j
which also implies that Ii succeeds Ij if and only if
t− ≥ t+ . The two intervals overlap, otherwise.
i
j
2.3

Timeline

We deﬁne a timeline as a partially ordered set of time
intervals. Fig. 1 gives a graphical illustration of an
example timeline, where events are annotated and
associated with time intervals. Relations amongst
events can be properly reﬂected in the timeline representation. For example, in the ﬁgure, the events e1
and e2 are both associated with the interval I1 . The
relation between them is no relation, since it is unclear which occurs ﬁrst. On the other hand, e5 and
e3 both happen in the interval I2 but they form an
overlap relation. The events e6 and e7 occur within
the same interval I3 , but e7 precedes (i.e. before) e6
on the timeline. The event e4 is associated with the
interval (−∞, +∞), indicating there is no knowledge about its time of occurrence.
We believe that such a timeline representation
for temporally ordering events has several advantages over the temporal graph representations used
in previous works (Chambers and Jurafsky, 2008;
Yoshikawa et al., 2009; Denis and Muller, 2011).
Unlike previous works, in our model the events are
partially ordered in a single timeline, where each
event is associated with a precise time interval. This
improves human interpretability of the temporal relations amongst events and time. This property of
our timeline representation, thus, facilitates merging multiple timelines induced from different articles. Furthermore, as we will show later, the use
of time intervals within the timeline representation
simpliﬁes the global inference formulation and thus
the inference process.

3

A Joint Timeline Model

Our task is to induce a globally coherent timeline
for a given article. We thus adopt a global inference model for performing the task. The model
consists of two components: (1) two local pairwise
classiﬁers, one between event mentions and time intervals (the E–T classiﬁer) and one between event

mentions themselves (the E–E classiﬁer), and (2)
a joint inference module that enforces global coherency constraints on the ﬁnal outputs of the two
local classiﬁers. Fig. 2 shows a simpliﬁed temporal
structure of event mentions and time intervals of an
article in our model.
Our E–T classiﬁer is different from previous
work (Chambers and Jurafsky, 2008; Yoshikawa et
al., 2009; Denis and Muller, 2011), where such classiﬁers were trained to identify temporal relations between event mentions and a temporal expression. In
our work, in order to construct absolute timeline of
event mentions, temporal expressions are captured
and normalized as absolute time intervals. The E–T
classiﬁers are then used to assign event mentions to
their contextually corresponding time intervals.
We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al.,
2009; Verhagen et al., 2010). Speciﬁcally, we do
not require that event mentions and time expressions
have to appear in the same sentence, and we do not
require two event mentions have to appear very close
to each other (e.g., main event mentions in adjacent
sentences) in order to be considered as candidate
pairs for classiﬁcation. Instead, we performed classiﬁcations over all pairs of event mentions and time
intervals as well as over all pairs of event mentions.
We show through experiments that lifting these restrictions is indeed important (see Sec. 5).
Another important improvement over previous
work is our global inference model We would like
to highlight that our work is also distinct from most
previous works in the global inference component.
Speciﬁcally, our global inference model jointly optimizes the E-E relations amongst event mentions
and their associations, E-T, with temporal information (intervals in our case). Previous work (Chambers and Jurafsky, 2008; Denis and Muller, 2011),
on the other hand, assumed that the E-T information
is given and only tried to improve E-E.
3.1

The Pairwise Classiﬁers

We ﬁrst describe our local classiﬁers that associate
event mention with time interval and classify temporal relations between event mentions, respectively.
CE−T : is the E–T classiﬁer that associates an
event mention with a time interval. Given an event
mention and a time interval, the classiﬁer predicts

I1

e1

I2

e2

e3

I3

e4

Im

•••

e5

•••

en-1

en

Figure 2: A simpliﬁed temporal structure of an article. There
are m time intervals I1 · · · Im and n event mentions e1 · · · en .
A solid edge indicates an association between an interval and
an event mention, whereas a dash edge illustrates a temporal
relation between two event mentions.

whether the former associates with the latter.
CE−T (ei , Ij ) → {0, 1},
∀i, j, 1 ≤ i ≤ n, 1 ≤ j ≤ m,

(1)

where n and m are the number of event mentions
and time intervals in an article, respectively.
CE−E : is the E–E classiﬁer that identiﬁes
the temporal relation between two event mentions.
Given a pair of event mentions, the classiﬁer predicts
one of the four temporal relations between them:
¯
before, after, overlap and no relation. Speciﬁcally:
¯
¯
¯
CE−E (ei , ej ) → {¯ a, o, n},
b, ¯ ¯ ¯
∀i, j, 1 ≤ i, j ≤ n, i = j,

(2)

For training of the classiﬁers, we deﬁne a set of
features following some previous work (Bethard et
al., 2007; Chambers and Jurafsky, 2008; Yoshikawa
et al., 2009), together with some additional features
that we believe to be helpful for the interval-based
representation. We describe the base features below
and use † and ‡ to denote the features used for CE−T
and CE−E , respectively. We use the term temporal
entity (or entity, for short) to refer to either an event
mention or a time interval.
Lexical Features: A set of lexical features related
to the temporal entities: (i)†‡ the word, lemma and
part-of-speech of the input event mentions and the
context surrounding them, where the context is deﬁned as a window of 2 words before and after the
mention; (ii)† the modal verbs to the left and to the
right of the event mention; (iii)‡ the temporal connectives between the event mentions1 .
1

We deﬁne a list of temporal connectives including before,
after, since, when, meanwhile, lately, etc.

Syntactic Features: (i)†‡ which entity appears
ﬁrst in the text; (ii)†‡ whether the two entities appear
in the same sentence; (iii)†‡ the quantized number of
sentences between the two entities2 ; (iv)†‡ whether
the input event mentions are covered by prepositional phrases and what are the heads of the phrases;
(v)†‡ if the entities are in the same sentence, what is
their least common constituent on the syntactic parse
tree; (vi)† whether there is any other temporal entity
that is closer to one of the two entities.
Semantic Features‡ : A set of semantic features,
mostly related to the input event mentions: (i)
whether the input event mentions have a common
synonym from their synsets in WordNet (Fellbaum,
1998); (ii) whether the input event mentions have a
common derivational form derived from WordNet.
Linguistic Features†‡ : The tense and the aspect
of the input event mentions. We use an in-house
rule-based recognizer to extract these features.
Time Interval Features† : A set of features related to the input time interval: (i) whether the
interval is implicit; (ii) if it is implicit, identify
its interval type: “dct” = [t− , t+ ], “past” =
DCT DCT
(−∞, t− ], “feature” = [t+ , +∞), and “enDCT
DCT
tire” = (−∞, +∞); (iii) the interval is before, after
or overlapping with the DCT.
We note that unlike many previous work (Mani et
al., 2006; Chambers and Jurafsky, 2008; Denis and
Muller, 2011), our classiﬁers do not use any gold
annotations of event attributes (event class, tense, aspect, modal and polarity) provided in the TimeBank
corpus as features.
In our work, we use a regularized averaged Perceptron (Freund and Schapire, 1999) as our classiﬁcation algorithm3 . We used the one-vs.-all scheme
to transform a set of binary classiﬁers into a multiclass classiﬁer (for CE−E ). The raw prediction
scores were converted into probability distribution
using the Softmax function (Bishop 1996). If there
are n classes and the raw score of class i is acti , the
posterior estimation for class i is:
˜
P (i) =
2

eacti
1≤j≤n e

actj

We quantize the number of sentences between two entities
to 0, 1, 2, less than 5 and greater than or equal to 5
3
Other algorithm (e.g. SVM) gave comparable or worse results, so we only show the results from Averaged Perceptron.

3.2

Joint Inference for Event Timeline

To exploit the interaction among the temporal entities in an article, we optimize the predicted temporal structure, formed by predictions from CE−T and
CE−E , w.r.t. a set of global constraints that enforce
coherency on the ﬁnal structure. We perform exact
inference using Integer Linear Programming (ILP)
as in (Roth and Yih, 2007; Clarke and Lapata, 2008).
We use the Gurobi Optimizer4 as a solver.
Let I = {I1 , I2 , . . . , Im } denote the set of time
intervals extracted from an article, and let E =
{e1 , e2 , . . . , en } denote all event mentions in the
same article. Let EI = {(ei , Ij ) ∈ E × I|ei ∈
E, Ij ∈ I} denote the set of all pairs of event
mentions and time intervals. We also denote the
set of event mention pairs by EE = {(ei , ej ) ∈
E × E|ei ∈ E, ej ∈ E, i = j}. The prediction probability of an association of a pair eI ∈ EI, given
by classiﬁer CE−T , is denoted by p eI,1 5 . Now, let
R = {¯ a, o, n} be the set of temporal relations beb, ¯ ¯ ¯
tween two event mentions. The prediction probability of an event mention pair ee ∈ EE that takes
temporal relation r, given by CE−E , is denoted by
p ee,r . Furthermore, we deﬁne x eI,1 to be a binary
indicator variable that takes on the value 1 iff an association is predicted between e and I. Similarly,
we deﬁne a binary indicator variable y ee,r of a pair
of event mentions ee that takes on the value 1 iff ee
is predicted to hold the relation r.
The objective function is then deﬁned as a linear
combination of the prediction probabilities from the
two local classiﬁers as follows:
arg max λ
x,y

p

eI,1

·x

eI,1

eI∈EI

+ (1 − λ)

p

ee,r

·y

ee,r

(3)

ee∈EE r∈R

subject to the following constraints:
x

eI,1

∈ {0, 1},

∀eI ∈ EI

(4)

y

ee,r

∈ {0, 1},

∀ee ∈ EE, r ∈ R

(5)

∀ee ∈ EE

(6)

y

ee,r

= 1,

We use the single parameter λ to balance the overall contribution of two components E-T and E-E.
λ is determined through cross validation tuning on
a development set. We use (4) and (5) to make sure
x eI,1 and y ee,r are binary values. The equality
constraint (6) ensures that exactly one particular relation can be assigned to each event mention pair.
In addition, we also require that each event is associated with only one time interval. These constraints are encoded as follows:
x

eI,1

= 1,

∀e ∈ E

(7)

I∈I

Our model also enforces reﬂexivity and transitivity constraints on the relations among event mentions as follows:
y

ei ej ,r

−y

ej ei ,ˆ
r

= 0,

∀ei ej = (ei , ej ) ∈ EE, i = j
y

ei ej ,r1

+y

ej ek ,r2

−y

ei ek ,r3

(8)

≤ 1,

∀ei ej , ej ek , ei ek ∈ EE, i = j = k

(9)

The equality constraints in (8) encode reﬂexive
property of event-event relations, where the relation r denotes the inversion of the relation r. The
ˆ
set of possible (r, r) pairs is deﬁned as follows:
ˆ
(¯ a), (¯, ¯ (¯, o), (¯ , n) . Following the work
b, ¯ a b), o ¯ n ¯
of (Bramsen et al., 2006; Chambers and Jurafsky,
2008), we encode transitive closure of relations between event mentions with inequality constraints in
(9), which states that if the pair (ei , ej ) has a certain
relation r1 , and the pair (ej , ek ) has the relation r2 ,
then the relation r3 must be satisﬁed between ei and
ek . Examples of such triple (r1 , r2 , r3 ) include (¯ ¯
b, b,
¯ and (¯, a, a).
b)
a ¯ ¯
Finally, to capture the interactions between our
local pairwise classiﬁers we add the following constraints:
x

ei Ik ,1

+x

ej Il ,1

−y

ei ej ,¯
b

≤ 1,

∀ei Ik , ej Il ∈ EI, ∀ei ej ∈ EE,
Ik precedes Il , i = j, k = l

(10)

r∈R
4

http://gurobi.com/
This value is complementary to the non-association probability, denoted by p eI,0 = 1 − p eI,1
5

Intuitively, the inequality constraints in (10) specify that a temporal relation between two event mentions can be inferred from their respective associated

time intervals. Speciﬁcally, if two event mentions ei
and ej are associated with two time intervals Ik and
Il respectively, and Ik precedes Il in the timeline,
then ei must happen before ej .
It is important to note that our interval-based formulation is more concise in terms of the number of
variables and constraints needed in the ILP relative
to time expression-based (or timepoint-based) formulations used in previous work (Chambers and Jurafsky, 2008). Speciﬁcally, in such timepoint-based
formulations, the relation between each event mention and each time expression needs to be inferred,
resulting in |E||T ||RT | variables, where |E|, |T |,
and |RT | are the numbers of event mentions, time
points, and temporal relations respectively. In contrast, only |E||I| variables are required in our formulation, where |I| is the number of intervals (since
we extract intervals explicitly, |I| is roughly equal
to |T |). Furthermore, performing inference with the
timepoint-based formulation would require |E||T |
equality constraints to enforce that each event mention can take only one relation in RT for a particular
time point, whereas our interval-based model only
requires |E| constraints, since each event is strictly
associated with one interval (see Eqn. (7)). We justify the beneﬁts of our formulation later in Sec. 5.4.

4

Incorporating Knowledge from Event
Coreference

One of the key contributions of our work is using
event coreference information to enhance the timeline construction performance. This is motivated by
the following two principles:
(P1) All mentions of a unique event are associated with the same time interval, and overlap with
each other.
(P2) All mentions of an event have the same temporal relation with all mentions of another event.
The example below, extracted from an article published on 03/11/2003 in the Automatic Content Extraction (ACE), 2005, corpus6 serves to illustrate the
signiﬁcance of event coreference to our task.
6

http://www.itl.nist.gov/iad/mig/tests/ace/2005/

The world’s most powerful ﬁne art auction houses,
Sotheby’s and Christie’s, have agreed to [e1 =
1
pay] 40 million dollars to settle an international
price-ﬁxing scam, Sotheby’s said. The [e1 = pay2
ment], if approved by the courts, would settle a
slew of [e2 = suits] by clients over auctions held
1
between 1993 and 2000 outside the US. ... Sotheby’s
and Christie’s will each [e1 = pay] 20 million dol3
lars,” said Sotheby’s, which operates in 34 countries.

In this example, there are 4 event mentions, whose
trigger words are highlighted in bold face. The underlined text gives an explicit time interval: I1 =
[1993-01-01 00:00:00, 2000-12-31 23:59:59] (we
ignore 2 other intervals given by 1993 and 2000
to simplify the illustration). Now if we consider
the event mention e1 , it actually belongs to the im2
plicit future interval I2 = [2003-03-11 23:59:59,
+∞). Nevertheless, there is a reasonable chance
that CE−T associates it with I1 , given that they both
appear in the same sentence, and there is no direct evident feature indicating the event will actually happen in the future. In such a situation, using
a local classiﬁer to identify the correct temporal association could be challenging.
Fortunately, precise knowledge from event coreference may help alleviate such a problem. The
knowledge reveals that the 4 event mentions can be
grouped into 2 distinct events: E 1 = {e1 , e1 , e1 },
1 2 3
E 2 = {e2 }. If CE−T can make a strong prediction
1
in associating the event mention e1 (or e1 ) to I2 , in1
3
stead of I1 , the system will have a high chance to
re-assign e1 to I2 based on principle (P1). Similarly,
2
if CE−E is effective in ﬁguring out that some mention of event E 1 occurs after some mention of E 2 ,
then all the mentions of E 1 would be predicted to
occur after all mentions in E 2 according to (P2).
To incorporate knowledge from event coreference
into our classiﬁers and the joint inference model, we
use the following procedure: (1) performing classiﬁcation with CE−T and CE−E on the data, (2) using
the knowledge from event coreference to overwrite
the prediction probabilities obtained by the two local classiﬁers in step (1), and (3) applying the joint
inference model on the new prediction probabilities
obtained from (2). We note that if we stop at step (2),
we get the outputs of the local classiﬁers enhanced
by event coreference knowledge.
To overwrite the classiﬁcation probabilities using

event coreference knowledge, we propose two approaches as follows:
MaxScore: We deﬁne the probability between
any mention e ∈ E i and an interval I as follows:
p

˜
= max P (e , I)

eI,1

e ∈E i

(11)

˜
where P (e , I) is the classiﬁer (CE−T ) probability
for associating event mention e to the time interval.
On the other hand, the probabilities for associating the set of temporal relations, R, to each pair of
mentions in E i × E j , is given by the following pair:
(ei , ej )∗ =
p

ee,r

˜
P (ei , ej ), r)

arg max
(ei

,ej

)∈E i ×E j ,r∈R

˜
= P (ei , ej )∗ , r , ∀r ∈ R

(12)

In other words, over all possible event mention
pairs and relations, we ﬁrst pick the pair who globally obtains the highest probability for some relation. Next, we simply take the probability distribution of that event mention pair as the distribution
over the relations, for the event pair.
SumScore: The probability between any mention
e ∈ E i and an interval I is obtained by:
p

eI,1

=

1
|E i |

˜
P (e , I)

(13)

e ∈E i

To obtain the probability distribution over the set
of temporal relations, R, for any pair of mentions in
E i × E j , we used the following procedure:
r∗ = arg max
r∈R
i

j ∗

(e , e )

=

ee,r

ei ∈E i ej ∈E j
˜ i

arg max
(ei

p

˜
P (ei , ej ), r

,ej

P (e , ej ), r∗

)∈E i ×E j

˜
= P (ei , ej )∗ , r , ∀r ∈ R

(14)

In other words, given two groups of event mentions, we ﬁrst compute the total score of each relation, and select the relation which has the highest
score. Next from the list of pairs of event mentions
from the two groups, we select the pair which has the
relation r* with highest score compared to all other
pairs. The probability distribution of this pair will
be used as the probability distribution of all event
mention pairs between the two events.
In both approaches, we assign the overlap relations to all pairs of event mentions in the same event
with probability 1.0.

5

Experimental Study

We ﬁrst describe the experimental data and then
present and discuss the experimental results.
5.1

Data and Setup

Most previous works in temporal reasoning used
the TimeBank corpus as a benchmark. The corpus contains a fairly diverse collection of annotated event mentions, without any speciﬁc focus on
certain event types. According to the annotation
guideline of the corpus, most of verbs, nominalizations, adjectives, predicative clauses and prepositional phrases can be tagged as events. However, in
practice, when performing temporal reasoning about
events in a given text, one is typically interested in
signiﬁcant and typed events, such as Killing, Legislation, Election. Furthermore, event mentions in
TimeBank are annotated with neither event arguments nor event coreference information.
We noticed that the ACE 2005 corpus contains the
annotation that we are interested in. The corpus consists of articles annotated with event mentions (with
event triggers and arguments) and event coreference
information. To create an experimental data set for
our work, we selected from the corpus 20 newswire
articles published in March 2003. To extract time
intervals from the articles, we used the time interval extractor described in (Zhao et al., 2012) with
minimal post-processing. Implicit intervals are also
added according to Sec. 2.2. We then hired an annotator with expertise in the ﬁeld to annotate the data
with the following information: (i) event mention
and time interval association, and (ii) the temporal
relations between event mentions, including {¯ a,
b, ¯
o}. The annotator was not required to annotate all
¯
pairs of event mentions, but as many as possible.
Next, we saturated the relations based on the initial annotations as follows: (i) event mentions that
had not been associated with any time intervals were
assigned to the entire timeline interval (−∞, +∞),
and (ii) added inferred temporal relations between
event mentions with reﬂectivity and transitivity. Table 1 shows the data statistics before and after saturation. There are totally 8312 event pairs from 20
documents, including no relation pairs. We note that
in a separate experiment, we still evaluated CE−E
on the TimeBank corpus and got better performance

Data
Initial
Saturated

#Intervals
232
232

#E-mentions
324
324

#E-T
305
324

#E-E
376
5940

Table 1: The statistics of our experimental data set.

than a corresponding classiﬁer in an existing work
(see Sec. 5.4).
We conducted all experiments with 5-fold cross
validation at the instance level on our data set after
saturation. The global inference model was applied
on a whole document. The results of the systems are
reported in averaged precision, recall and F1 score
on the association performance, for CE−T , and the
temporal relations (we excluded the n relation, for
¯
CE−E ). We also measured the overall performance
of the systems by computing the average of the performance of the classiﬁers.
5.2

A Baseline

We developed a baseline system that works as follows. It associates an event mention with the closest
time interval found in the same sentence. If such
an interval is not found, the baseline associates the
mention with the closest time interval to the left.
If the interval is again not found, the mention will
be associated with the DCT interval. The baseline
is based on the intuition of natural reading order:
events that are mentioned earlier are likely to precede those mentioned later. For the temporal relation between a pair of event mentions, the baseline
treats the event mention that appears earlier in the
text as temporally happening before the other mention. The baseline performance is shown in the ﬁrst
group of results in Table 2.
5.3

Our Systems

For our systems, we ﬁrst evaluated the performance
of our local pairwise classiﬁers and the global inference model. The second group of results in Table 2 shows the systems’ performance. Overall,
the results show that our global inference model
relatively outperformed the baseline and the local
classiﬁers by 57.8% and 9.2% in F1 , respectively.
We perform a bootstrap resampling signiﬁcance test
(Koehn, 2004) on the output predictions of the local classiﬁers with and without the inference model.

The test shows that the overall improvement with
the inference model is statistically signiﬁcant (p <
0.01). This indicates the effectiveness of our joint
inference model with global coherence constraints.
Next, we integrated event coreference knowledge
into our systems (as described in Sec. 4) and evaluated their performance. Our experiments showed
that the SumScore approach works better for CE−T ,
while MaxScore is more suitable for CE−E . Our observations showed that event mentions of an event
may appear in close proximity with multiple time
intervals in the text, making CE−T produce high
prediction scores for many event mention-interval
pairs. This, consequently, confuses MaxScore on
the best association of the event and the time intervals, whereas SumScore overcomes the problem by
averaging out the association scores. On the other
hand, CE−E gets more beneﬁt from MaxScore because CE−E works better on pairs of event mentions
that appear closely in the text, which activate more
valuable learning features. We will report the results
using the best approach of each classiﬁer.
To evaluate our systems with event coreference
knowledge, we ﬁrst experimented our systems with
gold event coreference as given by the ACE 2005
corpus. Table 2 shows the contribution of event
coreference to our systems in the third group of the
results. The results show that injecting knowledge
from event coreference remarkably improved both
the local classiﬁers and the joint inference model.
Overall, the system that combined event coreference and the global inference model achieved the
best performance, which signiﬁcantly overtook all
other compared systems. Speciﬁcally, it outperformed the baseline system, the local classiﬁers, and
the joint inference model without event coreference
with 80%, 25%, and 14% of relative improvement in
F1 , respectively. It also consistently outperformed
the local classiﬁers enhanced with event coreference. We note that the precision and recall of CE−T
in the joint inference model are the same because
the inference model enforced each event mention to
be associated with exactly one time interval. This
is also true for the systems integrated with event
coreference because our integration approaches assign only one time interval to an event mention.
We next move to experimenting with automatically learned event coreference systems. In this ex-

Model
1
2

3

4

Baseline
No Event Coref.
Local classiﬁers
Global inference
With Gold Event Coref.
Local classiﬁers
Global inference
With Learned Event Coref.
Local classiﬁers
Global inference

Prec.
33.29

CE−T
Rec.
33.29

F1
33.29

Prec.
20.86

CE−E
Rec.
32.81

F1
25.03

Prec.
27.06

62.70
47.88

34.50
47.88

43.29
47.88

40.46
41.42

42.42
48.04

40.96
44.14

51.58
44.65

38.46
47.96

42.13
46.01

50.88
50.88

50.88
50.88

50.88
50.88

43.86
48.04

52.65
62.45

47.46
54.05

47.37
49.46

51.77
56.67

49.17
52.47

46.37
46.37

46.37
46.37

46.37
46.37

40.83
42.09

45.28
52.50

42.60
46.47

43.60
44.23

45.83
49.44

44.49
46.42

Overall
Rec.
F1
33.05 29.16

Table 2: Performance under various evaluation settings. All ﬁgures are averaged scores from 5-fold cross-validation experiments.

periment, we re-trained the event coreference system described in Chen et al. (2009) on all articles in the ACE 2005 corpus, excluding the 20 articles used in our data set. The performance of these
systems are shown in the fourth group of the results in Table 2. The results show that by using a
learned event coreference system, we achieved the
same improvement trends as with gold event coreference. However, we did not obtain signiﬁcant improvement when comparing with global inference
without event coreference information. This result
shows that the performance of an event coreference
system can have a signiﬁcant impact on the overall performance. While this suggests that a better
event coreference system could potentially help the
task more, it also opens the question whether event
coreference can be beneﬁted from our local classiﬁers through the use of a joint inference framework.
We would like to leave this for future investigations.
5.4

Previous Work-Related Experiments

We also performed experiments using the same setting as in (Yoshikawa et al., 2009), which followed
the guidelines of the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010), on our saturated data. Several assumptions were made to simplify the task. For example, only main events in
adjacent sentences are considered when identifying
event-event relations. See (Yoshikawa et al., 2009)
for more details. We performed 5-fold cross validation without event coreference. Overall, the system
achieved 29.99 F1 for the local classiﬁers and 34.69
when the global inference is used. These results are
better than the baseline but underperform our full
models where those simpliﬁcation assumptions are

not imposed, as shown in Table 2, indicating the importance of relaxing their assumptions in practice.
We also evaluated our CE−E on the TimeBank
corpus. We followed the settings of Chambers and
Jurafsky (2008) to extract all event mention pairs
that were annotated with before (or ibefore, “immediately before”) and after (or iafter) relations in 183
news articles in the corpus. We trained and evaluated our CE−E on these examples with the same feature set that we evaluated in our experiments above,
with gold tense and aspect features but without event
type. Following their work, we performed 10-fold
cross validation. Our classiﬁer achieved a microaveraged accuracy of 73.45%, whereas Chambers
and Jurafsky (2008) reported 66.8%. We next injected the knowledge of an event coreference system trained on the ACE2005 corpus into our CE−E ,
and obtained a micro-averaged accuracy of 73.39%.
It was not surprising that event coreference did not
help in this dataset because: (i) different domains
– the event coreference was trained on ACE 05 but
applied on TimeBank, and (ii) different annotation
guidelines on events in ACE 2005 and TimeBank.
Finally, we conducted an experiment that justiﬁes the advantages of our interval-based inference
model over a time point-based inference. To do this,
we ﬁrst converted our data in Table 1 from intervals to time points and infer the temporal relations
between the annotated event mentions and the time
points: before, after, overlap, and unknown. We
modiﬁed the ﬁrst component in the objective function in (3) to accommodate these temporal relations.
We also made several changes to the constraints,
including removing those in (7) since they are no
longer required, and adding constraints that ensure

the relation between a time point and an event mention takes exactly one value. Proper changes were
also made to other constraints in (10) to reﬂect the
fact that time points are considered rather than intervals. We observed that experiment with such a formulation was unable to ﬁnish within 5 hours (we terminated the ILP inference after waiting for 5 hours),
whereas our interval-based model ﬁnished the experiment with an average of 21 seconds per article.

6

Related Work

Research in temporal reasoning recently received
much attention. Allen (1983) introduced an interval
based temporal logic which has been used widely
in the ﬁeld. Recent efforts in building an annotated
temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for
the task (Mani et al., 2006; Bethard et al., 2007).
This corpus was later used (with simpliﬁcations) in
two TempEval challenges (Verhagen et al., 2007;
Verhagen et al., 2010). In these challenges, several
temporal-related tasks were deﬁned including the
tasks of identifying the temporal relation between an
event mention and a temporal expression in the same
sentence, and recognizing temporal relations of pairs
of event mentions in adjacent sentences. However,
with several restrictions imposed to these tasks, the
developed systems were not practical.
Recently, there has been much work attempting
to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008)
used global relational constraints to not only expand
the training data but also identiﬁes temporal inconsistencies to improve local classiﬁers. They used
greedy search to select the most appropriate conﬁguration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et
al. (2006), Chambers and Jurafsky (2008), Denis
and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP.
However, the inference models in their work were
not a joint model involving multiple local classiﬁers
but only one local classiﬁer was involved in their objective functions.
The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Net-

work (MLN). They, however, used the same setting
as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are
considered. Our work, on the other hand, focuses on
constructing an event timeline with time intervals,
taking multiple local pairwise predictions into a joint
inference model and removing the restrictions on the
positions of the temporal entities. Furthermore, we
propose for the ﬁrst time to use event coreference
and evaluate the importance of its role in the task of
event timeline construction.

7

Conclusions and Future Work

We proposed an interval-based representation of the
timeline of event mentions in an article. Our representation allowed us to formalize the joint inference model that can be solved efﬁciently, compared
to a time point-based inference model, thus opening up the possibility of building more practical
event temporal inference systems. Our inference
model achieved signiﬁcant improvement over the local classiﬁers. We also showed that event coreference can naturally support timeline construction,
and good event coreference led to signiﬁcant improvement in the system performance. Speciﬁcally,
when such gold event coreference knowledge was
injected into the model, a signiﬁcant improvement
in the overall performance could be obtained. While
our experiments suggest that the temporal classiﬁers can potentially help enhance the performance
of event coreference, in future work we would like
to investigate into coupling event coreference with
other components in a global inference framework.

Acknowledgments
The authors gratefully acknowledge the support
of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air
Force Research Laboratory (AFRL) prime contract
No. FA8750-09-C-0181, and the Army Research
Laboratory (ARL) under agreement W911NF-09-20053. The ﬁrst author also thanks the Vietnam Education Foundation (VEF) for its sponsorship. Any
opinions, ﬁndings, and conclusion or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the view of the
VEF, DARPA, AFRL, ARL, or the US government.

References
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the ACM.
Steven Bethard, James H. Martin, and Sara Klingenstein.
2007. Timelines from text: Identiﬁcation of syntactic
temporal relations. In ICSC.
P. Bramsen, P. Deshpande, Y. K. Lee, and R. Barzilay.
2006. Inducing temporal graphs. In EMNLP.
N. Chambers and D. Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering.
In EMNLP.
Zheng Chen, Heng Ji, and Robert Haralick. 2009. A
pairwise event coreference model, feature impact and
evaluation for event coreference resolution. In Workshop on Events in Emerging Text Types.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear programming
approach. Journal of Artiﬁcial Intelligence Research.
Pascal Denis and Philippe Muller. 2011. Predicting
globally-coherent temporal structures from texts via
endpoint inference and graph decomposition. In IJCAI.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
Yoav Freund and Robert E. Schapire. 1999. Large margin classiﬁcation using the perceptron algorithm. Machine Learning.
Philipp Koehn. 2004. Statistical signiﬁcance tests for
machine translation evaluation. In EMNLP.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In ACL.
J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas,
A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro,
and M. Lazo. 2003. The TIMEBANK corpus. In
Corpus Linguistics.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identiﬁcation via a linear programming
formulation. In Introduction to Statistical Relational
Learning.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts. In
WSDM.
Marta Tatu and Munirathnam Srikanth. 2008. Experiments with reasoning for temporal relations between
events. In COLING.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 task 15: Tempeval temporal relation identiﬁcation. In SemEval-2007.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In SemEval-2010.

Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asahara, and Yuji Matsumoto. 2009. Jointly identifying temporal relations with markov logic. In ACLIJCNLP.
Ran Zhao, Quang Do, and Dan Roth. 2012. A robust
shallow temporal reasoning system. In NAACL-HLT
Demo.

