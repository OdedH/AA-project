Parsing with Treebank Grammars: Empirical Bounds, Theoretical
Models, and the Structure of the Penn Treebank
Dan Klein and Christopher D. Manning
Computer Science Department
Stanford University
Stanford, CA 94305-9040
klein, manning @cs.stanford.edu

The parameters we varied were:
Tree Transforms: N OT RANSFORM, N O E MPTIES,
N O U NARIES H IGH, and N O U NARIES L OW.
Grammar Rule Encodings: L IST, T RIE, or M IN




Rule Introduction: T OP D OWN or B OTTOM U P

The default settings are shown above in bold face.
We do not discuss all possible combinations of these
settings. Rather, we take the bottom-up parser using an
untransformed grammar with trie rule encodings to be
the basic form of the parser. Except where noted, we
will discuss how each factor affects this baseline, as
most of the effects are orthogonal. When we name a
setting, any omitted parameters are assumed to be the
defaults.
2.1

Tree Transforms

In all cases, the grammar was directly induced from
(transformed) Penn treebank trees. The transforms
used are shown in ﬁgure 1. For all settings, functional tags and crossreferencing annotations were
stripped. For N OT RANSFORM, no other modiﬁcation
was made. In particular, empty nodes (represented as
- NONE - in the treebank) were turned into rules that
generated the empty string ( ), and there was no collapsing of categories (such as PRT and ADVP) as is often done in parsing work (Collins, 1997, etc.). For



This paper originated from examining the empirical
performance of an exhaustive active chart parser using an untransformed treebank grammar over the Penn
Treebank. Our initial experiments yielded the surprising result that for many conﬁgurations empirical
parsing speed was super-cubic in the sentence length.
This led us to look more closely at the structure of
the treebank grammar. The resulting analysis builds
on the presentation of Charniak (1996), but extends
it by elucidating the structure of non-terminal interrelationships in the Penn Treebank grammar. On the
basis of these studies, we build simple theoretical
models which closely predict observed parser performance, and, in particular, explain the originally observed super-cubic behavior.
We used treebank grammars induced directly from
the local trees of the entire WSJ section of the Penn
Treebank (Marcus et al., 1993) (release 3). For each
length and parameter setting, 25 sentences evenly distributed through the treebank were parsed. Since we
were parsing sentences from among those from which
our grammar was derived, coverage was never an is-

2 Parameters



1 Introduction

sue. Every sentence parsed had at least one parse – the
parse with which it was originally observed.1
The sentences were parsed using an implementation of the probabilistic chart-parsing algorithm presented in (Klein and Manning, 2001). In that paper,
we present a theoretical analysis showing an
worst-case time bound for exhaustively parsing arbitrary context-free grammars. In what follows, we do
not make use of the probabilistic aspects of the grammar or parser.

©§ £
¨¦¥¤¢

 

This paper presents empirical studies and
closely corresponding theoretical models of
the performance of a chart parser exhaustively parsing the Penn Treebank with the
Treebank’s own CFG grammar. We show
how performance is dramatically affected by
rule representation and tree transformations,
but little by top-down vs. bottom-up strategies. We discuss grammatical saturation, including analysis of the strongly connected
components of the phrasal nonterminals in
the Treebank, and model how, as sentence
length increases, the effective grammar rule
size increases as regions of the grammar
are unlocked, yielding super-cubic observed
time behavior in some conﬁgurations.

¡

Abstract

1
Effectively “testing on the training set” would be invalid
if we wished to present performance results such as precision
and recall, but it is not a problem for the present experiments,
which focus solely on the parser load and grammar structure.

TOP

TOP

TOP

TOP

S-HLN

S

S

360

TOP

S

VP

NP

VP

VP

-NONE-

VB

-NONE-

VB

VB



Atone



Atone

Atone

Atone

Atone

(c)

(d)

Avg. Time (seconds)

300

NP-SBJ

(e)

(a)

(b)

List-NoTransform
exp 3.54 r 0.999
Trie-NoTransform
exp 3.16 r 0.995
Trie-NoEmpties
exp 3.47 r 0.998
Trie-NoUnariesHigh
exp 3.67 r 0.999
Trie-NoUnariesLow
exp 3.65 r 0.999
Min-NoTransform
exp 2.87 r 0.998
Min-NoUnariesLow
exp 3.32 r 1.000

VB

240
180
120
60
0

Figure 1: Tree Transforms: (a) The raw tree, (b) N O T RANSFORM, (c) N O E MPTIES, (d) N O U NARIES H IGH (e) N O U NARIES L OW
NNS
NNP

NNS

40

50

Figure 3: The average time to parse sentences using
various parameters.

NNP

NNP

NN

JJ

NNS

NNP

CD

NN

JJ

NNS

DT

DT

NNS

CC

JJ

NP

NP

CC
PP
SBAR

QP

NP

NN

CC

NP
PP

In this section, we outline the observed performance
of the parser for various settings. We frequently speak
in terms of the following:

NNS

NP

PP
SBAR

NN
PRP

NP
NP

NNS
JJ

NN

SBAR
NN

NNS

span: a range of words in the chart, e.g., [1,3]4
edge: a category over a span, e.g., NP:[1,3]
traversal: a way of making an edge from an
active and a passive edge, e.g., NP:[1,3]
(NP DT. NN :[1,2] + NN :[2,3])

PRP
NN

QP

NNS



NN
PRP
QP

N O E MPTIES, empties were removed by pruning nonterminals which covered no overt words. For N O U NA RIES H IGH , and N O U NARIES L OW , unary nodes were
removed as well, by keeping only the tops and the bottoms of unary chains, respectively.2
2.2

Grammar Rule Encodings

The parser operates on Finite State Automata (FSA)
grammar representations. We compiled grammar
rules into FSAs in three ways: L ISTs, T RIEs, and
M INimized FSAs. An example of each representation is given in ﬁgure 2. For L IST encodings, each
local tree type was encoded in its own, linearly structured FSA, corresponding to Earley (1970)-style dotted rules. For T RIE, there was one FSA per category, encoding together all rule types producing that
category. For M IN, state-minimized FSAs were constructed from the trie FSAs. Note that while the rule
encoding may dramatically affect the efﬁciency of a
parser, it does not change the actual set of parses for a
given sentence in any way.3
2

In no case were the nonterminal-to-word or TOP-tononterminal unaries altered.
3
FSAs are not the only method of representing and compacting grammars. For example, the preﬁx compacted tries
we use are the same as the common practice of ignoring
items before the dot in a dotted rule (Moore, 2000). Another

3.1

Time

The parser has an
theoretical time bound,
where is the number of words in the sentence to be
parsed, is the number of nonterminal categories in
the grammar and is the number of (active) states in
the FSA encoding of the grammar. The time bound
is derived from counting the number of traversals processed by the parser, each taking
time.
In ﬁgure 3, we see the average time5 taken per sentence length for several settings, with the empirical exponent (and correlation -value) from the best-ﬁt simple power law model to the right. Notice that most
settings show time growth greater than
.
Although,
is simply an asymptotic bound,
there are good explanations for the observed behavior. There are two primary causes for the super-cubic
time values. The ﬁrst is theoretically uninteresting.
The parser is implemented in Java, which uses garbage
collection for memory management. Even when there
is plenty of memory for a parse’s primary data structures, “garbage collection thrashing” can occur when

© § %¥¤¢
£

Figure 2: Grammar Encodings: FSAs for a subset of
the rules for the category NP. Non-black states are
active, non-white states are accepting, and bold transitions are phrasal.

$

M IN

©!£
#"¤¢

T RIE

¥

L IST

© § %¥¤¢
£

NN

NN

NN
NN

NNS
JJ

NP

3 Observed Performance

NNS
CD

NN



NN

DT
DT

NN



NN

© § ¥ ¤¢
 £

NN

DT



CD

DT

NNP
NN

CD



NNS

30



JJ

20

Sentence Length

NNP
NN

10



NNP
JJ

0

logical possibility would be trie encodings which compact
the grammar states by common sufﬁx rather than common
preﬁx, as in (Leermakers, 1992). The savings are less than
for preﬁx compaction.
4
Note that the number of words (or size) of a span is equal
to the difference between the endpoints.
5
The hardware was a 700 MHz Intel Pentium III, and we
used up to 2GB of RAM for very long sentences or very
poor parameters. With good parameter settings, the system
can parse 100+ word treebank sentences.

20.0M

20.0M

1.002

5.0M

List
exp 2.60 r 0.999
Trie
exp 2.86 r 1.000

10.0M

Min
exp 2.78 r 1.000
5.0M

1.000
Ratio (TD/BU)

10.0M

15.0M
Avg. Traversals

Avg. Traversals

1.001
NoTransform
exp 2.86 r 1.000
NoEmpties
exp 3.28 r 1.000
NoUnariesHigh
exp 3.74 r 0.999
NoUnariesLow
exp 3.83 r 0.999

15.0M

0.999
Edges
Traversals

0.998
0.997
0.996
0.995

0.0M

0.0M

0

10

20

30

40

50

0.994
0

10

20

30

Sentence Length

0

50

10

20

30

40

50

Sentence Length

Sentence Length

(a)

40

(b)

(c)

Figure 4: (a) The number of traversals for different grammar transforms. (b) The number of traversals for different
grammar encodings. (c) The ratio of the number of edges and traversals produced with a top-down strategy over
the number produced with a bottom-up strategy (shown for T RIE -N OT RANSFORM, others are similar).
parsing longer sentences as temporary objects cause
increasingly frequent reclamation. To see past this effect, which inﬂates the empirical exponents, we turn to
the actual traversal counts, which better illuminate the
issues at hand. Figures 4 (a) and (b) show the traversal
curves corresponding to the times in ﬁgure 3.
The interesting cause of the varying exponents
comes from the “constant” terms in the theoretical
bound. The second half of this paper shows how
modeling growth in these terms can accurately predict
parsing performance (see ﬁgures 9 to 13).

transform is chosen, there will be NP nodes missing
from the parses, making the parses less useful for any
task requiring NP identiﬁcation. For the remainder of
the paper, we will focus on the settings N OT RANS FORM and N O E MPTIES .

3.2

Figure 4 (c) shows the effect on total edges and
traversals of using top-down and bottom-up strategies.
There are some extremely minimal savings in traversals due to top-down ﬁltering effects, but there is a corresponding penalty in edges as rules whose left-corner
cannot be built are introduced. Given the highly unrestrictive nature of the treebank grammar, it is not very
surprising that top-down ﬁltering provides such little
beneﬁt. However, this is a useful observation about
real world parsing performance. The advantages of
top-down chart parsing in providing grammar-driven
prediction are often advanced (e.g., Allen 1995:66),
but in practice we ﬁnd almost no value in this for broad
coverage CFGs. While some part of this is perhaps
due to errors in the treebank, a large part just reﬂects
the true nature of broad coverage grammars: e.g., once
you allow adverbial phrases almost anywhere and allow PPs, (participial) VPs, and (temporal) NPs to be
adverbial phrases, along with phrases headed by adverbs, then there is very little useful top-down control
left. With such a permissive grammar, the only real
constraints are in the POS tags which anchor the local
trees (see section 4.3). Therefore, for the remainder of
the paper, we consider only bottom-up settings.

© ' ¥ £
¨&¤¢

753
8642

© ' ¥ £ ¢ )
¨&¤10(

©'¥ £
¨&9¤¢

©' £
@¨¥ 9¤¢





2

3.3

Tree Transforms

Figure 4 (a) shows the effect of the tree transforms on
traversal counts. The N O U NARIES settings are much
more efﬁcient than the others, however this efﬁciency
comes at a price in terms of the utility of the ﬁnal
parse. For example, regardless of which N O U NARIES
6

A standard chart parser might conceivably require stortraversals on its agenda, but ours proving more than
ably never does.
7
This count is the number of phrasal categories with the
introduction of a TOP label for the unlabeled top treebank
nodes.

3.5

Top-Down vs. Bottom-Up

4 Models
In the remainder of the paper we provide simple models that nevertheless accurately capture the varying
magnitudes and exponents seen for different grammar
encodings and tree transformations. Since the
term
of
comes directly from the number of start,

© § ¥ ¤¢
 £

. Since
The memory bound for the parser is
the parser is running in a garbage-collected environment, it is hard to distinguish required memory from
utilized memory. However, unlike time and traversals
which in practice can diverge, memory requirements
match the number of edges in the chart almost exactly,
since the large data structures are all proportional in
size to the number of edges
.6
for
Almost all edges stored are active edges (
sentences longer than 30 words), of which there can be
: one for every grammar state and span. Pas, one for evsive edges, of which there can be
ery category and span, are a shrinking minority. This
is because, while is bounded above by 27 in the treebank7 (for spans 2), numbers in the thousands (see
ﬁgure 12). Thus, required memory will be implicitly
modeled when we model active edges in section 4.3.

Grammar Encodings

§¥

Memory

3.4

Figure 4 (b) shows the effect of each tree transform on
traversal counts. The more compacted the grammar
representation, the more time-efﬁcient the parser is.

E B
F¦DCA

split, and end points for traversals, it is certainly not
responsible for the varying growth rates. An initially
plausible possibility is that the quantity bounded by
the term is non-constant in in practice, because
longer spans are more ambiguous in terms of the number of categories they can form. This turns out to
be generally false, as discussed in section 4.2. Alternately, the effective term could be growing with ,
which turns out to be true, as discussed in section 4.3.
The number of (possibly zero-size) spans for a sen. Thus,
tence of length is ﬁxed:
to be able to evaluate and model the total edge counts,
we look to the number of edges over a given span.

¥



ADVP
PP
SBARQ
WHADVP

FRAG
PRN
SINV
WHNP

INTJ
QP
SQ
WHPP

NAC
RRC
TOP
X

NP
S
UCP

Figure 5: The empty-reachable set for the N OT RANS FORM grammar.
TOP

¥



RU©R G £©! G
TVTSQ¦¥PIH%¥£

¥

Deﬁnition 1 The passive (or active) saturation of a
given span is the number of passive (or active) edges
over that span.
In the total time and traversal bound
, the
effective value of is determined by the active saturation, while the effective value of is determined by
the passive saturation. An interesting fact is that the
saturation of a span is, for the treebank grammar and
sentences, essentially independent of what size sentence the span is from and where in the sentence the
span begins. Thus, for a given span size, we report the
average over all spans of that size occurring anywhere
in any sentence parsed.

© § ¥ ¤¢
 £

ADJP ADVP
FRAG INTJ NAC
NP NX PP PRN QP
RRC S SBAR SBARQ
SINV SQ UCP VP
WHNP X

LST

PRT

WHPP

CONJP
WHADJP

WHADVP

Figure 6: The same-span reachability graph for the
N OT RANSFORM grammar.
TOP





4.1

ADJP
NX
SBAR
VP

SQ

X

NX

RRC
LST
ADJP ADVP
FRAG INTJ NP
PP PRN QP S
SBAR UCP VP
WHNP

CONJP
NAC

PRT

SINV
SBARQ

WHADJP

Treebank Grammar Structure

WHPP

WHADVP





is empty-reachable in a
Deﬁnition 2 A category
grammar
if
can be built using only empty terminals.

W

W

X

The empty-reachable set for the N OT RANSFORM
grammar is shown in ﬁgure 5.8 These 23 categories
plus the tag - NONE - create a passive saturation of 24
for zero-spans for N OT RANSFORM (see ﬁgure 9).
Deﬁnition 3 A category
is same-span-reachable
from a category in a grammar if can be built
from using a parse tree in which, aside from at most

Y

X

Y

W

W

8

The set of phrasal categories used in the Penn Treebank is documented in Manning and Sch¨ tze (1999, 413);
u
Marcus et al. (1993, 281) has an early version.

Figure 7: The same-span-reachability graph for the
N O E MPTIES grammar.
one instance of , every node not dominating that instance is an instance of an empty-reachable category.

W

The reason that effective growth is not found in the
component is that passive saturation stays almost
constant as span size increases. However, the more interesting result is not that saturation is relatively constant (for spans beyond a small, grammar-dependent
size), but that the saturation values are extremely large
compared to (see section 4.2). For the N OT RANS FORM and N O E MPTIES grammars, most categories
are reachable from most other categories using rules
which can be applied over a single span. Once you get
one of these categories over a span, you will get the
rest as well. We now formalize this.

The same-span-reachability relation induces a graph
over the 27 non-terminal categories. The stronglyconnected component (SCC) reduction of that graph is
shown in ﬁgures 6 and 7.9 Unsurprisingly, the largest
SCC, which contains most “common” categories (S,
NP, VP, PP, etc.) is slightly larger for the N OT RANS FORM grammar, since the empty-reachable set is nonempty. However, note that even for N OT RANSFORM,
the largest SCC is smaller than the empty-reachable
set, since empties provide direct entry into some of the
lower SCCs, in particular because of WH-gaps.
Interestingly, this same high-reachability effect occurs even for the N O U NARIES grammars, as shown in
the next section.
4.2

Passive Edges

The total growth and saturation of passive edges is relatively easy to describe. Figure 8 shows the total num9
Implied arcs have been removed for clarity. The relation
is in fact the transitive closure of this graph.

30.0K

30.0K

25.0K
NoTransform
exp 1.84 r 1.000
NoEmpties
exp 1.97 r 1.000
NoUnariesHigh
exp 2.13 r 1.000
NoUnariesLow
exp 2.21 r 0.999

20.0K
15.0K
10.0K

Avg. Passive Totals

Avg. Passive Totals

25.0K

NoTransform
exp 1.84 r 1.000
NoEmpties
exp 1.95 r 1.000
NoUnariesHigh
exp 2.08 r 1.000
NoUnariesLow
exp 2.20 r 1.000

20.0K
15.0K
10.0K
5.0K

5.0K

0.0K

0.0K
0

10

20

30

40

0

50

10

20

30

40

50

Sentence Length

Sentence Length

Figure 8: The average number of passive edges processed in practice (left), and predicted by our models (right).
30

25

25

20

Avg. Passive Saturation

Avg. Passive Saturation

30

NoTransform
NoEmpties
NoUnariesHigh
NoUnariesLow

15
10
5

20

NoTransform
NoEmpties
NoUnariesHigh
NoUnariesLow

15
10
5
0

0
0

1

2

3

4

5

6

7

8

9

0

10

1

2

3

4

5

6

7

8

9

10

Span Size

Span Size

Figure 9: The average passive saturation (number of passive edges) for a span of a given size as processed in
practice (left), and as predicted by our models (right).

ed ca
f6#b`

gd ca
V6#b`

d ca © y ! G
st r ) © £ d i d
t 6#b`pxw¦¥£ e vu1Sq%¥Pph`

The maximum possible passive saturation for any span
greater than one is equal to the number of phrasal categories
in the treebank grammar: 27. However, empty and size-one
spans can additionally be covered by POS tag edges.

We correctly predict that the passive edge total exponents will be slightly less than 2.0 when unaries are
present, and greater than 2.0 when they are not. With
unaries, the linear terms in the reduced equation are
signiﬁcant over these sentence lengths and drag down
the exponent. The linear terms are larger for N O T RANSFORM and therefore drag the exponent down
more.11 Without unaries, the more gradual saturation growth increases the total exponent, more so for
N O U NARIES L OW than N O U NARIES H IGH. However,
note that for spans around 8 and onward, the saturation
curves are essentially constant for all settings.
4.3

Active Edges

Active edges are the vast majority of edges and essentially determine (non-transient) memory requirements.
While passive counts depend only on the grammar
transform, active counts depend primarily on the encoding for general magnitude but also on the transform
for the details (and exponent effects). Figure 10 shows
the total active edges by sentence size for three settings chosen to illustrate the main effects. Total active
growth is sub-quadratic for L IST, but has an exponent
of up to about 2.4 for the T RIE settings.
11

Note that, over these values of , even a basic quadratic
function like the simple sum
has a bestﬁt simple power curve exponent of only
for the same
reason. Moreover, note that
has a higher best-ﬁt exponent, yet will never actually outgrow it.

gfm
#e
l j
k ih
g f E  B 
ed¤ r


' 6#b`
dca

10

The predictions are shown in ﬁgure 8. For the N O T RANSFORM or N O E MPTIES settings, this reduces to:

ed ca © ! G £ G gd ca © £ d ca    ) © £d id
f8#`%¥1V8#¦`q¦¥xG ' 8b` s "g ' s q¦¥Pp`

ber of passive edges by sentence length, and ﬁgure 9
shows the saturation as a function of span size.10 The
grammar representation does not affect which passive
edges will occur for a given span.
The large SCCs cause the relative independence of
passive saturation from span size for the N OT RANS FORM and N O E MPTIES settings. Once any category in
the SCC is found, all will be found, as well as all categories reachable from that SCC. For these settings, the
passive saturation can be summarized by three satura, one-spans
tion numbers: zero-spans (empties)
, and all larger spans (categories)
.
(words)
Taking averages directly from the data, we have our
ﬁrst model, shown on the right in ﬁgure 9.
For the N O U NARIES settings, there will be no
same-span reachability and hence no SCCs. To reach
a new category always requires the use of at least one
overt word. However, for spans of size 6 or so, enough
words exist that the same high saturation effect will
still be observed. This can be modeled quite simply
by assuming each terminal unlocks a ﬁxed fraction of
the nonterminals, as seen in the right graph of ﬁgure 9,
but we omit the details here.
Using these passive saturation models, we can directly estimate the total passive edge counts by summation:

2.0M

1.5M
List-NoTransform
exp 1.88 r 0.999
Trie-NoTransform
exp 2.18 r 0.999

1.0M

Trie-NoEmpties
exp 2.43 r 0.999
0.5M

Avg. Active Totals

Avg. Active Totals

2.0M

0.0M

1.5M

List-NoTransform
exp 1.81 r 0.999
Trie-NoTransform
exp 2.10 r 1.000

1.0M

Trie-NoEmpties
exp 2.36 r 1.000
0.5M

0.0M
0

10

20

30

40

50

0

10

20

Sentence Length

30

40

50

Sentence Length

Figure 10: The average number of active edges for sentences of a given length as observed in practice (left), and
as predicted by our models (right).
12.0K

10.0K
List-NoTransform
exp 0.092 r 0.957
Trie-NoTransform
exp 0.323 r 0.999

8.0K
6.0K

Trie-NoEmpties
exp 0.389 r 0.997

4.0K

Avg. Active Saturation

14.0K

12.0K
Avg. Active Saturation

14.0K

10.0K

6.0K

List-NoTransform
exp 0.111 r 0.999
Trie-NoTransform
exp 0.297 r 0.998

4.0K

Trie-NoEmpties
exp 0.298 r 0.991

8.0K

2.0K

2.0K

0.0K

0.0K
0

5

10

15

0

20

5

10

Span Length

15

20

Span Length

Figure 11: The average active saturation (number of active edges) for a span of a given size as processed in
practice (left), and as predicted by our models (right).

c

n

n

`

a

a

To model the active totals, we again begin by modeling the active saturation curves, shown in ﬁgure 11.
The active saturation for any span is bounded above by
, the number of active grammar states (states in the
grammar FSAs which correspond to active edges). For
list grammars, this number is the sum of the lengths of
all rules in the grammar. For trie grammars, it is the
number of unique rule preﬁxes (including the LHS)
in the grammar. For minimized grammars, it is the
number of states with outgoing transitions (non-black
states in ﬁgure 2). The value of is shown for each
setting in ﬁgure 12. Note that the maximum number of
active states is dramatically larger for lists since common rule preﬁxes are duplicated many times. For minimized FSAs, the state reduction is even greater. Since
states which are earlier in a rule are much more likely
to match a span, the fact that tries (and min FSAs)
compress early states is particularly advantageous.
Unlike passive saturation, which was relatively
close to its bound , active saturation is much farther
below . Furthermore, while passive saturation was
relatively constant in span size, at least after a point,
active saturation quite clearly grows with span size,
even for spans well beyond those shown in ﬁgure 11.
We now model these active saturation curves.
What does it take for a given active state to match a
given span? For T RIE and L IST, an active state cor-

n

Figure 12: Grammar sizes: active state counts.

responds to a preﬁx of a rule and is a mix of POS
tags and phrasal categories, each of which must be
matched, in order, over that span for that state to be
reached. Given the large SCCs seen in section 4.1,
phrasal categories, to a ﬁrst approximation, might as
well be wildcards, able to match any span, especially
if empties are present. However, the tags are, in comparison, very restricted. Tags must actually match a
word in the span.
More precisely, consider an active state in the
grammar and a span . In the T RIE and L IST encodings, there is some, possibly empty, list of labels
that must be matched over before an active edge with
this state can be constructed over that span.12 Assume
that the phrasal categories in can match any span
(or any non-zero span in N O E MPTIES).13 Therefore,
phrasal categories in do not constrain whether can
match . The real issue is whether the tags in will
match words in . Assume that a random tag matches a
random word with a ﬁxed probability , independently
of where the tag is in the rule and where the word is in
the sentence.14 Assume further that, although tags occur more often than categories in rules (63.9% of rule
items are tags in the N OT RANSFORM case15 ), given a

a

N O UL OW
100818
22026
3250

a

N O UH IGH
81287
17778
2817

n

N O E MPTIES
78233
17011
2610

c

N OT RANS
80120
17298
2631

L IST
T RIE
M IN

12
The essence of the M IN model, which is omitted here,
is that states are represented by the “easiest” label sequence
which leads to that state.
13
The model for the N O U NARIES cases is slightly more
complex, but similar.
14
This is of course false; in particular, tags at the end of
rules disproportionately tend to be punctuation tags.
15
Although the present model does not directly apply to
the N O U NARIES cases, N O U NARIES L OW is signiﬁcantly









d¥ui
vPo


d

d

o




These active saturation curves produce the active total curves in ﬁgure 10, which are also qualitatively correct in both magnitudes and exponents.
4.4

Traversals

Now that we have models for active and passive edges,
we can combine them to model traversal counts as
well. We assume that the chance for a passive edge
and an active edge to combine into a traversal is a single probability representing how likely an arbitrary active state is to have a continuation with a label matching an arbitrary passive state. List rule states have only
one continuation, while trie rule states in the branch17

In general, the we used was lower for not having modeled tagging ambiguity, but higher for not having modeled
the fact that the SCCs are not of size 27.
18
And does so without any “tweakable” parameters.
19
Note that the list curves do not compellingly suggest a
power law model.



a
c
a
c
©xwte¦d£
o
c
©¨%p£PvuPo p
d¥ i
©o
Vte¦d£s)rq%cp
© £
d

c

a

a

c

o

c

n

d

y
h`

a

d

d

c



¥

¥

`

s zpd¨!
© ` y !£ y

¥



 ¥ od c  ~ (© £d ¥ uio | r ) © £d ca
©qVt%c£xp8z%£  ¨| Fp¨9pPvP}xx{q%¥P6#qc
© £dca
q%¥P8qc

more efﬁcient than N O U NARIES H IGH despite having more
active states, largely because using the bottoms of chains increases the frequency of tags relative to categories.
16
This is also false; tags occur slightly more often at the
beginnings of rules and less often at the ends.

This model has two parameters. First, there is which
we estimated directly by looking at the expected match
between the distribution of tags in rules and the distribution of tags in the Treebank text (which is around
1/17.7). No factor for POS tag ambiguity was used,
another simpliﬁcation.17 Second, there is the map
from signatures to a number of active states,
which was read directly from the compiled grammars.
This model predicts the active saturation curves
shown to the right in ﬁgure 11. Note that the model,
though not perfect, exhibits the qualitative differences
between the settings, both in magnitudes and exponents.18 In particular:
The transform primarily changes the saturation over
short spans, while the encoding determines the overall magnitudes. For example, in T RIE -N O E MPTIES
the low-span saturation is lower than in T RIE N OT RANSFORM since short spans in the former
case can match only signatures which have both
and small, while in the latter only needs to be
small. Therefore, the several hundred states which
are reachable only via categories all match every
span starting from size 0 for N OT RANSFORM, but
are accessed only gradually for N O E MPTIES. However, for larger spans, the behavior converges to
counts characteristic for T RIE encodings.
For L IST encodings, the early saturations are huge,
due to the fact that most of the states which are
available early for trie grammars are precisely the
ones duplicated up to thousands of times in the list
grammars. However, the additive gain over the initial states is roughly the same for both, as after a few
items are speciﬁed, the tries become sparse.
The actual magnitudes and exponents19 of the saturations are surprisingly well predicted, suggesting
that this model captures the essential behavior.

`

ﬁxed number of tags and categories, all permutations
are equally likely to appear as rules.16
Under these assumptions, the probability that an active state is in the treebank grammar will depend
only on the number of tags and of categories in
. Call this pair
the signature of . For
a given signature , let
be the number of active states in the grammar which have that signature.
Now, take a state of signature
and a span .
If we align the tags in with words in and align
the categories in with spans of words in , then provided the categories align with a non-empty span (for
N O E MPTIES) or any span at all (for N OT RANSFORM),
then the question of whether this alignment of with
matches is determined entirely by the tags. However,
with our assumptions, the probability that a randomly
chosen set of tags matches a randomly chosen set of
words is simply .
We then have an expression for the chance of matching a speciﬁc alignment of an active state to a speciﬁc
span. Clearly, there can be many alignments which
differ only in the spans of the categories, but line up the
same tags with the same words. However, there will be
a certain number of unique ways in which the words
and tags can be lined up between and . If we know
this number, we can calculate the total probability that
there is some alignment which matches. For example,
consider the state NP
NP CC NP . PP (which has
signature (1,2) – the PP has no effect) over a span of
length , with empties available. The NPs can match
any span, so there are alignments which are distinct
from the standpoint of the CC tag – it can be in any
position. The chance that some alignment will match
is therefore
, which, for small is roughly
linear in . It should be clear that for an active state
like this, the longer the span, the more likely it is that
this state will be found over that span.
It is unfortunately not the case that all states
with the same signature will match a span length
with the same probability. For example, the state
NP NP CC . NP has the same signature, but must
NP
align the CC with the ﬁnal element of the span. A state
like this will not become more likely (in our model) as
span size increases. However, with some straightforward but space-consuming recurrences, we can calculate the expected chance that a random rule of a given
signature will match a given span length. Since we
know how many states have a given signature, we can
calculate the total active saturation
as

20.0M

20.0M

15.0M
List-NoTransform
exp 2.60 r 0.999
Trie-NoTransform
exp 2.86 r 1.000

10.0M

Trie-NoEmpties
exp 3.28 r 1.000

Avg. Traversals

Avg. Traversals

15.0M

List-NoTransform
exp 2.60 r 0.999
Trie-NoTransform
exp 2.92 r 1.000

10.0M

Trie-NoEmpties
exp 3.47 r 1.000
5.0M

5.0M

0.0M

0.0M
0

10

20

30

40

0

50

10

20

30

40

50

Sentence Length

Sentence Length

Figure 13: The average number of traversals for sentences of a given length as observed in practice (left), and as
predicted by the models presented in the latter part of the paper (right).

For L IST, the observed exponent is lower than for
T RIEs, though the total number of traversals is dramatically higher. This is because the active saturation is growing much faster for T RIEs; note that in
cases like this the lower-exponent curve will never
actually outgrow the higher-exponent curve.
Of the settings shown, only T RIE -N O E MPTIES
exhibits super-cubic traversal totals.
Despite
their similar active and passive exponents, T RIE N O E MPTIES and T RIE -N OT RANSFORM vary in
traversal growth due to the “early burst” of active
edges which gives T RIE -N OT RANSFORM signiﬁcantly more edges over short spans than its power
law would predict. This excess leads to a sizeable
quadratic addend in the number of transitions, causing the average best-ﬁt exponent to drop without
greatly affecting the overall magnitudes.




Overall, growth of saturation values in span size increases best-ﬁt traversal exponents, while early spikes
in saturation reduce them. The traversal exponents
therefore range from L IST-N OT RANSFORM at 2.6 to
T RIE -N O U NARIES L OW at over 3.8. However, the ﬁnal performance is more dependent on the magnitudes,
which range from L IST-N OT RANSFORM as the worst,
despite its exponent, to M IN -N O U NARIES H IGH as the
best. The single biggest factor in the time and traversal performance turned out to be the encoding, which
is fortunate because the choice of grammar transform
will depend greatly on the application.
20

This is a simpliﬁcation as well, since the shorter preﬁxes
that tend to have higher continuation degrees are on average
also a larger fraction of the active edges.

5 Conclusion
We built simple but accurate models on the basis of
two observations. First, passive saturation is relatively
constant in span size, but large due to high reachability
among phrasal categories in the grammar. Second, active saturation grows with span size because, as spans
increase, the tags in a given active edge are more likely
to ﬁnd a matching arrangement over a span. Combining these models, we demonstrated that a wide range
of empirical qualitative and quantitative behaviors of
an exhaustive parser could be derived, including the
potential super-cubic traversal growth over sentence
lengths of interest.

References
James Allen. 1995. Natural Language Understanding. Benjamin Cummings, Redwood City, CA.
Eugene Charniak. 1996. Tree-bank grammars. In
Proceedings of the Thirteenth National Conference
on Artiﬁcial Intelligence, pages 1031–1036.
Michael John Collins. 1997. Three generative, lexicalised models for statistical parsing. In ACL
35/EACL 8, pages 16–23.
Jay Earley. 1970. An efﬁcient context-free parsing algorithm. Communications of the ACM, 6:451–455.
Dan Klein and Christopher D. Manning. 2001. An
agenda-based chart parser for arbitrary probabilistic context-free grammars. Technical Report
dbpubs/2001-16, Stanford University.
R. Leermakers. 1992. A recursive ascent Earley
parser. Information Processing Letters, 41:87–91.
Christopher D. Manning and Hinrich Sch¨ tze. 1999.
u
Foundations of Statistical Natural Language Processing. MIT Press, Boston, MA.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn treebank. Computational Linguistics, 19:313–330.
Robert C. Moore. 2000. Improved left-corner chart
parsing for large context-free grammars. In Proceedings of the Sixth International Workshop on
Parsing Technologies.

© § ¦¥¤¢
£

ing portion of the trie average about 3.7 (min FSAs
4.2).20 Making another uniformity assumption, we assume that this combination probability is the continuation degree divided by the total number of passive
labels, categorical or tag (73).
In ﬁgure 13, we give graphs and exponents of the
traversal counts, both observed and predicted, for various settings. Our model correctly predicts the approximate values and qualitative facts, including:

