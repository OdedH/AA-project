A Probabilistic Approach to Diachronic Phonology

Alexandre Bouchard-Cˆt´
oe
Tom Griﬃths

Percy Liang

Dan Klein

Languages evolve

Gloss
Word/verb
Fruit
Laugh
Center
August
Swim

Latin
verbum
fructus
ridere
centrum
augustus
natare

Italian
verbo
frutta
ridere
centro
agosto
nuotare
.
.

Spanish
verbo
fruta
reir
centro
agosto
nadar

Portuguese
verbu
fruta
rir
centro
agosto
nadar

Language evolution

Gloss
Word/verb
Fruit
Laugh
Center
August
Swim

Latin
verbum
fructus
ridere
centrum
augustus
natare

Italian
verbo
frutta
ridere
centro
agosto
nuotare
.
.

• Phonological rules more regular than
morphological or syntactic ones
• basis of the comparative method

Spanish
verbo
fruta
reir
centro
agosto
nadar

Portuguese
verbu
fruta
rir
centro
agosto
nadar

Example of a mutation process as seen by the
comparative method
la

vl
ib
es

• ib : Proto-ibero Romance
• vl : Vulgar Latin

it
pt

Example of a mutation process as seen by the
comparative method
la

vl

........
....
..
.
........
....
..
.

u → o / some context
m → / some context
....
........
....
..
.

ib
es

it
pt

• Deterministic re-write rules at each branch
• Activated by some context

........
....
..
.

Example of a mutation process as seen by the
comparative method
/werbum/ (la)
........
....
..
.
........
....
..
.

/verbo/ (vl)
/veɾbo/ (ib)
/beɾbo/ (es)

/vɛɾbo/ (it)

/veɾbu/ (pt)

u → o / some context
m → / some context
....
........
....
..
.
........
....
..
.

Gloss
Latin
Italian Spanish Portuguese
Word/verb verbum verbo verbo
verbu

Example of a mutation process as seen by the
comparative method
/kentrum/ (la)
........
....
..
.
........
....
..
.

/ʧentro/ (vl)
/sentɾo/ (ib)
/sentɾo/ (es)

/ʧɛntro/ (it)

/semtɾu/ (pt)

u → o / some context
m → / some context
....
........
....
..
.
........
....
..
.

Gloss
Latin
Italian Spanish Portuguese
Word/verb verbum verbo verbo
verbu
Center
centrum centro centro
centro
.
.

Example of a mutation process as seen by the
comparative method
la

vl
ib
es

it
pt

• In practice, the ancient words and/or the evolutionary tree are
unknown
• Methodology: manually inspecting the data

Our work:
• A probabilistic model that captures phonological aspects of
language change.
• Many usages:

?
/kwinto/

?
/kinto/

?

Reconstruction of word forms (ancient and modern)

Our work:
• A probabilistic model that captures phonological aspects of
language change.
• Many usages:

/kwintam/
?

/kinta/
?

/kinto/

?

/kwinto/

?

/kimtu/

Inference of phonological rules

Our work:
• A probabilistic model that captures phonological aspects of
language change.
• Many usages:
/kwintam/

/kinta/
/kwinto/

/kinto/

/kimtu/

vs.

/kwintam/
/kwinto/

/kinta/
/kinto/

/kimtu/

Selection of phylogenies

Our work:
• A probabilistic model that captures phonological aspects of
language change.
• Many usages:
– Reconstruction of word forms (ancient and modern)
– Inference of phonological rules
– Selection of phylogenies
• An inference procedure and experiments on all three applications
• A new task and evaluation framework

The model

Big picture

la

vl

it

es

• Assume for now that the tree topology is known

Big picture

la

vl

it

/werbum/
/kentrum/
...

/veɾbu/
/ʧentro/

es

/vɛrbo/
/ʧentro/
...

...

/beɾbo/

• Assume for now that the tree topology is known
• Track individual words

/sentɾo/

...

Stochastic edit model

/werbum/
/fokus/

#

...

f
f

/veɾbu/
/fwɔko/
...
...

...

...

w

o

k
ɔ

u
k

s

#

o

...

• Let’s look at how a single words evolve along one of the edges of
the tree
• Mutation of Latin FOCUS (/fokus/)
into Italian fuoco (/fwOko/) (ﬁre)

Stochastic edit model: operations

#

f
f

• Substitution

w

o

k
ɔ

u
k

s
o

#

Stochastic edit model: operations

#

f
f

w

o

k
ɔ

u
k

• Substitution (incl. self-substitution)

s
o

#

Stochastic edit model: operations

#

f
f

w

o

k
ɔ

u
k

• Substitution (incl. self-substitution)
• Insertion

s
o

#

Stochastic edit model: operations

#

f
f

w

o

k
ɔ

u
k

• Substitution (incl. self-substitution)
• Insertion
• Deletion

s
o

#

Stochastic edit model: context

#

f
f

w

o

k
ɔ

u
?

s

#

o

• Distribution over operations conditioned on adjacent phonemes

Stochastic edit model: generation process

#

f
f

w

o

k
ɔ

u
k

s
o

#

Stochastic edit model: generation process

#

f
?

o

k

u

s

#

Stochastic edit model: generation process

#

f
f

• P(f → f w / #

o
w

V) = 0.05

k

u

s

#

Stochastic edit model: generation process

#

f
f

• P(f → f w / #

o

w
V) = 0.05

k
?

u

s

#

Stochastic edit model: generation process

#

f
f

• P(f → f w / #
• P(o → O / C

o

w
V) = 0.05

V) = 0.1

k
ɔ

u

s

#

Stochastic edit model: generation process

#

f
f

• P(f → f w / #
• P(o → O / C

o

w

k
ɔ

u
k

s
o

V) = 0.05
V) = 0.1

• ...
• P(/fokus/ → /fwOko/)) = 0.05 × 0.1 × · · ·

#

Edit parameters

la

vl

it

/werbum/
/kentrum/
...

/veɾbu/
/ʧentro/

es

/vɛrbo/
/ʧentro/
...

...

/beɾbo/

/sentɾo/

...

Edit parameters
/werbum/
/kentrum/
...

la

P
θla→vl

vl

θla→es

/veɾbu/
/ʧentro/

...

θla→es

it

es

/vɛrbo/
/ʧentro/
...

/beɾbo/

/sentɾo/

...

• One set of parameter θA→B for each edge A → B in the tree
• Shared across all word forms evolving along this edge

Edit parameters
θla→vl
/veɾbu/
/ʧentro/

...

• θA→B speciﬁes P(operation|context)
context
um#
um#
um#
a cb
a cb
.
.

operation
P(operation|context)
deletion
0.1
substitution to /m/
0.8
substitution to /b/
0.1
deletion
0.8
insertion of c
0.1
.
.
.
.
.
.

Distribution on the edit parameters
• Too many parameters
• Addressed by:
– Sparsity prior: independent Dirichlet priors (one for each
context)
– Group context distributions. Example:
context
Vm#
Vm#
Vm#
VcC
VcC
.
.

operation
P(operation|context)
deletion
0.1
substitution to /a/
0.8
substitution to /b/
0.1
deletion
0.8
insertion of c
0.1
.
.
.
.
.
.

Inference and experiments

Inference: EM
• Exact E step is intractable
– We use a stochastic E step based on Gibbs sampling
• E: ﬁx the edit parameters, resample the derivations
• M: update the edit parameters from expected edit counts

Automatic extraction of a Romance corpus
Wiktionary
/

XML dump
QQQ
QQQ
QQQ
QQQ
Q(
/

Bible
Europarl

Align.
/

Closure
m6

/

Cognate detector

mm
mmm
mmm
mm
mmm
/

Align.

• Noisier than manually curated cognate lists
• More data available
• Our model overcomes this noise
Data available online:
http://nlp.cs.berkeley.edu/pages/historical.html

Reconstruction of ancient word forms
• Task: reconstruction of Latin given all of the Spanish and Italian
words, and some of the Latin words
• Evaluation: uniform cost edit distance on held-out data
• Baseline: pick one of the modern languages at random

Reconstruction of ancient word forms
• Task: reconstruction of Latin given all of the Spanish and Italian
words, and some of the Latin words
• Example: “teeth”, nearly correctly reconstructed

/dEntis/
i →E
E→jE

/djEntes/

s→

/dEnti/

• Numbers:
Language Baseline Model Improvement
Latin
2.84
2.34
9%

Reconstruction of word forms
• Evaluation: uniform cost edit distance on held-out data
• Baseline: pick one of the modern languages at random
• Example: “teeth”, nearly correctly reconstructed

/dEntis/
i →E
E→jE

/djEntes/

s→

/dEnti/

• Numbers:
Language Baseline Model Improvement
Latin
2.84
2.34
9%
Spanish
3.59
3.21
11%

Inference of phonological rules

la

vl
ib
es

• ib : Proto-ibero Romance
• vl : Vulgar Latin

it
pt

Inference of phonological rules

la

.........
.......
....
...

0.92
0.87
...
.

vl

.........
.......
....
...

m→ /_#
u →o/_
.....
...
.........
.......
....
...

.....
....
...
.

.........
.......
....
...

.....
....
...
.

.....
....
...
.
.....
....
...
.

ib
es

it
pt

• Reconstruct the internal nodes
• Focus on the rules used most often during the last E step

Hypothesized derivation for “word”
along with top rules
/werbum/ (la)

m→ /_#
u →o/_
w → v / many environments
...

m→
u→o
w→v

/verbo/ (vl)
r→ɾ

...

e→ɛ

...

• Comparison with historical evidence: the Appendix Probi
coluber non colober
passim non passi

Hypothesized derivation for “word”
along with top rules
...
u → o / many environments
v → b / init. or intervocal.
t → t e / ALV _ #
...

r→ɾ

/veɾbo/ (ib)
v→b

/beɾbo/ (es)
• /v/ to /b/ fortition
• /s/ to /z/ voicing in Italian

u→o

/veɾbu/ (pt)

Selection of phylogenies

Inference of topology

la

?
es

it

pt

Example of previous approaches
• Gray and Atkinson, 2003
• Coarse encoding:
Latin
French
Italian
Latin
Spanish
Portuguese

mandere (to chew)
manger
mangiare
comedere (to consume)
comer
comer

Meaning
Cognate set
Latin
French
Italian
Spanish
Portuguese

• These characters evolve independently in their model
• Lots of information discarded

Eat
1 2
1 1
1 0
1 0
0 1
0 1

···
···
···
···
···
···
···

Comparison

la

vl

it

/werbum/
/kentrum/
...

/veɾbu/
/ʧentro/

es

/vɛrbo/
/ʧentro/
...

...

/beɾbo/

Our samples look like this

/sentɾo/

...

Comparison
0

la

0

vl

it

es

1

0

1

...

0

...

0
...

Atkinson’s

0

...

What we did
• Present good vs. bad topologies and compute the likelihood ratio
la

la

it
es

pt

la

pt
es

it

es
it

pt

• this can be turned into a full topology inference algorithm using
the quartet method [Erdos et al., 1996]

Conclusion

• Introduced a probabilistic approach to diachronic phonology
• Enables reconstruction of ancient and modern word forms,
phonological rules and tree topologies
• Future work:
– We are scaling it up to larger phylogenies
– We are working on an extension using a log-linear
parametrization of the contexts, reminiscent of stochastic OT
• Data available online:
http://nlp.cs.berkeley.edu/pages/historical.html

