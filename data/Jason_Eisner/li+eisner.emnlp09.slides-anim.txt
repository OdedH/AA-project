First- and Second-order Expectation Semirings
with Applications to
Minimum-Risk Training on Translation Forests
Zhifei Li and Jason Eisner
Center for Language and Speech Processing
Computer Science Department
Johns Hopkins University

1
Wednesday, August 19, 2009

2
Wednesday, August 19, 2009

dianzi shang de mao

2
Wednesday, August 19, 2009

dianzi shang de mao
the cat on the mat

2
Wednesday, August 19, 2009

dianzi shang de mao
the cat on the mat

2
Wednesday, August 19, 2009

dianzi shang de mao
3
Wednesday, August 19, 2009

Joshua

dianzi shang de mao
3
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0

hypergraph

S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

dianzi0 shang1

X→ mao, a cat

de2

mao3

Joshua

dianzi shang de mao
3
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
S→ X0 , X0 lattice is a special case
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
node
S→ X0 , X0 lattice is a special case
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
node
S→ X0 , X0 lattice is a special case
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
node
S→ X0 , X0 lattice is a special case

hyperedge

S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
node
S→ X0 , X0 lattice is a special case

hyperedge

S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

A hypergraph is a compact data structure
to encode exponentially many trees.
packed forest
S 0,4
node
S→ X0 , X0 lattice is a special case

hyperedge

S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
4

Wednesday, August 19, 2009

mao3

S 0,4
S→ X0 , X0
S→ X0 , X0

S→ X0X , XX 0,4 a · · · mat
S→ , X0
X 0,4 the · · ·S→ X0 ,,0X0 0
cat
S→ X0 X 0
X ,
X→ X0X→de01de ,X1’sX1 1XX0
X 1 X , X on 0
X→ Xdede XX,0X1 on X0
0
X→ X0
X1 1 of
X→ X→ X0 1de0 X1 , X0 X1
X0 de X , X ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X→ dianzi shang, the mat
X→ dianzi shang, the mat
X→ dianzi shang, the mat X→ mao, a cat
X→ dianzi shang, the mat X→ mao, a cat
X→ mao, a cat
X→ mao, a cat

dianzi00 0shang11 1 de22 2 Xmao3· ·3· cat
dianzi shang de
mao
3,4 3
dianzi 0 shang 1 de 2 maoa 3

X 0,2 the · · · mat

X→ dianzi shang, the mat

dianzi0 shang1

X→ mao, a cat

de2

mao3

5
Wednesday, August 19, 2009

S 0,4

How many trees?

S→ X0 , X0
S→ X0 , X0

S→ X0X , XX 0,4 a · · · mat
S→ , X0
X 0,4 the · · ·S→ X0 ,,0X0 0
cat
S→ X0 X 0
X ,
X→ X0X→de01de ,X1’sX1 1XX0
X 1 X , X on 0
X→ Xdede XX,0X1 on X0
0
X→ X0
X1 1 of
X→ X→ X0 1de0 X1 , X0 X1
X0 de X , X ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X→ dianzi shang, the mat
X→ dianzi shang, the mat
X→ dianzi shang, the mat X→ mao, a cat
X→ dianzi shang, the mat X→ mao, a cat
X→ mao, a cat
X→ mao, a cat

dianzi00 0shang11 1 de22 2 Xmao3· ·3· cat
dianzi shang de
mao
3,4 3
dianzi 0 shang 1 de 2 maoa 3

X 0,2 the · · · mat

X→ dianzi shang, the mat

dianzi0 shang1

X→ mao, a cat

de2

mao3

5
Wednesday, August 19, 2009

S 0,4

How many trees?

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

a cat on the mat
Wednesday, August 19, 2009

mao3

S→ X0 , X0
X→ X0 de X1 , X1 of X0
X→ dianzi shang, the mat

dianzi0 shang1

mao3
6

mao3

X→ mao, a cat

de2

X→ mao, a cat

de2

de2

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ mao, a cat

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

How many trees?

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

four!

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

a cat on the mat
Wednesday, August 19, 2009

mao3

S→ X0 , X0
X→ X0 de X1 , X1 of X0
X→ dianzi shang, the mat

dianzi0 shang1

mao3
6

mao3

X→ mao, a cat

de2

X→ mao, a cat

de2

de2

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ mao, a cat

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

How many trees?

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

four!

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

mao3

l,
ra
e

po
ex

en
g

0

X→ X0 de X1 , X0 X1

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

de2

mao3

S→ X0 , X0
X→ X0 de X1 , X1 of X0

dianzi0 shang1
6

mao3

the mat a cat

X→ dianzi shang, the mat

mao3

X→ mao, a cat

X→ mao, a cat

de2

X→ mao, a cat

de2

S→ X0 , X0

X→ dianzi shang, the mat

the mat ‘s a cat

a cat on the mat
Wednesday, August 19, 2009

0

dianzi0 shang1

X→ X0 de X1 , X1 on X0

dianzi0 shang1

re
t

m

X→ dianzi shang, the mat

S→ X0 , X0

X→ dianzi shang, the mat

lly
a

ny
a

tiS→ X , X
n

e
n

In

s!
e

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

a cat on the mat
Wednesday, August 19, 2009

mao3

S→ X0 , X0
X→ X0 de X1 , X1 of X0
X→ dianzi shang, the mat

dianzi0 shang1

mao3
7

mao3

X→ mao, a cat

de2

X→ mao, a cat

de2

de2

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ mao, a cat

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

Weighted Hypergraph

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p=#

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

p="

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
7

mao3

p=!

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

p=!

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p=#

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

p="

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
8

mao3

p=!

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

p=!

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p=#

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

p="

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
8

mao3

p=!

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

p=!

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

Z$!%"%#%!$&

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

S→ X0 , X0

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p=#

mao3

X→ dianzi shang, the mat

S→ X0 , X0

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ dianzi shang, the mat

p="

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
8

mao3

p=!

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

p=!

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

Z$!%"%#%!$&

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
9

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

Z$!%"%#%!$&

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

The hypergraph deﬁnes a probability
distribution over trees!

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
9

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

Z$!%"%#%!$&

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

The hypergraph deﬁnes a probability
distribution over trees!
the distribution is parameterized by !

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
9

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

10
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

Entropy?

10
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

Entropy?
Bayes Risk?

10
Wednesday, August 19, 2009

Minimum Risk Training on Translation Forests
Finding optimal parameters:
"* = argmin Risk(P") ! Temperature " Entropy(P")
MERT

Min-Risk

49

48.7

BLEU

48.5
48
47.5

47.7

47

BLEU scores on an IWSLT Chinese-English test set
11
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

12
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

- expectation
- entropy
- Bayes risk
- cross-entropy
- KL divergence
- feature expectations
- ﬁrst-order gradient of Z
12

Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

- expectation
- entropy
- Bayes risk
- cross-entropy
- KL divergence
- feature expectations
- ﬁrst-order gradient of Z

Wednesday, August 19, 2009

• Second-order quantities:

- Expectation over product
- interaction between features
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk
12

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

- expectation
- entropy
- Bayes risk
- cross-entropy
- KL divergence
- feature expectations
- ﬁrst-order gradient of Z

Wednesday, August 19, 2009

This work provides a uniﬁed, elegant,
and efﬁcient framework in computing
all of these!

• Second-order quantities:

- Expectation over product
- interaction between features
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk
12

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

- expectation
- entropy
- Bayes risk
- cross-entropy
- KL divergence
- feature expectations
- ﬁrst-order gradient of Z

Wednesday, August 19, 2009

This work provides a uniﬁed, elegant,
and efﬁcient framework in computing
all of these!
useful in applying machine learning
techniques into machine translation

• Second-order quantities:

- Expectation over product
- interaction between features
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk
12

Outline
•

Semiring-weighted Inside Algorithm

•
•
•

•
•
•

counting semiring

(Goodman, 1999)

expectation semirings

second-order expectation semirings (new)

Applications of the Semirings (new)
Speed-up with Inside-outside (new)
Minimum Risk Training over Forests (new)

13
Wednesday, August 19, 2009

(Eisner, 2002)

Semiring-weighted
Inside Algorithm

14
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2
15

Wednesday, August 19, 2009

mao3

v5

v5
e7

e4

e3

v1

v4

e4
e5

e1

e6

v2

v2

e2

dianzi0 shang1

e2

de2
16

Wednesday, August 19, 2009

e5

e6

v1

e1

e8

v4

v3

v3
e3

e7

e8

mao3

What is a Semiring?

17
Wednesday, August 19, 2009

What is a Semiring?

K, ⊕, ⊗
a set with plus and times operations

17
Wednesday, August 19, 2009

Compute the Number of Derivation Trees

18
Wednesday, August 19, 2009

Compute the Number of Derivation Trees
Counting semiring: ordinary integers

18
Wednesday, August 19, 2009

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
Inside algorithm:

18
Wednesday, August 19, 2009

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
Inside algorithm:
Inputs:

18
Wednesday, August 19, 2009

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
v5

v5

Inside algorithm:

e7

Inputs:
- a hypergraph

e7

e8

e4

e3

e4
e5

v1
e1
dianzi0 shang1

18
Wednesday, August 19, 2009

v4

v4

v3

v3

e8

e5

e6

e6

v2

v2

e2

e2

de2

mao3

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
v5

v5

Inside algorithm:

e7

Inputs:
- a hypergraph
- a weight for each
hyperedge

e7

e8

e4

e3

e4
e5

v1
e1
dianzi0 shang1

18
Wednesday, August 19, 2009

v4

v4

v3

v3

e8

e5

e6

e6

v2

v2

e2

e2

de2

mao3

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
v5

Inside algorithm:

e7

Inputs:
- a hypergraph
- a weight for each
hyperedge

v5
e8 " e7

e4

e3

"

e4
"
e5

v1
e1 "
dianzi0 shang1

18
Wednesday, August 19, 2009

"
v4

v4

v3

v3

e8

"
e5

e6

"

e6

v2

v2

e2

" e2

de2

mao3

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
v5

Inside algorithm:

e7

Inputs:
- a hypergraph
- a weight for each
hyperedge

v5
e8 " e7

e4

e3

"

Output: k(root)

e4
"
e5

v1
e1 "
dianzi0 shang1

18
Wednesday, August 19, 2009

"
v4

v4

v3

v3

e8

"
e5

e6

"

e6

v2

v2

e2

" e2

de2

mao3

Compute the Number of Derivation Trees
Counting semiring: ordinary integers
v5

Inside algorithm:

e7

Inputs:
- a hypergraph
- a weight for each
hyperedge

v5
e8 " e7

e4

e3

"

Output: k(root)

e4
"
e5

v1

Complexity:
O(size of the hypergraph)

e1 "

18
Wednesday, August 19, 2009

"
v4

v4

v3

v3

e8

dianzi0 shang1

"
e5

e6

"

e6

v2

v2

e2

" e2

de2

mao3

e

v5
e7

v5
e8 " e7

e4

e3

"

v4

e4
"
e5

"

"

e6

v2

19

v2

e2

e1 "
dianzi0 shang1

e5

e6

v1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"

e4
"
e5

v4

"
e5

e6

v1

"

e6

v2

19

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"

e4
"
e5

v4

"
e5

e6

v1

"

e6

v2

19

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

k(v1)= k(e1)

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"

e4
"
e5

v4

"
e5

e6

v1

"

e6

v2

19

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

k(v1)= k(e1)

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

"

e6

v2

19

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

k(v1)= k(e1)

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

"

e6

v2

20

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

"

e6

v2

20

v2

e2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

" e2

de2

mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
20

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
21

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e3:

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
21

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e3:

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
21

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e3: k(e3) ⊗ k(v1) ⊗ k(v2)
v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
21

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e3: k(e3) ⊗ k(v1) ⊗ k(v2) ="!"!"$"
v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
21

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
22

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e4:
v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
22

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e4:
v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
22

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e4: k(e4) ⊗ k(v1) ⊗ k(v2) ="!"!"$"
v5
e7

v5

e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
22

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
Hyperedge e3: k(e3) ⊗ k(v1) ⊗ k(v2) = "

Hyperedge e4: k(e4) ⊗ k(v1) ⊗ k(v2) = "
v5
e7

v5

e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
23

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
k(e3)

⊗ k(v ) ⊗k(v )
1

v5
e7

e8 " e7

e3

"
v1

e8

e4
"
e5

2

"
v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

1

v4

v3
e4

⊗ k(v ) ⊗k(v )

v5

v3

Bottom-up
process in
computing the
number of trees

k(e4)

2

e2
24

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
k(v3) = k(e3)

⊗ k(v ) ⊗k(v ) ⊕ k(e ) ⊗ k(v ) ⊗k(v )
1

v5
e7

e8 " e7

e3

"
v1

e4
"
e5

2

"
v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

e8

v4

v3
e4

1

v5

v3

Bottom-up
process in
computing the
number of trees

4

2

e2
24

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
k(v3) = k(e3)

⊗ k(v ) ⊗k(v ) ⊕ k(e ) ⊗ k(v ) ⊗k(v )
1

4

2

1

2

"""$!

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

v3

e8

e2
24

de2

"

e6

v2 k(v2)="

" e2
mao3

e

Compute k(v3): the weight at node v3
k(v3) = k(e3)

⊗ k(v ) ⊗k(v ) ⊕ k(e ) ⊗ k(v ) ⊗k(v )
1

4

2

1

2

"""$!

v5
e7

v5
e8 " e7

e4

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

v3

k(v3)=!
v3

e8

e2
24

de2

"

e6

v2 k(v2)="

" e2
mao3

e

k(v1)= k(e1)
k(v3)= k(e3)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
1

2

v5
e7

4

e8 " e7

Bottom-up
process in
computing the
number of trees

e3

"
v1

e8

"
v4

v4
e4
"
e5

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

2

v5

k(v
v3 3)=! v3
e4

1

e2
25

de2

"

e6

v2 k(v2)="

" e2
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )

k(v3)= k(e3)
4

5

1

2

4

1

2

1

2

6

1

2

v5
e7

v5
e8 " e7

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

k(v
v3 3)=! v3
e4

e8

e2
25

de2

"

e6

v2 k(v2)="

" e2
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )

k(v3)= k(e3)
4

5

1

2

4

1

2

1

2

6

1

2

v5
e7

v5
e8 " e7

Bottom-up
process in
computing the
number of trees

e3

"
v1

e4
"
e5

k(v4)=!

v4

"
e5

e6

k(v1)="

v2

e1 "
dianzi0 shang1

Wednesday, August 19, 2009

"

v4

k(v
v3 3)=! v3
e4

e8

e2
25

de2

"

e6

v2 k(v2)="

" e2
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )

k(v3)= k(e3)
4

5

1

2

4

1

2

1

2

6

1

2

v5
e7

v5
e8 1 e7
"

Bottom-up
process in
computing the
number of trees

e3

1
"

v1

e4
1
"
e5

e5

e6

v2

"
e1 1

e2
26

k(v4)=!

v4

1
"

k(v1)="

dianzi0 shang1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3
e4

e8

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

4

v5

e8 1 e7
"

Bottom-up
process in
computing the
number of trees

e3

1
"

v1

e4
1
"
e5

e5

e6

v2

"
e1 1

e2
26

k(v4)=!

v4

1
"

k(v1)="

dianzi0 shang1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3
e4

e8

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

!"!$(
v5

v5

e8 1 e7
"

e7

Bottom-up
process in
computing the
number of trees

e3

1
"

v1

e4
1
"
e5

e5

e6

v2

"
e1 1

e2
26

k(v4)=!

v4

1
"

k(v1)="

dianzi0 shang1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3
e4

e8

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

!"!$(
v5

e8 1 e7
"

e7

Bottom-up
process in
computing the
number of trees

e3

1
"

v1

e4
1
"
e5

1
"

e5

e6

v2

"
e1 1

e2
26

k(v4)=!

v4

1
"

k(v1)="

dianzi0 shang1
Wednesday, August 19, 2009

e8

v4

k(v
v3 3)=! v3
e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

!"!$(
v5

e8 1 e7
"

e7

Bottom-up
process in
computing the
number of trees

e3

1
"

v1

e4
1
"
e5

1
"

e5

e6

v2

"
e1 1

e2
26

k(v4)=!

v4

1
"

k(v1)="

dianzi0 shang1
Wednesday, August 19, 2009

e8

v4

k(v
v3 3)=! v3
e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

4

e8 1 e7
"

e3

1
"

v1

e8

e4
1
"
e5

k(v1)="

dianzi0 shang1

e5

e6

v2
e2
27

k(v4)=!

v4

1
"

"
e1 1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3
e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

Summary:

4

e8 1 e7
"

e3

1
"

v1

e8

e4
1
"
e5

k(v1)="

dianzi0 shang1

e5

e6

v2
e2
27

k(v4)=!

v4

1
"

"
e1 1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3
e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

Summary:

4

e8 1 e7
"

e3

each edge

1
"

v1

e8

e4
1
"
e5

k(v1)="

dianzi0 shang1

e5

e6

v2
e2
27

k(v4)=!

v4

1
"

"
e1 1
Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3

• input: a weight for e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

Summary:

e8 1 e7
"

e3

1
"

v1

e8

1
"

e4
1
"
e5

1
"

k(v1)="

dianzi0 shang1

e5

e6

v2
e2
27

k(v4)=!

v4

v4

"
e1 1
Wednesday, August 19, 2009

k(v5)=(

v5

k(v
v3 3)=! v3

• input: a weight for e4
each edge
• output: a weight
for each node

4

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

Summary:

4

e8 1 e7
"

e3

e8

e4
1
"
e5

each edge
1
"
• output: a weight
for each node
v1 k(v1)="
• " is used at nodes
dianzi0 shang1

e5

e6

v2
e2
27

k(v4)=!

v4

1
"

"
e1 1

Wednesday, August 19, 2009

1
"

v4

k(v
v3 3)=! v3

• input: a weight for e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

Summary:

4

e8 1 e7
"

e3

e8

e4
1
"
e5

each edge
1
"
• output: a weight
for each node
v1 k(v1)="
• " is used at nodes
"
• ! is used at edges e1 1
dianzi0 shang1
Wednesday, August 19, 2009

1
"
1
"

e5

e6

v2
e2
27

k(v4)=!

v4

v4

k(v
v3 3)=! v3

• input: a weight for e4

k(v5)=(

v5

de2

1
"

e6

v2 k(v2)="

1 e2
"
mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

e8 1 e7
"

e3
"
1

v1

e8 "
1

e4
"
1
e5

"
1

k(v1)="

dianzi0 shang1

e5

e6

k(v4)=!

v4

v4

"
1

e6

v2

28

v2

e2

"
e1 1

Wednesday, August 19, 2009

k(v5)=(

v5

k(v
v3 3)=! v3
e4

4

"
1 e2

de2

mao3

k(v2)="

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

v5

e7

e8 1 e7
"

e3
"
1

Does it have to be a
single integer?
v1

e8 "
1

e4
"
1
e5

"
1

k(v1)="

dianzi0 shang1

e5

e6

k(v4)=!

v4

v4

"
1

e6

v2

28

v2

e2

"
e1 1

Wednesday, August 19, 2009

k(v5)=(

v5

k(v
v3 3)=! v3
e4

4

"
1 e2

de2

mao3

k(v2)="

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

v5 k(v5)=!&)!(*+,"

v5

e7
8
e7
e8 .")!-/e.")!-/
k(v3)=!-)!""

v3

v3
e4

v4

v4

k(v4)=!")!!"

e4
e3 .#)!#/ .")!"/
.!)!!/
e5 e6
.!)!-/ e5 e6
k(v2)=!")!!"

v1 k(v1)=!")!!"
v2
e.")!!/
1
dianzi0 shang1
Wednesday, August 19, 2009

e2
29

v2
.")!!/ 2
e

de2

mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

v5 k(v5)=!&)!(*+,"

v5

e7
8
e7
e8 .")!-/e.")!-/
k(v3)=!-)!""

v3

v3

v4

v4

k(v4)=!")!!"

e4
A semiring member e3 .#)!#/ .")!"/
e4
.!)!!/
e5 e6
.!)!-/ e5 e6
is a 2-tuple
k(v2)=!")!!"

v1 k(v1)=!")!!"
v2
e.")!!/
1
dianzi0 shang1
Wednesday, August 19, 2009

e2
29

v2
.")!!/ 2
e

de2

mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

v5 k(v5)=!&)(*,)(*,),/

v5

e8
e7
e8 e7
.")!-)-)-/ .")-)-)-/
k(v3)=!")")")"/v
v4 k(v4)=.")!)")#/
v4

v3

3

.")")")"/
e4 e3 e4
.!)!)!)!/
.#)#)#)#/ e5 e6
.!)-)-)-/e5 e6

v1 k(v1)=.")!)!)(/
v2
.")!)!)(/
e1

dianzi0 shang1
Wednesday, August 19, 2009

v2 k(v2)=.")!)!)(/

.")!)!)(/ 2
e
e2
30

de2

mao3

e

k(v1)= k(e1)

k(v2)= k(e2)

⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )⊗ k(v )
k(v )= k(e ) ⊗ k(v ) ⊕ k(e ) ⊗ k(v )

k(v3)= k(e3)

1

2

4

1

2

2

6

1

2

4

5

1

5

7

3

8

4

v5 k(v5)=!&)(*,)(*,),/

v5

e8
e7
e8 e7
.")!-)-)-/ .")-)-)-/
k(v3)=!")")")"/v
v4 k(v4)=.")!)")#/
v4

v3

A

3

.")")")"/
semiring member e3 e4
e4
.!)!)!)!/
.#)#)#)#/ e5 e6
is a 4-tuple .!)-)-)-/e5 e6

v1 k(v1)=.")!)!)(/
v2
.")!)!)(/
e1

dianzi0 shang1
Wednesday, August 19, 2009

v2 k(v2)=.")!)!)(/

.")!)!)(/ 2
e
e2
30

de2

mao3

Why do we want to work on tuples?

31
Wednesday, August 19, 2009

Why do we want to work on tuples?
expectation semiring
second-order expectation semiring

31
Wednesday, August 19, 2009

Why do we want to work on tuples?
expectation semiring
second-order expectation semiring
useful for
parameter estimation
at training time

31
Wednesday, August 19, 2009

Why do we want to work on tuples?
expectation semiring
second-order expectation semiring
useful for
parameter estimation
at training time
Goodman (1999) deﬁnes many other
semirings useful at “testing” time
31
Wednesday, August 19, 2009

First- and Second-order Expectation Semirings

32
Wednesday, August 19, 2009

First- and Second-order Expectation Semirings
First-order:

(Eisner, 2002)

32
Wednesday, August 19, 2009

First- and Second-order Expectation Semirings
First-order:

•

(Eisner, 2002)

each member is a 2-tuple:

32
Wednesday, August 19, 2009

p, r

First- and Second-order Expectation Semirings
First-order:

•

(Eisner, 2002)

each member is a 2-tuple:

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

32
Wednesday, August 19, 2009

p, r

First- and Second-order Expectation Semirings
First-order:

•

(Eisner, 2002)

each member is a 2-tuple:

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

Second-order:

32
Wednesday, August 19, 2009

p, r

First- and Second-order Expectation Semirings
First-order:

•

(Eisner, 2002)

each member is a 2-tuple:

p, r

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

Second-order:

•

each member is a 4-tuple:

32
Wednesday, August 19, 2009

p, r, s, t

First- and Second-order Expectation Semirings
First-order:

•

(Eisner, 2002)

each member is a 2-tuple:

p, r

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

Second-order:

•

each member is a 4-tuple:

p1 , r1 , s1 , t1 ⊗ p2 , r2 , s2 , t2
p1 , r1 , s1 , t1 ⊕ p2 , r2 , s2 , t2

p1 p2 , p1 r2 + p2 r1 , p1 s2 + p2 s1 ,
p1 t2 + p2 t1 + r1 s2 + r2 s1
p1 + p2 , r1 + r2 , s1 + s2 , t1 + t2
32

Wednesday, August 19, 2009

p, r, s, t

First- and Second-order Expectation Semirings
First-order:

•

each member is a 2-tuple:

p, r

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

Second-order:

•

each member is a 4-tuple:

p1 p2 , p1 r2 + p2 r1 , p1 s2 + p2 s1 ,
p1 t2 + p2 t1 + r1 s2 + r2 s1
p1 + p2 , r1 + r2 , s1 + s2 , t1 + t2

p1 , r1 , s1 , t1 ⊗ p2 , r2 , s2 , t2
p1 , r1 , s1 , t1 ⊕ p2 , r2 , s2 , t2
33
Wednesday, August 19, 2009

p, r, s, t

First- and Second-order Expectation Semirings
First-order:

•

each member is a 2-tuple:

p, r

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

What does p, r, s, or t mean?

Second-order:

•

each member is a 4-tuple:

p1 p2 , p1 r2 + p2 r1 , p1 s2 + p2 s1 ,
p1 t2 + p2 t1 + r1 s2 + r2 s1
p1 + p2 , r1 + r2 , s1 + s2 , t1 + t2

p1 , r1 , s1 , t1 ⊗ p2 , r2 , s2 , t2
p1 , r1 , s1 , t1 ⊕ p2 , r2 , s2 , t2
33
Wednesday, August 19, 2009

p, r, s, t

First- and Second-order Expectation Semirings
First-order:

•

each member is a 2-tuple:

p, r

p1 p2 , p 1 r 2 + p2 r1
p 1 + p2 , r 1 + r 2

p1 , r1 ⊗ p2 , r2
p1 , r1 ⊕ p2 , r2

What does p, r, s, or t mean?

Second-order:

•

p, r, s, t
application-dependent

each member is a 4-tuple:

p1 p2 , p1 r2 + p2 r1 , p1 s2 + p2 s1 ,
p1 t2 + p2 t1 + r1 s2 + r2 s1
p1 + p2 , r1 + r2 , s1 + s2 , t1 + t2

p1 , r1 , s1 , t1 ⊗ p2 , r2 , s2 , t2
p1 , r1 , s1 , t1 ⊕ p2 , r2 , s2 , t2
33
Wednesday, August 19, 2009

Applications

34
Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

e6

v2

v2

e2

e2

de2

mao3

35
Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

e6

v2

v2

e2

e2

de2

mao3

35
Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

# choose a semiring

e6

v2

v2

e2

e2

de2

mao3

35
Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

# choose a semiring

e6

v2

v2

e2

e2

de2

mao3

# specify a weight for each edge

35
Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

# choose a semiring

e6

v2

v2

e2

e2

de2

mao3

# specify a weight for each edge
# run the inside algorithm
35

Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

# choose a semiring

e6

v2

v2

e2

e2

de2

mao3

ﬁrst- or second-order
expectation semiring

# specify a weight for each edge
# run the inside algorithm
35

Wednesday, August 19, 2009

Compute Quantities on a Hypergraph: a Recipe
v5

v5
e7

e7

e8

e4

e3

v4

v4

v3

v3

Three steps:

e8

e4
e5

e5

e6

v1
e1
dianzi0 shang1

# choose a semiring

e6

v2

v2

e2

e2

de2

mao3

ﬁrst- or second-order
expectation semiring

# specify a weight for each edge
# run the inside algorithm
35

Wednesday, August 19, 2009

Compute
First-order Expectations

36
Wednesday, August 19, 2009

S 0,4

The hypergraph deﬁnes a probability
distribution over trees!

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
37

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

The hypergraph deﬁnes a probability
distribution over trees!

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

expected translation length?

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

X→ X0 de X1 , X1 of X0

dianzi0 shang1
37

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat

X→ X0 de X1 , X1 on X0

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat

S 0,4

The hypergraph deﬁnes a probability
distribution over trees!

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

expected translation length?

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

(

X→ X0 de X1 , X1 of X0

dianzi0 shang1
37

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat ,

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat ,

X→ X0 de X1 , X1 on X0
X→ dianzi shang, the mat

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat ,

S 0,4

The hypergraph deﬁnes a probability
distribution over trees!

S→ X0 , X0
S→ X0 , X0

X 0,4 a · · · mat

X 0,4 the · · · cat

X→ X0 de X1 , X1 on X0
X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat

expected translation length?
(0!'&%,01'&$(*+,

X 3,4 a · · · cat

X→ dianzi shang, the mat

X→ mao, a cat

dianzi0 shang1

de2

X→ X0 de X1 , X0 X1

p$#'&

mao3

S→ X0 , X0

X→ dianzi shang, the mat

dianzi0 shang1

S→ X0 , X0

dianzi0 shang1

de2

Wednesday, August 19, 2009

mao3

(

X→ X0 de X1 , X1 of X0

dianzi0 shang1
37

mao3

p$!'&

S→ X0 , X0

X→ dianzi shang, the mat

mao3

a cat on the mat ,

de2

X→ mao, a cat

de2

X→ mao, a cat

X→ mao, a cat

the mat a cat

the mat ‘s a cat ,

X→ X0 de X1 , X1 on X0
X→ dianzi shang, the mat

X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1

p$"'&

p$!'&

S→ X0 , X0

X→ mao, a cat

de2

mao3

a cat of the mat ,

Compute the expected translation length
using an expectation semiring

38
Wednesday, August 19, 2009

e

Compute Expected Translation Length

# choose a semiring
# specify a weight for each edge

# run the inside algorithm

39
Wednesday, August 19, 2009

e

Compute Expected Translation Length

# choose a semiring
expectation semiring
# specify a weight for each edge

# run the inside algorithm

39
Wednesday, August 19, 2009

e

Compute Expected Translation Length

# choose a semiring
expectation semiring
# specify a weight for each edge
def

ke = pe , pe re

# run the inside algorithm

39
Wednesday, August 19, 2009

e

Compute Expected Translation Length

# choose a semiring
expectation semiring
# specify a weight for each edge
def

ke = pe , pe re
pe: transition probability or log-linear score at edge e

# run the inside algorithm

39
Wednesday, August 19, 2009

e

Compute Expected Translation Length

# choose a semiring
expectation semiring
# specify a weight for each edge
def

ke = pe , pe re
pe: transition probability or log-linear score at edge e
re: number of English words generated at edge e

# run the inside algorithm

39
Wednesday, August 19, 2009

Expectations on Hypergraphs

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph
def

r = Ep [r] =

p(d)r(d)
d∈HG

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph
def

r = Ep [r] =

•

p(d)r(d)
d∈HG

the distribution p(d) is deﬁned by the hypergraph

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph
def

r = Ep [r] =

•
•

p(d)r(d)
d∈HG

the distribution p(d) is deﬁned by the hypergraph
r(d) is a function over a derivation d

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph
def

r = Ep [r] =

•
•

p(d)r(d)
d∈HG

the distribution p(d) is deﬁned by the hypergraph
r(d) is a function over a derivation d

e.g., the length of the translation yielded by d

40
Wednesday, August 19, 2009

Expectations on Hypergraphs
•

Expectation over a hypergraph
def

r = Ep [r] =

p(d)r(d)
d∈HG

•
•

r(d) is a function over a derivation d

•

r(d) is additively decomposed

the distribution p(d) is deﬁned by the hypergraph

e.g., the length of the translation yielded by d
def

r(d) =

re
e∈d

e.g., translation length is additively decomposed!
40
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:

def

re = log qe

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:

def

re = log qe
def

re = loss at edge e

41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:

def

re = log qe
def

re = loss at edge e

41
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:

def

re = log qe
def

re = loss at edge e

Why?

41
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e
entropy is an expectation

41
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e
entropy is an expectation
H(p) = Ep [− log p] = −
41

Wednesday, August 19, 2009

(Tromble et al. 2008)

p(d) log p(d)
d∈HG

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

(Tromble et al. 2008)

entropy is an expectation
H(p) = Ep [− log p] = −

p(d) log p(d)
d∈HG

log p(d) is additively decomposed!
41
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:

def

re = log qe
def

re = loss at edge e

Why?

42
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

cross-entropy is an expectation

42
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

cross-entropy is an expectation
H(p, q) = Ep (− log q) = −
42

Wednesday, August 19, 2009

(Tromble et al. 2008)

p(d) log q(d)
d∈HG

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

(Tromble et al. 2008)

cross-entropy is an expectation
H(p, q) = Ep (− log q) = −

p(d) log q(d)
d∈HG

log q(d) is additively decomposed!
42
Wednesday, August 19, 2009

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:

def

re = log qe
def

re = loss at edge e

Why?

43
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

Bayes risk is an expectation

43
Wednesday, August 19, 2009

(Tromble et al. 2008)

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

Bayes risk is an expectation
Risk = Ep (L) = −
43

Wednesday, August 19, 2009

(Tromble et al. 2008)

d∈HG

p(d) · L(Y (d))

Compute expectation using an expectation semiring:
def

ke = pe , pe re
pe : transition probability or log-linear score at edge e
re ?
def
re = log pe
Entropy:
Cross-entropy:
Bayes risk:
Why?

def

re = log qe
def

re = loss at edge e

(Tromble et al. 2008)

Bayes risk is an expectation
Risk = Ep (L) = −

d∈HG

p(d) · L(Y (d))

L(Y(d)) is additively decomposed!
43
Wednesday, August 19, 2009

Compute
Expectations over Products

44
Wednesday, August 19, 2009

p=3/8

p=2/8

S→ X0 , X0

S→ X0 , X0

X→ X0 de X1 , X0 X1
X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ mao, a cat

de2

mao3

dianzi0 shang1

the mat a cat

p=1/8

X→ dianzi shang, the mat

dianzi0 shang1

mao3

a cat on the mat
Wednesday, August 19, 2009

p=2/8

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

de2

mao3

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X1 on X0

dianzi0 shang1

de2

the mat ‘s a cat

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

45

X→ mao, a cat

de2

mao3

a cat of the mat

expected translation length:

p=3/8

p=2/8

S→ X0 , X0

S→ X0 , X0

X→ X0 de X1 , X0 X1
X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ mao, a cat

de2

mao3

dianzi0 shang1

the mat a cat

p=1/8

X→ dianzi shang, the mat

dianzi0 shang1

mao3

a cat on the mat
Wednesday, August 19, 2009

p=2/8

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

de2

mao3

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X1 on X0

dianzi0 shang1

de2

the mat ‘s a cat

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

45

X→ mao, a cat

de2

mao3

a cat of the mat

expected translation length:

p=3/8

p=2/8

S→ X0 , X0

S→ X0 , X0

X→ X0 de X1 , X0 X1
X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ mao, a cat

de2

mao3

X→ dianzi shang, the mat

dianzi0 shang1

the mat a cat

p=1/8

p=2/8

S→ X0 , X0

dianzi0 shang1

mao3

a cat on the mat
Wednesday, August 19, 2009

mao3

X→ dianzi shang, the mat

X→ mao, a cat

de2

de2

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X1 on X0
X→ dianzi shang, the mat

X→ mao, a cat

the mat ‘s a cat

S→ X0 , X0

dianzi0 shang1

4.75

45

X→ mao, a cat

de2

mao3

a cat of the mat

expected translation length:

4.75

variance of translation length?
p=3/8

p=2/8

S→ X0 , X0

S→ X0 , X0

X→ X0 de X1 , X0 X1
X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ mao, a cat

de2

mao3

dianzi0 shang1

the mat a cat

p=1/8

X→ dianzi shang, the mat

dianzi0 shang1

mao3

a cat on the mat
Wednesday, August 19, 2009

p=2/8

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

de2

mao3

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X1 on X0

dianzi0 shang1

de2

the mat ‘s a cat

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

45

X→ mao, a cat

de2

mao3

a cat of the mat

expected translation length:

4.75

variance of translation length?
2/8"(4-4.75)^2 + 6/8"(5-5.75)^2 $ 0.56

p=3/8

p=2/8

S→ X0 , X0

S→ X0 , X0

X→ X0 de X1 , X0 X1
X→ dianzi shang, the mat

dianzi0 shang1

X→ X0 de X1 , X0 ’s X1
X→ mao, a cat

de2

mao3

dianzi0 shang1

the mat a cat

p=1/8

X→ dianzi shang, the mat

dianzi0 shang1

mao3

a cat on the mat
Wednesday, August 19, 2009

p=2/8

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

de2

mao3

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X1 on X0

dianzi0 shang1

de2

the mat ‘s a cat

S→ X0 , X0

X→ dianzi shang, the mat

X→ mao, a cat

45

X→ mao, a cat

de2

mao3

a cat of the mat

e

Compute the Variance in Translation Length

# choose a semiring
# specify a weight for each edge

# run the inside algorithm
46
Wednesday, August 19, 2009

e

Compute the Variance in Translation Length

# choose a semiring
second-order expectation semiring
# specify a weight for each edge

# run the inside algorithm
46
Wednesday, August 19, 2009

e

Compute the Variance in Translation Length

# choose a semiring
second-order expectation semiring
# specify a weight for each edge
def
ke = pe , pe re , pe se , pe re se
pe: transition probability or log-linear score at edge e
re = se: number of English words generated at edge e

# run the inside algorithm
46
Wednesday, August 19, 2009

Second-order Expectations on Hypergraphs

•

Expectation of products over a hypergraph
def

t = Ep [r · s] =

•

p(d)r(d)s(d)
d∈HG

r and s are additively decomposed
def

r(d) =

re
e∈d

def

s(d) =

se
e∈d

47
Wednesday, August 19, 2009

Second-order Expectations on Hypergraphs

•

Expectation of products over a hypergraph
def

t = Ep [r · s] =

•

p(d)r(d)s(d)
d∈HG

r and s are additively decomposed
def

r(d) =

re
e∈d

def

s(d) =

se
e∈d

r and s can be identical or different functions.
47
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
48
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

pe = exp(Φe · θ)

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
48
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

pe = pe Φe

pe = exp(Φe · θ)

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
48
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
49
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

Entropy is an expectation!

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
49
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
50
Wednesday, August 19, 2009

adient of entropy
pe , pe log pe , p pe , (1 + log pe ) pe
Z, Z, Z,
Z −
Hessian matrix
pe ,
, pe , 2 p e
Z, r, Z, r2 Z
e
Z
Gradientexpectation
of risk
pe, pep e ,( pe ,)r e + pe ( r )
, L, p L p
Z, r, Z, r
Z
dient of
pe , pe re
Z, r, Z, r
e
e e
e
e
Z
Table 5: (1 + log table
radient of entropy
pe , pe log pe , pe ,A summary pe ) pe
Z, r, Z, r
Z −
First-order:
Z
Gradient of risk
pe , pe Le , pe , Le pe
Z, r, Z, r
Quantity
Weight for edge e
Value at root
Table 5: A summary table
Expectation
pe , pe re
Z, r
First-order gradient
pe pedge e
Z, Z
Quantity
Weight,for e
Value at root
Covariance matrix
pe , pe re ,epe serepe re se
Z, Z,s, t
r, r
Expectation
p , pe ,
Second-order:
Hessian matrix
pe , pp, , pp, 2 pe
Z, Z, Z, 2 Z
ee
ee
First-order gradient
Z, Z
Gradient of expectation pe , pe re , , p er (, p ps )rp + pe ( re )
p ,
Z, r, r, s, t r
Z,
e ,e r s
Covariance matrix
p
Z,

Applications of expectation semirings: a summary

Hessian matrix
Gradient of expectation

e

e e e
Table 6: A summary table
p e , p e , pe , 2 p e

pe , pe re ,

e e

e e

pe , ( pe )re + pe ( re )

Z, Z, Z, 2 Z
Z, r, Z, r

Table 6: A summary table

Bayes risk is an expectation!

# choose a semiring
# deﬁne a weight for each edge
# run inside algorithm (or inside-outside for speedup)
50
Wednesday, August 19, 2009

Inside-Outside
Speedup

51
Wednesday, August 19, 2009

Why is it slow?

52
Wednesday, August 19, 2009

Expectation Semirings with Vectors
v5

v5
e7

e7

e8

e4

e3

!

e4
e5

e6

v2

53

v2

e2

e1
dianzi0 shang1

e5

e6

v1

Wednesday, August 19, 2009

v4

v4

v3

v3

e8

e2

de2

mao3

Expectation Semirings with Vectors
1
v5!" , & "
v5
"
#
e8!- , "
e7 " , e! "e7
! 8
!
"
v4!" ,
4
v!" , v1 "
3
v3
(
e4 ! e3 e4 ! !" , ! " " ,
!
!" , " " !e,5 e6
e5 e6
" , "
"
v!" , ! "
1
"
!" , ! "
e1

dianzi0 shang1
Wednesday, August 19, 2009

#
1

"

!
!

!
!" , # "2
v
v2
!
!" , # "2
e
e2
53

de2

mao3

"

!

Expectation Semirings with Vectors
r is a

1
vector! v5
v5!" , & "
"
#
e8!- , "
e7 " , e! "e7
! 8
!
"
v4!" ,
4
v!" , v1 "
3
v3
(
e4 ! e3 e4 ! !" , ! " " ,
!
!" , " " !e,5 e6
e5 e6
" , "
"
v!" , ! "
1
"
!" , ! "
e1

dianzi0 shang1
Wednesday, August 19, 2009

#
1

"

!
!

!
!" , # "2
v
v2
!
!" , # "2
e
e2
53

de2

mao3

"

!

Expectation Semirings with Vectors
r is a

1
vector! v5
v5!" , & "
"
#
e8!- , "
e7 " , e! "e7
! 8
!
"
v4!" ,
4
v!" , v1 "
3
v3
(
e4 ! e3 e4 ! !" , ! " " ,
!
!" , " " !e,5 e6
e5 e6
" , "

Fake
numbers

"
v!" , ! "
1
"
!" , ! "
e1

dianzi0 shang1
Wednesday, August 19, 2009

#
1

"

!
!

!
!" , # "2
v
v2
!
!" , # "2
e
e2
53

de2

mao3

"

!

Second-order Expectation Semirings
v5

v5
e7

e7

e8

e4

e3

!

e4
e5

Wednesday, August 19, 2009

e6

v2

54

v2

e2

e1
dianzi0 shang1

e5

e6

v1
Fake
numbers

v4

v4

v3

v3

e8

e2

de2

mao3

Second-order Expectation Semirings
v5

v5

! ! ! !
"" ,7! , ! , ! !
8

e

e

e
!7

e

e4!
!

e

!
"" , ! , ! , !

e

e

! ! ! !
1 ", ! , ! , ! !
"

e

! ! !
"" , ! , ! , !
1

dianzi0 shang1
Wednesday, August 19, 2009

e

e

v

!
!

!
! !
! ! ! !
4 "" , ! , ! , ! !

v

v

v

!

! ! !
8 ", ! , ! , !
"

! ! ! !
"" , ! , 4! , ! ! !
3
! ! ! !
"" , ! , ! , ! !
4
3
!
! ! ! !
5
5
! !"" , ! , ! , ! ! !
6

v3

Fake
numbers

! ! ! !
"" , ! , ! , ! !

!
!

54

!
"" ,

e6

! ! ! !
"" ,2! , ! , ! !

v

e,2!
""

! !
! , ! , !

de2

!
!

! ! !
! , ! , !

v
!2
e2

!

mao3

!
!

!

!
!

Second-order Expectation Semirings

r and s are vectors!
v5

v5

! ! ! !
"" ,7! , ! , ! !
8

e

e

e
!7

e

e4!
!

e

!
"" , ! , ! , !

e

e

! ! ! !
1 ", ! , ! , ! !
"

e

! ! !
"" , ! , ! , !
1

dianzi0 shang1
Wednesday, August 19, 2009

e

e

v

!
!

!
! !
! ! ! !
4 "" , ! , ! , ! !

v

v

v

!

! ! !
8 ", ! , ! , !
"

! ! ! !
"" , ! , 4! , ! ! !
3
! ! ! !
"" , ! , ! , ! !
4
3
!
! ! ! !
5
5
! !"" , ! , ! , ! ! !
6

v3

Fake
numbers

! ! ! !
"" , ! , ! , ! !

!
!

54

!
"" ,

e6

! ! ! !
"" ,2! , ! , ! !

v

e,2!
""

! !
! , ! , !

de2

!
!

! ! !
! , ! , !

v
!2
e2

!

mao3

!
!

!

!
!

Second-order Expectation Semirings

r and s are vectors!
t is a matrix! ! v5 !
!

v5

!
"" ,7! , ! , ! !
8

e

e

e
!7

e

e4!
!

e

!
"" , ! , ! , !

e

e

! ! ! !
1 ", ! , ! , ! !
"

e

! ! !
"" , ! , ! , !
1

dianzi0 shang1
Wednesday, August 19, 2009

e

e

v

!
!

!
! !
! ! ! !
4 "" , ! , ! , ! !

v

v

v

!

! ! !
8 ", ! , ! , !
"

! ! ! !
"" , ! , 4! , ! ! !
3
! ! ! !
"" , ! , ! , ! !
4
3
!
! ! ! !
5
5
! !"" , ! , ! , ! ! !
6

v3

Fake
numbers

! ! ! !
"" , ! , ! , ! !

!
!

54

!
"" ,

e6

! ! ! !
"" ,2! , ! , ! !

v

e,2!
""

! !
! , ! , !

de2

!
!

! ! !
! , ! , !

v
!2
e2

!

mao3

!
!

!

!
!

Inside-Outside
Speedup

55
Wednesday, August 19, 2009

Inside-Outside
Speedup

See the paper for details!

55
Wednesday, August 19, 2009

Minimum Risk Training
over Translation Forests

57
Wednesday, August 19, 2009

Minimum Risk Training

58
Wednesday, August 19, 2009

Minimum Risk Training
Finding optimal parameters:

58
Wednesday, August 19, 2009

Minimum Risk Training
Finding optimal parameters:
"* = argmin Risk(P") ! Temperature " Entropy(P")

58
Wednesday, August 19, 2009

Minimum Risk Training
Finding optimal parameters:
"* = argmin Risk(P") ! Temperature " Entropy(P")

•

P" is a probability distribution over trees,
parameterized by the parameters "

58
Wednesday, August 19, 2009

Why Minimum Risk Training?
Min-Risk
Gradient
descent
BLEU
Latent
variable
Oracle
translation
Model
regularization

MERT

CRF

Perceptron

!
!
!
!
!

!
!
!
!
!

!
!
!
!
!

?
!
!
!
!

59
Wednesday, August 19, 2009

MIRA

?
!
!
!
!

Why Minimum Risk Training?
Min-Risk
Gradient
descent
BLEU
Latent
variable
Oracle
translation
Model
regularization

MERT

CRF

Perceptron

!
!
!
!
!

!
!
!
!
!

!
!
!
!
!

?
!
!
!
!

59
Wednesday, August 19, 2009

MIRA

?
!
!
!
!

•

Experimental Results
Data set: IWSLT CN-EN 2005

(Och, 2002)
(Smith and Eisner, 2006)
new!
new!

Training scheme
MERT (Nbest, small)
MR (Nbest, small)
MR (hypergraph, small)
MR (hypergraph, large)

test
47.7
47.7
48.4
48.7

Small: ﬁve features as in regular MERT
Large: two-stage forest-reranking with 21k additional
target-side ngram features
60
Wednesday, August 19, 2009

Summary

61
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

62
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

- expectation
- entropy
- cross-entropy
- KL divergence
- Bayes risk
- feature expectations
- ﬁrst-order gradient of Z
62

Wednesday, August 19, 2009

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

• First-order quantities:

• Second-order quantities:

- expectation
- entropy
- cross-entropy
- KL divergence
- Bayes risk
- feature expectations
- ﬁrst-order gradient of Z
62

Wednesday, August 19, 2009

- Covariance matrix
- feature interaction
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk

S 0,4
S→ X0 , X0
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

X 3,4 a · · · cat
X→ mao, a cat

de2

mao3

This work provides a uniﬁed, elegant,
and efﬁcient framework in computing
all of these!

• First-order quantities:

• Second-order quantities:

- expectation
- entropy
- cross-entropy
- KL divergence
- Bayes risk
- feature expectations
- ﬁrst-order gradient of Z
62

Wednesday, August 19, 2009

- Covariance matrix
- feature interaction
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk

S 0,4
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

48
47.5

47.7

X→ mao, a cat

mao3

This work provides a uniﬁed, elegant,
and efﬁcient framework in computing
all of these!

• First-order quantities:

• Second-order quantities:

- expectation
- entropy
- cross-entropy
- KL divergence
- Bayes risk
- feature expectations
- ﬁrst-order gradient of Z
62

Wednesday, August 19, 2009

48.7

48.5

47

X 3,4 a · · · cat

de2

Min-Risk

49

BLEU

Improved
BLEU score!

S→ X0 , X0

MERT

- Covariance matrix
- feature interaction
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk

Future: machine learning for MT

63
Wednesday, August 19, 2009

Future: machine learning for MT

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT

minimum
risk

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT

minimum deterministic
risk
annealing

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT

minimum deterministic
risk
annealing

active
learning

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT

minimum deterministic
risk
annealing

semiactive
supervised
learning
learning

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT
feature
interaction
minimum deterministic
risk
annealing

semiactive
supervised
learning
learning

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT
feature
second-order
interaction gradient descent
minimum deterministic
risk
annealing

semiactive
supervised
learning
learning

semirings for parameter estimation

63
Wednesday, August 19, 2009

Future: machine learning for MT
feature
second-order
interaction gradient descent
minimum deterministic
risk
annealing

.......

semiactive
supervised
learning
learning

semirings for parameter estimation

63
Wednesday, August 19, 2009

Joshua
semiring
64
Wednesday, August 19, 2009

Thank you!
##$

65
Wednesday, August 19, 2009

S 0,4
S→ X0 , X0

X 0,4 the · · · cat

X 0,4 a · · · mat

Probabilistic
Hypergraph
X→ X0 de X1 , X1 on X0

X→ X0 de X1 , X0 ’s X1

X→ X0 de X1 , X1 of X0

X→ X0 de X1 , X0 X1

X 0,2 the · · · mat
X→ dianzi shang, the mat

dianzi0 shang1

48
47.5

47.7

X→ mao, a cat

mao3

This work provides a uniﬁed, elegant,
and efﬁcient framework in computing
all of these!

• First-order quantities:

• Second-order quantities:

- expectation
- entropy
- cross-entropy
- KL divergence
- Bayes risk
- feature expectations
- ﬁrst-order gradient of Z
66

Wednesday, August 19, 2009

48.7

48.5

47

X 3,4 a · · · cat

de2

Min-Risk

49

BLEU

Improved
BLEU score!

S→ X0 , X0

MERT

- Covariance matrix
- feature interaction
- Hessian matrix of Z
- second-order gradient
descent
- gradient of expectation
- gradient of entropy or
Bayes risk

