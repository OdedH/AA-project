Poster W9

Agreement-Based Learning
Percy Liang, Dan Klein, Michael I. Jordan
UC Berkeley • Computer Science Division

1 minute summary

Product EM

Problem: learning complex hidden-variable models
Traditional solution: approximate EM
µ

E

Objective function:

M ···

def

Oagree(θ) = log

one intractable model

Our solution: product EM (train submodels to agree)
M b
¯ E µ
b
µ M
¯
+ ¯
+ µ
⇒
···
b
¯
b
µ
two tractable submodels
M
E
M
Applications: unsupervised NLP, phylogenetic HMMs
1

z

2

θ1
z1

···

x1

Oagree ≥ L(θ, q) =

Phylogenetic HMMs

baboon

A

?
chimp human

C

A

T C

C
A

C

A A

T
C

T

G C

C

G

T T

A

is

“

demand

loading

···
M

T A

Goal: learn to output a matching between two sequences by
modeling the translation process of words between a pair of
sentences
Computational challenge: enumerating all matchings
Agreement-based solution:
Two complementary HMM alignment models [Vogel, 1996]:
term

M

m

Unsupervised word alignment

railroad

Eq log pm(x, z; θm) + H(q)

µ

b1
b2

+

M

¯
b

E

M
···

µ

M

Properties:
• E-step couples submodels: could be intractable
• M-step decomposes into M tractable steps

Assume submodels are in exponential family:
T
X
Z
pm(x, z; θm) = exp θm φm(x)φ (z) − Am(θm)
for x ∈ X , z ∈ Zm and 0 otherwise

”

le

terme
terme

the

ferroviaire
ferroviaire

railroad

est
est

term

“
“

is

chargement
chargement

“

demand

sur
sur

demande
demande

loading

”

”
”

µ = E(b, ∩mZm) = Eq(z;b)φ (z) with support ∩mZm
X
M-step: set θm to match moments φm(x)µ

+ ¯
b

µ1

µ
¯

µ2

M

+ µ
¯

E

···
M

Choices for E-steps:
• Domain-approximate product EM: b = b, Z = Zm
(used for word alignment)
• Parameter-approximate product EM: b = M bm, Z = Z
(used for phylogenetic HMMs)
Properties:
• E-step decomposes into M tractable steps now
• M-step decomposes into M tractable steps as in product EM

Experimental results
• Phylogenetic HMMs: agreement-based learning yields faster
convergence
• Unsupervised word alignment: agreement-based learning
yields best published results
50% heldout

Aggregate parameters: b = m bm, bm =
E-step: compute expected suﬃcient statistics
Z

E

¯
b

M

X
T
φm(x) θm

def

b1
b2

Exponential family formulation

Reformulation of Product EM:
le

Aggregate parameters: b = m bm
E-step: compute statistics µm = E(b , Z )
1
Aggregate statistics: µ = M m µm
¯
X
M-step: set θm to match moments φm(x)¯
µ

E-step: q(z) ∝ m pm(x, z; θm)
M-step: θm = argmaxθ Eq log p(x, z; θm)

A

Computational challenge: doing inference in a loopy graph
Agreement-based solution:
Break up model into the red part and the green part

the

xM

m

Goal: model both nucleotide mutations across species and
dependencies between adjacent sites
A

zM

New objective function:
• A function of suﬃcient statistics µm and parameters θm for
each submodel m = 1, . . . , M
• See paper for some preliminary bounds
Algorithm:

Algorithm:
Introduce auxiliary q, use Jensen’s inequality:
def

C

θM

Oagree(θ) = p(x1 = · · · = xM = x, z1 = · · · = zM ; θ)

Motivating applications

?

m

Interpretation:
Each submodel m independently generates (xm, zm)

1

2

pm(x, z; θm)

Two sources of intractability in the E-step:
• Domain Z = ∩mZm is unwieldy (e.g., matchings)
• Parameters b result in high tree-width graph

HMM model

0.12

Independent EM
Domain-approximate product EM

0.8

alignment error rate

⇒M

Setup:
M submodels {pm(x, z; θm) : m = 1, . . . , M }

0.7

accuracy

b

Approximate product EM

0.6

0.5

0.4

Independent EM
Parameter-approximate product EM
0

5

10

15

iteration

20

25

0.11

0.1

0.09

0.08

0.07

1

2

3

4

5

6

iteration

7

8

9

10

