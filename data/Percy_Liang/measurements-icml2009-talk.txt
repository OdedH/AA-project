Learning from Measurements
in Exponential Families
ICML – Montreal
June 16, 2009

Percy Liang

Michael Jordan

Dan Klein

The big picture
target
predictor p∗

human

2

The big picture
target
predictor p∗
y:

human

feat feat feat

x: View

of

feat

feat

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

Outline:
1. Coherently learn from diverse measurements

2

The big picture
target
predictor p∗
y:

human

information

feat feat feat

x: View

of

learning
algorithm

feat

feat

learned
predictor p
ˆ

...

Los Gatos Foothills ...

Example:
avail

avail avail ... size

Available July

1

...

2

size

size

bedroom

1

size

...

bath ...

Types of information:
Labeled examples (speciﬁc) [standard supervised learning]
Constraints (general) [Chang, et al., 2007; Druck, et al., 2008]
Measurements: our unifying framework

Outline:
1. Coherently learn from diverse measurements
2. Actively select the best measurements

2

Measurements
X1
X2
X3
...
Xi
...
Xn

, Y1
, Y2
, Y3
...
, Yi
...
, Yn

3

Measurements
Measurement features: σ(x, y) ∈ Rk
σ( X1 , Y1
σ( X2 , Y2
σ( X3 , Y3
... ...
σ( Xi , Yi
... ...
σ( Xn , Yn

)
)
)
)
)

3

Measurements
σ( X1 , Y1
σ( X2 , Y2
σ( X3 , Y3
... ...
σ( Xi , Yi
... ...
σ( Xn , Yn
+ noise

)
)
)

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

τ=

σ(Xi , Yi ) + noise
i=1

)
)

+τ

3

Measurements
σ( X1 , Y1
σ( X2 , Y2
σ( X3 , Y3
... ...
σ( Xi , Yi
... ...
σ( Xn , Yn
+ noise
+τ

)
)
)

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

τ=

σ(Xi , Yi ) + noise
i=1

)
)

Xi
τ
Yi
n

3

Measurements
σ( X1 , Y1
σ( X2 , Y2
σ( X3 , Y3
... ...
σ( Xi , Yi
... ...
σ( Xn , Yn
+ noise
+τ

)
)
)

Measurement features: σ(x, y) ∈ Rk
Measurement values: τ ∈ Rk
n

τ=

σ(Xi , Yi ) + noise
i=1

)
)

Xi
τ
Yi
n

Set σ to reveal various types of information about Y through τ

3

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) =

i

I[xi = View, yi = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) =

i

I[xi = View, yi = *]

Label proportions:
σj (x, y) =

i

I[yi = *]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) =

i

I[xi = View, yi = *]

Label proportions:
σj (x, y) =

i

I[yi = *]

Label preference:
σj (x, y) =

i

I[yi = feat] − I[yi = avail]

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) =

i

I[xi = View, yi = *]

Label proportions:
σj (x, y) =

i

I[yi = *]

Label preference:
σj (x, y) =

i

I[yi = feat] − I[yi = avail]

Can get measurement values τ without looking at all examples

4

Examples of measurements
Fully-labeled example:
σj (x, y) = I[x = View of Los ..., y = * * * ...]
Partially-labeled example:
σj (x, y) = I[x = View of Los ..., y1 = *]
Labeled predicate:
σj (x, y) =

i

I[xi = View, yi = *]

Label proportions:
σj (x, y) =

i

I[yi = *]

Label preference:
σj (x, y) =

i

I[yi = feat] − I[yi = avail]

Can get measurement values τ without looking at all examples
Next: How to combine these diverse measurements coherently?

4

Prediction model
Bayesian framework:
Xi
τ
Yi
n

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd : model features

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd : model features
θ ∈ Rd : model parameters

5

Prediction model
Bayesian framework:
Xi
τ

θ
Yi
n

Exponential families:
pθ (y | x) = exp{ φ(x, y), θ − A(θ; x)}
φ(x, y) ∈ Rd : model features
θ ∈ Rd : model parameters
A(θ; x) = log exp{ φ(x, y), θ }dy: log-partition function

5

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(θ, Y ) || p(θ, Y | τ, X))

q∈Qθ,Y

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(θ, Y ) || p(θ, Y | τ, X))

q∈Qθ,Y

Approximations:
˜
• Qθ,Y : mean-ﬁeld factorization of q(Y ) and degenerate θ

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(θ, Y ) || p(θ, Y | τ, X))

q∈Qθ,Y

Approximations:
˜
• Qθ,Y : mean-ﬁeld factorization of q(Y ) and degenerate θ
• KL: measurements only hold in expectation (w.r.t. q(Y ))

6

Learning via Bayesian inference
Xi

Goal: compute p(θ, Y | τ, X)

τ

θ
Yi
n

Variational formulation:
min KL (q(θ, Y ) || p(θ, Y | τ, X))

q∈Qθ,Y

Approximations:
˜
• Qθ,Y : mean-ﬁeld factorization of q(Y ) and degenerate θ
• KL: measurements only hold in expectation (w.r.t. q(Y ))
Algorithm:
Apply Fenchel duality → saddlepoint problem
Take alternating stochastic gradient steps
6

Information geometry viewpoint
(assume zero measurement noise)
def

P = {pθ (y | x) : θ ∈ Rd }

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

def

P = {pθ (y | x) : θ ∈ Rd }

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

def

P = {pθ (y | x) : θ ∈ Rd }

KL (q || p)

7

Information geometry viewpoint
(assume zero measurement noise)
def

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

def

P = {pθ (y | x) : θ ∈ Rd }

KL (q || p)

Interpretation:
Measurements shape Q

Find model in P with best ﬁt

7

Information geometry viewpoint
(assume zero measurement noise)
def

def

P = {pθ (y | x) : θ ∈ Rd }

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

KL (q || p)

Interpretation:
Measurements shape Q

Find model in P with best ﬁt

Two ways to recover supervised learning:
1. Measure σ = φ: P ∩ Q is the unique solution

7

Information geometry viewpoint
(assume zero measurement noise)
def

def

P = {pθ (y | x) : θ ∈ Rd }

Q = {q(y | x) : Eq [σ] = τ }

min

q∈Q,p∈P

KL (q || p)

Interpretation:
Measurements shape Q

Find model in P with best ﬁt

Two ways to recover supervised learning:
1. Measure σ = φ: P ∩ Q is the unique solution
2. Measure σ = {I[x = a, y = b]}:
Q = {empirical distribution}, project onto P

7

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]
If f is a measurement feature (direct):
“inputs in A should be labeled according to τ ”

8

Model features φ versus measurement features σ
Xi
τ

θ
φ

σ

Yi
n

Guidelines:
To set σ, consider human (e.g., full labels)
To set φ, consider statistical generalization (e.g., word suﬃxes)

Intuition: consider feature f (x, y) = I[x ∈ A, y = 1]
If f is a measurement feature (direct):
“inputs in A should be labeled according to τ ”
If f is a model feature (indirect):
“inputs in A should be labeled similarly”

8

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g.,

i

I[xi = View , yi = feat])

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g.,

i

I[xi = View , yi = feat])

Per-position test accuracy (on 100 examples):
# labeled examples
General Expectation Criteria
Constraint-Driven Learning
Measurements

10
74.6
74.7
71.4

25
77.2
78.5
76.5

100
80.5
81.7
82.5

9

Results on the Craigslist task
n = 1000 total examples (ads), 11 possible labels
Model:
Conditional random ﬁeld with standard NLP features
Measurements:
• fully-labeled examples
• 33 labeled predicates (e.g.,

i

I[xi = View , yi = feat])

Per-position test accuracy (on 100 examples):
# labeled examples
General Expectation Criteria
Constraint-Driven Learning
Measurements

10
74.6
74.7
71.4

25
77.2
78.5
76.5

100
80.5
81.7
82.5

Able to integrate labeled examples and predicates gracefully

9

So far: given measurements, how to learn

Next: how to choose measurements?

10

Bayesian decision theory
Xi
τ

θ
Yi
n

What do we do with an (approximate) posterior p(Y, θ | X, τ )?

11

Bayesian decision theory
reward

Xi

X

τ

θ
ˆ
Y

Y

Yi
n

What do we do with an (approximate) posterior p(Y, θ | X, τ )?
Bayes-optimal predictor:
ˆ
average over X , max over Y , average over Y of reward

11

Bayesian decision theory
reward

Xi

X

τ

θ
ˆ
Y

Y

Yi
n

What do we do with an (approximate) posterior p(Y, θ | X, τ )?
Bayes-optimal predictor:
ˆ
average over X , max over Y , average over Y of reward
R(σ, τ ) = expected reward of Bayes-optimal predictor
(i.e., how happy we are with the given situation)

11

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X) [U (σ, τ )]

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X) [U (σ, τ )]

12

Experimental design (active learning)
Xi
U

τ

θ

σ

Yi
n

Utility of measurement (σ, τ ):
U (σ, τ ) = R(σ, τ ) − C(σ)
reward

cost

When considering σ, don’t know τ , so integrate out:
U (σ) = Ep(τ |X) [U (σ, τ )]
Choose best measurement feature σ:
σ ∗ = argmaxσ U (σ)

12

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
0.9

test accuracy

0.8
0.7
0.6
random

0.6

entropy

20

40

60

80

100

# measurements k

(a) Labeling examples

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
0.7

test accuracy

0.8

0.8

test accuracy

0.9

0.7
0.6
random

0.6

40

60

80

# measurements k

(a) Labeling examples

0.6

frequency
random

0.5

entropy

20

0.7

100

entropy

20

40

60

80

100

# measurements k

(b) Labeling word types

13

Part-of-speech tagging results
n = 1000 total examples (sentences), 45 possible labels
Model: Indep. logistic regression with standard NLP features
Measurements:
• fully-labeled examples
• labeled predicates (e.g., i I[xi = the, yi = dt])
Use label entropy as surrogate for assessing measurements
Test accuracy (on 100 examples):
0.7

test accuracy

0.8

0.8

test accuracy

0.9

0.7
0.6
random

0.6

40

60

80

# measurements k

(a) Labeling examples

0.6

frequency
random

0.5

entropy

20

0.7

100

entropy

20

40

60

80

100

# measurements k

(b) Labeling word types

13

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

14

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

Bayesian model

14

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

14

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

information
geometry

14

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

Bayesian model

decision theory

information
geometry

14

Summary
target
predictor p∗

human

measurements

learning
algorithm

learned
predictor p
ˆ

Measurements

variational approx.

information
geometry

Bayesian model

decision theory

active
learning

14

